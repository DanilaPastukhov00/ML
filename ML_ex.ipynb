{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e6a73b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Метрики оценки моделей зависят от типа задачи: классификация, регрессия или другие. Вот основные метрики:\n",
    "\n",
    "### 1. Метрики для классификации\n",
    "- **Accuracy (Точность)**: Доля правильно классифицированных объектов.\n",
    "$\n",
    "Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$\n",
    "где $TP$ — истинно положительные, $TN$ — истинно отрицательные, $FP$ — ложно положительные, $FN$ — ложно отрицательные.\n",
    "\n",
    "- **Precision (Точность)**: Доля истинно положительных среди всех предсказанных положительных.\n",
    "$\n",
    "Precision = \\frac{TP}{TP + FP}\n",
    "$\n",
    "\n",
    "- **Recall (Полнота)**: Доля истинно положительных среди всех реальных положительных.\n",
    "$\n",
    "Recall = \\frac{TP}{TP + FN}\n",
    "$\n",
    "\n",
    "- **F1-Score**: Гармоническое среднее Precision и Recall.\n",
    "$\n",
    "F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}\n",
    "$\n",
    "\n",
    "- **ROC-AUC**: Площадь под ROC-кривой, которая показывает зависимость между чувствительностью (Recall) и 1-специфичностью.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Метрики для регрессии\n",
    "- **Mean Squared Error (MSE)**: Среднеквадратичная ошибка.\n",
    "    $\n",
    "    MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "    $\n",
    "\n",
    "- **Mean Absolute Error (MAE)**: Средняя абсолютная ошибка.\n",
    "    $\n",
    "    MAE = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|\n",
    "    $\n",
    "\n",
    "- **R² (Коэффициент детерминации)**: Доля объяснённой дисперсии.\n",
    "    $\n",
    "    R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2} \n",
    "    $\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Выбор метрики\n",
    "- Для **несбалансированных данных** в классификации лучше использовать Precision, Recall или F1-Score.\n",
    "- Для регрессии выбор метрики зависит от задачи: MSE штрафует за большие ошибки, а MAE более устойчив к выбросам.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8f317",
   "metadata": {},
   "source": [
    "Метрика **ROC-AUC** (Receiver Operating Characteristic - Area Under the Curve) — это один из самых популярных способов оценки качества бинарных классификаторов.\n",
    "\n",
    "---\n",
    "\n",
    "### Что такое ROC-кривая?\n",
    "\n",
    "**ROC-кривая** показывает, как меняется качество модели при разных порогах классификации. На графике по осям:\n",
    "\n",
    "- **X (False Positive Rate, FPR)** — доля ложных срабатываний:  \n",
    "  $\n",
    "  FPR = \\frac{FP}{FP + TN}\n",
    "  $\n",
    "- **Y (True Positive Rate, TPR)** или Recall — доля верно предсказанных положительных:\n",
    "  $\n",
    "  TPR = \\frac{TP}{TP + FN}\n",
    "  $\n",
    "\n",
    "Для разных порогов вероятности модель будет давать разные TPR и FPR — и мы получаем кривую.\n",
    "\n",
    "---\n",
    "\n",
    "### Что такое AUC?\n",
    "\n",
    "**AUC** = Area Under the Curve — площадь под ROC-кривой.\n",
    "\n",
    "- Значение **AUC лежит в диапазоне от 0 до 1**:\n",
    "  - **1.0** — идеальная модель.\n",
    "  - **0.5** — рандом (модель не лучше угадывания).\n",
    "  - **<0.5** — модель хуже случайной (но можно просто инвертировать предсказания).\n",
    "\n",
    "---\n",
    "\n",
    "### Преимущества ROC-AUC:\n",
    "- Учитывает **все возможные пороги**.\n",
    "- Устойчив к **несбалансированным классам** (лучше, чем accuracy в этом плане).\n",
    "- Не зависит от конкретного порога, что даёт общую картину.\n",
    "\n",
    "---\n",
    "\n",
    "### Когда использовать (а когда — нет):\n",
    "\n",
    "Хорошо:\n",
    "- Для **оценки общей силы модели** независимо от выбранного порога.\n",
    "\n",
    "Не идеально:\n",
    "- Когда важна **конкретная стоимость ошибок** (например, False Positive опаснее, чем False Negative).\n",
    "- При **крайнем дисбалансе классов** лучше использовать **PR-AUC (Precision-Recall AUC)**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "084ceb34-8b70-4c47-b2b9-c85deb14fc00",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# 1.\tГрадиентный спуск."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c3b51e-3611-4b01-b48a-8aa5aad27a15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Функция потерь. Оптимизация."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb869387-f2d7-4f58-a8c4-67aee778cd34",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**1. Функция потерь (Loss function)**  \n",
    "- **Что это такое?**  \n",
    "  Функция потерь показывает, насколько хорошо или плохо наша модель решает задачу. Она сравнивает предсказанные моделью значения с реальными (истинными) значениями и возвращает некое «число ошибки». Чем меньше это число, тем лучше модель.  \n",
    "\n",
    "- **Почему она важна?**  \n",
    "  Она служит «ориентиром» при обучении: мы стремимся минимизировать значение этой функции, чтобы улучшить качество предсказаний.  \n",
    "\n",
    "Примеры:\n",
    "- **MSE (Mean Squared Error)** — среднеквадратичная ошибка. Обычно используется в задачах регрессии.  \n",
    "- **Cross-entropy (перекрёстная энтропия)** — часто используется в задачах классификации.  \n",
    "\n",
    "**2. Оптимизация**  \n",
    "- **Что значит оптимизировать?**  \n",
    "  Оптимизация — это процесс подбора параметров (например, весов в нейронной сети), чтобы функция потерь была как можно меньше.  \n",
    "\n",
    "- **Как это делается на практике?**  \n",
    "  Самый популярный метод — **градиентный спуск**. Идея в том, что мы вычисляем «наклон» (градиент) функции потерь по отношению к параметрам и немного сдвигаем параметры в сторону уменьшения этой функции.  \n",
    "\n",
    "**3. Градиентный спуск**  \n",
    "- **Основная идея**:  \n",
    "  1. Случайным образом инициализируем параметры (веса) модели.  \n",
    "  2. Считаем, как сильно изменилась функция потерь, если слегка «сдвинуть» каждый параметр (то есть находим градиент).  \n",
    "  3. Обновляем параметры в направлении, противоположном градиенту (потому что мы хотим уменьшить функцию потерь).  \n",
    "  4. Повторяем много раз, пока не достигнем минимума (или пока улучшения не станут незначительными).  \n",
    "\n",
    "- **Как записывается обновление?**  \n",
    "  Если $ w $ — это вектор параметров, а $ L(w) $ — функция потерь, то обновление выглядит так:  \n",
    "\n",
    "  $ w_{\\text{new}} = w_{\\text{old}} - \\alpha \\cdot \\nabla L(w_{\\text{old}})$ ,\n",
    "  где  \n",
    "  - $ \\alpha $ — это **шаг обучения** (learning rate), который определяет, насколько сильно мы двигаемся в сторону снижения ошибки,  \n",
    "  - $ \\nabla L $ — вектор частных производных (градиент) функции потерь по параметрам.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22899290-c741-41a9-9f6d-d50ba51fe86f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Производная, частные производные, градиент. Методы оценки градиента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98349edb-9186-4648-8904-e759c77a9dba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**1. Производная**  \n",
    "- Если у нас есть функция $f(x)$, то **производная** $f'(x)$ в точке $x$ — это «скорость изменения» функции в этой точке.  \n",
    "- Проще говоря, это наклон графика функции. Если производная положительная — функция возрастает, отрицательная — убывает.  \n",
    "\n",
    "**2. Частные производные**  \n",
    "- Когда у нас несколько переменных (например, функция $f(x, y)$), мы можем взять производную по каждой из них отдельно.  \n",
    "- Такая производная по одной переменной, при условии что все остальные переменные считаются константами, называется **частной производной**.  \n",
    "\n",
    "\n",
    "**3. Градиент**  \n",
    "- **Градиент** — это вектор, состоящий из всех частных производных функции по её переменным. Например, у функции $ f(x, y) $ градиент будет:\n",
    "  $\n",
    "  \\nabla f(x, y) = \\left( \\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y} \\right).\n",
    "  $\n",
    "- Градиент указывает направление наискорейшего возрастания функции.  \n",
    "- В задачах оптимизации (например, при обучении нейронных сетей) мы идём в обратном направлении (против градиента), чтобы **уменьшать** функцию потерь.  \n",
    "\n",
    "**4. Методы оценки (вычисления) градиента**  \n",
    "1. **Аналитический (символьный) расчёт**  \n",
    "   - Если функция задана в удобном для математики виде, можно вывести формулу для градиента вручную.  \n",
    "   - В машинном обучении такое редко делается вручную для больших моделей, но концептуально это возможно.  \n",
    "\n",
    "2. **Автоматическое дифференцирование (автодиф / autodiff)**  \n",
    "   - Это ключевой метод в популярных фреймворках типа TensorFlow или PyTorch.  \n",
    "   - Он автоматически строит граф вычислений и по нему вычисляет точные градиенты.  \n",
    "   - Очень удобен, так как не нужно вручную выводить формулу для производной.  \n",
    "\n",
    "3. **Численное дифференцирование (например, метод конечных разностей)**  \n",
    "   - Идея в том, что можно приблизительно оценить производную, слегка меняя входные параметры и смотря, как меняется значение функции.  \n",
    "   - Например, можно вычислить $\\frac{f(x + \\epsilon) - f(x - \\epsilon)}{2\\epsilon}$ (центральная разностная схема) для оценки производной по $x$.  \n",
    "   - Этот метод простой, но при большой размерности или слишком маленьком/большом $\\epsilon$ может быть неточным или вычислительно дорогим.  \n",
    "\n",
    "4. **Стохастические методы / Методы с оценкой градиента по данным**  \n",
    "   - В задачах обучения моделей на больших данных обычно не считают точный градиент по всей выборке, а оценивают его по части данных (мини-батч).  \n",
    "   - Это ускоряет обучение, хотя добавляет «шум» в процесс, но этот шум иногда даже помогает «выпрыгивать» из локальных минимумов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66e20aa-f1e2-47a6-b72f-b063737dfb1b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Градиентный спуск, проблема выбора шага."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d2495-7999-4d41-aebe-4edb9abbe9aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "При обучении моделей с помощью градиентного спуска один из ключевых гиперпараметров — это **шаг обучения** (learning rate, $ \\alpha $). Его правильный выбор во многом определяет, насколько быстро и стабильно будет сходиться алгоритм.\n",
    "\n",
    "---\n",
    "\n",
    "### В чём проблема выбора шага обучения?\n",
    "\n",
    "1. **Слишком большой шаг**  \n",
    "   - Градиентные обновления могут «перепрыгивать» через минимум.  \n",
    "   - Алгоритм может даже вовсе не сойтись, а «скакать» вокруг или уходить в бесконечность.  \n",
    "\n",
    "2. **Слишком маленький шаг**  \n",
    "   - Сходимость становится очень медленной.  \n",
    "   - Модель может «застрять» на плоскостях или около седловых точек, затрачивая множество итераций на выход из «застоя».  \n",
    "\n",
    "3. **Разный масштаб признаков**  \n",
    "   - Если отдельные параметры (или признаки данных) на порядки отличаются по масштабу, то выбор одного шага для всех параметров может быть неэффективным. В этом случае обычно прибегают к методам адаптивной подстройки шага (например, Adam, RMSProp и т.д.).  \n",
    "\n",
    "   - Эти методы автоматически подстраивают шаг обучения для каждого параметра (каждого веса модели) на основе истории градиентов.  \n",
    "   - Например, **Adam** использует экспоненциально сглаженные средние значения градиента и его квадрата, чтобы «понимать», где обучение «стоит на месте», а где изменения сильные.  \n",
    "   - **Плюсы**: обычно более быстрая и стабильная сходимость «из коробки».  \n",
    "   - **Минусы**: появляется больше гиперпараметров (бета1, бета2 и т.д.), нужно аккуратно настраивать и иногда контролировать переобучение.  \n",
    "\n",
    "4. **Методы постобработки шага (learning rate scheduler)**  \n",
    "   - Многие фреймворки позволяют применять **scheduler**, который по определённому расписанию (например, каждые $n$ эпох или когда метрика на валидационной выборке не улучшается) уменьшает шаг обучения.  \n",
    "   - Часто используют «стратегию learning rate warm-up», когда сначала шаг небольшой, затем повышается, а после снова снижается — это может помочь модели «осторожно» стартовать, а затем быстрее обучаться на ранних итерациях.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f38ec6e-cf39-4ab4-b7ff-ae483d91efbe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Стохастический градиентный спуск."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32861c03-bcae-4245-94a1-8d7a84ceeb51",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Стохастический градиентный спуск (Stochastic Gradient Descent, SGD)** — это вариант градиентного спуска, в котором мы на каждом шаге берём не всю обучающую выборку для вычисления градиента, а **случайную часть данных** (мини-батч) или даже один случайный пример. \n",
    "\n",
    "---\n",
    "\n",
    "### Почему это нужно?\n",
    "\n",
    "1. **Классический градиентный спуск** (Batch Gradient Descent) вычисляет градиент на всей выборке.  \n",
    "   - Плюс: точная оценка градиента.  \n",
    "   - Минус: дорого и долго, особенно на больших наборах данных.\n",
    "\n",
    "2. **Стохастический градиентный спуск** (SGD) или **мини-батч SGD**:  \n",
    "   - Идея: на каждой итерации берём один пример (или небольшой пакет «мини-батч») для вычисления градиента.  \n",
    "   - Плюс: обучение идёт быстрее на практике (не ждём, пока пройдём через все данные).  \n",
    "   - Плюс: «шум» в оценке градиента иногда помогает «выбраться» из локальных минимумов.  \n",
    "   - Минус: оценка градиента может быть неточной — это шумит процесс обучения, и модель может скакать вокруг минимума.\n",
    "\n",
    "---\n",
    "\n",
    "### Как выглядит процесс?\n",
    "\n",
    "1. **Инициализируем** веса модели (случайным образом или каким-то другим способом).  \n",
    "2. **Случайно выбираем** один пример (или небольшой мини-батч) из обучающей выборки.  \n",
    "3. **Считаем функцию потерь** на этих выбранных данных.  \n",
    "4. **Вычисляем градиент** (производные потерь по параметрам).  \n",
    "5. **Обновляем параметры** модели, идя против градиента:  \n",
    "   $\n",
    "   w \\gets w - \\alpha \\cdot \\nabla L(w),\n",
    "   $\n",
    "   где $ w $ — параметры, $ \\alpha $ — шаг обучения, $ \\nabla L(w) $ — градиент на выбранных данных.  \n",
    "6. **Повторяем** шаги 2-5 много раз.  \n",
    "\n",
    "Обычно мы проходим **«эпохи»**: одна эпоха — это проход по **всей** обучающей выборке, «разбитой» на мини-батчи, после чего данные можно снова перемешать.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e749b-945f-454e-a02b-7aebe874e30b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Использование момента. Метод Нестерова."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256bd12-a034-4350-8e58-e13b9c816f0b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Использование «момента» (Momentum)** и **Метод Нестерова** — это улучшения стохастического градиентного спуска (SGD), которые помогают ускорить и стабилизировать процесс обучения, особенно в ситуациях, где есть «застревания» на плоскостях или резкие колебания обновлений.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Момент (Momentum)\n",
    "\n",
    "#### Идея\n",
    "В классическом стохастическом градиентном спуске мы просто смещаемся в направлении антиградиента:\n",
    "$\n",
    "    w \\gets w - \\alpha \\cdot \\nabla L(w).\n",
    "$\n",
    "\n",
    "Но если функция потерь имеет узкие «криволинейные долины» (что часто бывает), простой SGD может «колебаться», двигаясь то вперёд, то назад по этим долинам. **Momentum** (момент) даёт сглаживание этих колебаний.\n",
    "\n",
    "#### Как работает\n",
    "- Вводится переменная скорости (или импульса) $\\mathbf{v}$, которую обновляют по формуле:\n",
    "  $\n",
    "    \\mathbf{v}_{t+1} = \\beta \\, \\mathbf{v}_t + (1 - \\beta)\\,\\nabla L(w_t),\n",
    "  $\n",
    "  где $\\beta$ (обычно около 0.9) — коэффициент сглаживания.  \n",
    "- После этого веса обновляются с учётом скорости:\n",
    "  $\n",
    "    w_{t+1} = w_t - \\alpha \\, \\mathbf{v}_{t+1}.\n",
    "  $\n",
    "\n",
    "**Смысл**: если градиент в одном направлении повторяется несколько шагов подряд, $\\mathbf{v}$ накапливает импульс и «тянет» веса быстрее в нужную сторону. Если направление меняется, старая скорость постепенно затухает (умножается на $\\beta$, которое меньше 1).\n",
    "\n",
    "**Преимущества**:\n",
    "1. **Сглаживает колебания**: модель не так легко будет «метаться» из стороны в сторону.  \n",
    "2. **Ускоряет движение** в направлении «стабильного» градиента: если много шагов подряд градиент указывает в одну сторону, модель накапливает импульс и быстрее достигает минимума.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Метод Нестерова (Nesterov Accelerated Gradient, NAG)\n",
    "\n",
    "#### В чём отличие от обычного Momentum?\n",
    "\n",
    "В обычном Momentum мы сначала используем предыдущую скорость $\\mathbf{v}_t$, добавляем текущий градиент, и потом делаем шаг обновления. В методе Нестерова мы пытаемся «заглянуть» вперёд, куда нас приведёт импульс, и **там** оцениваем градиент.\n",
    "\n",
    "Другими словами, мы **предсказываем**, где окажемся за счёт предыдущего импульса, и именно в этой «предсказанной» точке смотрим градиент. Это помогает учесть, что вектор импульса может быть слишком большим или находиться не совсем там, где нужно.\n",
    "\n",
    "#### Формула (упрощённо)\n",
    "1. Сначала делаем «шаг предсказания» (look-ahead) по старому импульсу:\n",
    "   $\n",
    "     \\tilde{w} = w_t - \\beta \\, \\alpha \\, \\mathbf{v}_t\n",
    "   $\n",
    "   (мы «заглядываем», где будем, если применим накопленный импульс).\n",
    "2. Считаем градиент **в точке** $\\tilde{w}$:\n",
    "   $\n",
    "     \\nabla L(\\tilde{w})\n",
    "   $\n",
    "3. Обновляем импульс:\n",
    "   $\n",
    "     \\mathbf{v}_{t+1} = \\beta \\, \\mathbf{v}_t + (1 - \\beta)\\,\\nabla L(\\tilde{w})\n",
    "   $\n",
    "4. Обновляем веса уже с учётом нового импульса:\n",
    "   $\n",
    "     w_{t+1} = w_t - \\alpha \\, \\mathbf{v}_{t+1}.\n",
    "   $\n",
    "\n",
    "В итоге мы используем информацию о том, куда «тянет» импульс, прежде чем вычислять градиент. Это делает корректировку более точной и обычно улучшает сходимость по сравнению с «классическим» Momentum.\n",
    "\n",
    "---\n",
    "\n",
    "### Почему это работает лучше?\n",
    "\n",
    "- **Наблюдение**: в обычном Momentum мы берём градиент в точке $ w_t $, но фактически мы уже собираемся переместиться в точку $ w_t - \\beta\\alpha \\mathbf{v}_t $.  \n",
    "- **Метод Нестерова** говорит: «Сначала представим, что мы уже сделали этот шаг, **там** и посчитаем градиент, затем откорректируем движение».  \n",
    "\n",
    "За счёт этого получается более точное направление обновления. В результате — **быстрее сходимся** и меньше «перелётов» через минимум, чем с обычным импульсом."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd00921-6542-4dda-a428-adb9fe9bded4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Adagrad, Adadelta, RMSProp, Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e729386-74b5-4fba-8956-62bff5f797f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Адаптивные методы оптимизации в машинном обучении**\n",
    "\n",
    "Адаптивные методы оптимизации представляют собой усовершенствования классического стохастического градиентного спуска (SGD) с добавлением моментов и других техник. Эти методы адаптируют скорость обучения (шаг оптимизации) для каждого параметра модели индивидуально, что помогает справляться с различными масштабами и чувствительностью разных весов. Рассмотрим основные из них:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Adagrad**\n",
    "\n",
    "#### Идея\n",
    "Adagrad адаптирует скорость обучения для каждого параметра модели отдельно, основываясь на том, как часто этот параметр обновляется. Если параметр часто получает большие градиенты, его шаг обучения уменьшается. Если градиенты небольшие или редкие, шаг остается относительно большим.\n",
    "\n",
    "#### Как это работает\n",
    "Для каждого параметра ведется учет того, насколько сильно он изменялся в процессе обучения. Параметры, которые часто обновляются с большими изменениями, получают меньший шаг, что предотвращает их чрезмерное изменение. Параметры с менее активными обновлениями сохраняют больший шаг, что способствует их эффективному обучению.\n",
    "\n",
    "#### Плюсы и минусы\n",
    "- **Плюсы**:\n",
    "  - Хорошо работает с разреженными данными, где многие параметры редко обновляются.\n",
    "  - Автоматически настраивает шаг обучения для каждого параметра.\n",
    "  \n",
    "- **Минусы**:\n",
    "  - Со временем шаг обучения может стать слишком маленьким, что замедляет обучение и может привести к застреванию модели.\n",
    "  - Не подходит для задач, где требуется продолжительное обучение, так как шаг может не восстановиться.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Adadelta**\n",
    "\n",
    "#### Идея\n",
    "Adadelta разработан как улучшение Adagrad, чтобы решить проблему бесконечного уменьшения шага обучения. Вместо простого накопления всех прошлых градиентов, Adadelta использует экспоненциальное сглаживание, что позволяет шагу обучения оставаться стабильным.\n",
    "\n",
    "#### Как работает\n",
    "Adadelta хранит скользящее среднее квадратов градиентов, что позволяет учитывать только недавние изменения. Это предотвращает слишком быстрое уменьшение шага обучения и обеспечивает более устойчивое и гибкое обновление параметров.\n",
    "\n",
    "#### Плюсы и минусы\n",
    "- **Плюсы**:\n",
    "  - Устраняет проблему затухания шага обучения, характерную для Adagrad.\n",
    "  - Обеспечивает стабильные и устойчивые обновления параметров.\n",
    "  \n",
    "- **Минусы**:\n",
    "  - Требует настройки дополнительных параметров, что может усложнить процесс обучения.\n",
    "  - В некоторых случаях менее эффективен, чем другие методы, такие как RMSProp или Adam.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **RMSProp**\n",
    "\n",
    "#### Идея\n",
    "RMSProp развивает идеи Adagrad и Adadelta, используя экспоненциальное сглаживание для учета последних градиентов. Это позволяет поддерживать стабильный шаг обучения, независимо от накопленной истории градиентов.\n",
    "\n",
    "#### Как работает\n",
    "Метод RMSProp сохраняет скользящее среднее квадратов последних градиентов для каждого параметра. При обновлении параметров он использует это среднее для нормализации градиентов, что помогает избежать слишком больших или слишком маленьких шагов обучения.\n",
    "\n",
    "#### Плюсы и минусы\n",
    "- **Плюсы**:\n",
    "  - Эффективно работает на практике, особенно в рекуррентных нейронных сетях.\n",
    "  - Избегает проблемы бесконечного уменьшения шага обучения.\n",
    "  \n",
    "- **Минусы**:\n",
    "  - Требует тщательной настройки параметров, таких как коэффициент сглаживания.\n",
    "  - В некоторых случаях может приводить к нестабильным колебаниям, если параметры не оптимально настроены.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Adam (Adaptive Moment Estimation)**\n",
    "\n",
    "#### Идея\n",
    "Adam сочетает в себе преимущества методов Momentum и RMSProp, используя как среднее значение градиентов, так и их дисперсию. Это позволяет более точно и эффективно обновлять параметры модели.\n",
    "\n",
    "#### Как работает\n",
    "Adam хранит две экспоненциальные скользящие средние: одну для градиентов, другую для их квадратов. Эти средние используются для корректировки шага обучения, обеспечивая адаптивное и устойчивое обновление параметров. Метод также включает корректировку смещения, чтобы улучшить точность на ранних этапах обучения.\n",
    "\n",
    "#### Плюсы и минусы\n",
    "- **Плюсы**:\n",
    "  - Очень хорошо работает \"из коробки\" на различных задачах, включая глубокие нейронные сети.\n",
    "  - Обеспечивает стабильную и быструю сходимость.\n",
    "  - Менее требователен к настройке гиперпараметров, так как стандартные значения часто работают достаточно хорошо.\n",
    "  \n",
    "- **Минусы**:\n",
    "  - В некоторых случаях может переобучаться, если шаг обучения слишком велик.\n",
    "  - Может застревать в плоских минимумах или локальных оптимумах, если параметры не настроены правильно.\n",
    "  - В отдельных задачах классический SGD с подходящим моментом может обеспечить лучшее обобщение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf1e31b-46b2-4705-89a2-e48c960ceb4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# 2.\tЛинейная регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56515ab0-3620-403a-91b6-9d850b675770",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Постановка задачи линейной регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4db54-b620-41de-bef6-433f800434a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Линейная регрессия** — это базовый метод машинного обучения, который пытается найти **линейную** зависимость между входными признаками (факторами) и выходным значением (целевой переменной).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Идея задачи\n",
    "\n",
    "Мы хотим **предсказывать** некоторое число (например, цену квартиры, вес человека, прибыль фирмы и т.д.) по набору входных признаков. Допустим, у нас есть:\n",
    "\n",
    "- $x_1, x_2, \\dots, x_n$ — входные признаки (например, площадь квартиры, количество комнат, этаж и т.д.),\n",
    "- \\(y\\) — выход, то есть значение, которое мы хотим предсказывать (цена квартиры).\n",
    "\n",
    "В **линейной регрессии** мы предполагаем, что связь между $x$ и $y$ можно аппроксимировать **прямой** (в случае одного признака) или **гиперплоскостью** (в случае нескольких признаков) вида:\n",
    "\n",
    "$\n",
    "\\hat{y} = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_n x_n,\n",
    "$\n",
    "\n",
    "где $w_0, w_1, \\dots, w_n$ — искомые коэффициенты (веса), а $\\hat{y}$ — предсказанное моделью значение.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Формальная постановка задачи\n",
    "\n",
    "1. У нас есть набор обучающих данных (train set): \n",
    "   $\n",
    "   \\{(x^{(i)}, y^{(i)})\\}_{i=1}^m,\n",
    "   $\n",
    "   где $x^{(i)} = (x^{(i)}_1, \\dots, x^{(i)}_n)$ — вектор признаков для $i$-го объекта,  \n",
    "   $y^{(i)}$ — истинное значение (таргет) для $i$-го объекта,  \n",
    "   $m$ — общее число объектов в обучающей выборке.\n",
    "\n",
    "2. Мы хотим найти такие веса $w_0, w_1, ..., w_n$, чтобы **минимизировать** ошибку предсказаний. Чаще всего в линейной регрессии используют **среднеквадратичную ошибку** (MSE):\n",
    "\n",
    "$\n",
    "\\text{MSE}(w) = \\frac{1}{m} \\sum_{i=1}^m \\Bigl(\\hat{y}^{(i)} - y^{(i)}\\Bigr)^2 \n",
    "= \\frac{1}{m} \\sum_{i=1}^m \\Bigl(w_0 + w_1 x_1^{(i)} + \\dots + w_n x_n^{(i)} - y^{(i)}\\Bigr)^2.\n",
    "$\n",
    "\n",
    "3. В задаче линейной регрессии мы ищем **минимум** этой ошибки:\n",
    "\n",
    "$\n",
    "(w_0^*, w_1^*, \\dots, w_n^*) = \\arg\\min_{w_0, w_1, \\dots, w_n} \\text{MSE}(w).\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "  Для больших задач и в задачах, где добавляются регуляризации или нелинейные элементы, часто проще и эффективнее использовать **градиентный спуск**, двигаясь пошагово в сторону уменьшения MSE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1388f5-d924-4410-9b59-ab5888999b36",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Метод наименьших квадратов. Алгебраическое и оптимизационное решения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cfc26e-1401-418c-ad4e-ddbcab2366ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Ниже разберём **Метод наименьших квадратов** в контексте линейной регрессии — как он формально формулируется (оптимизационная постановка) и как получается **алгебраическое** решение (через «нормальные уравнения»).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Оптимизационная постановка\n",
    "\n",
    "Мы имеем выборку из $m$ объектов:\n",
    "$\n",
    "\\{(x^{(i)}, y^{(i)})\\}_{i=1}^m,\n",
    "$\n",
    "где $x^{(i)} = (x_1^{(i)}, x_2^{(i)}, \\dots, x_n^{(i)})$ — это $n$-мерный вектор признаков, и $y^{(i)}$ — целевой показатель (число).\n",
    "\n",
    "Ищем линейную модель вида:\n",
    "$\n",
    "\\hat{y}^{(i)} = w_0 + w_1 x_1^{(i)} + \\dots + w_n x_n^{(i)}.\n",
    "$\n",
    "\n",
    "Чтобы «подогнать» модель, хотим **минимизировать** суммарную квадратичную ошибку (Mean Squared Error, MSE). \n",
    "$\n",
    "\\text{MSE}(w) = \\sum_{i=1}^m \\Bigl(w_0 + w_1 x_1^{(i)} + \\dots + w_n x_n^{(i)} - y^{(i)}\\Bigr)^2.\n",
    "$\n",
    "\n",
    "**Задача**: найти вектор весов $\\mathbf{w} = (w_0, w_1, \\dots, w_n)$, который **минимизирует** эту функцию ошибки.  \n",
    "$\n",
    "\\mathbf{w}^* = \\arg \\min_{\\mathbf{w}} \\text{MSE}(\\mathbf{w}).\n",
    "$\n",
    "\n",
    "Это и есть **оптимизационная** постановка: мы сводим задачу подбора линейной регрессии к задаче **минимизации** функции потерь (MSE).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Алгебраическое решение (через нормальные уравнения)\n",
    "\n",
    "При условии, что матрица признаков «хорошо кондиционирована» (нет вырожденности) и размерность задачи сравнительно небольшая, существует **прямое решение**. Для удобства запишем задачу в матричном виде:\n",
    "\n",
    "1. $\\mathbf{X}$ — матрица размера $m \\times (n+1)$, где каждый объект — это строка $[1, x_1^{(i)}, x_2^{(i)}, ..., x_n^{(i)}]$. То есть мы считаем «1» отдельным признаком для $w_0$.  \n",
    "2. $\\mathbf{w} = (w_0, w_1, \\dots, w_n)^T$ — вектор весов размером $(n+1) \\times 1$.  \n",
    "3. $\\mathbf{y} = (y^{(1)}, y^{(2)}, \\dots, y^{(m)})^T$ — вектор целевых значений.\n",
    "\n",
    "Тогда предсказание для всей выборки:  \n",
    "$\n",
    "\\hat{\\mathbf{y}} = \\mathbf{X}\\mathbf{w}.\n",
    "$\n",
    "\n",
    "Функция ошибки (сумма квадратов отклонений) принимает вид:  \n",
    "$\n",
    "\\text{MSE}(\\mathbf{w}) = (\\mathbf{X}\\mathbf{w} - \\mathbf{y})^T(\\mathbf{X}\\mathbf{w} - \\mathbf{y}).\n",
    "$\n",
    "\n",
    "Если найти градиент этой ошибки по $\\mathbf{w}$ и приравнять к нулю, получим так называемые **нормальные уравнения**:\n",
    "$\n",
    "\\mathbf{X}^T \\mathbf{X} \\, \\mathbf{w} = \\mathbf{X}^T \\mathbf{y}.\n",
    "$\n",
    "\n",
    "При условии, что $\\mathbf{X}^T \\mathbf{X}$ обратима (нет линейно зависимых признаков и другие технические детали), решение:\n",
    "$\n",
    "\\mathbf{w}^* = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}.\n",
    "$\n",
    "\n",
    "Это и есть **алгебраическое** (точное) решение задачи наименьших квадратов.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Интерпретация\n",
    "\n",
    "- $\\mathbf{X}^T \\mathbf{X}$ — матрица, которая описывает взаимосвязи признаков между собой.  \n",
    "- $\\mathbf{X}^T \\mathbf{y}$ — вектор, который описывает, как связаны признаки с целевыми значениями.\n",
    "\n",
    "Решение $\\mathbf{w}^*$ — это такой вектор весов, который (в идеале) **точно** минимизирует суммарную квадратичную ошибку на обучающей выборке.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Связь с оптимизационной постановкой\n",
    "\n",
    "- **Алгебраическое решение** фактически получается из **оптимизационной** задачи, когда мы берём производную функции ошибки $\\text{MSE}$ по $\\mathbf{w}$ и решаем уравнение $\\nabla \\text{MSE}(\\mathbf{w}) = 0$.  \n",
    "- Для больших систем, где обращать $\\mathbf{X}^T \\mathbf{X}$ дорого или невозможно, используют **численные методы** (например, градиентный спуск). Но принцип **тот же**: пытаемся свести $\\text{MSE}(\\mathbf{w})$ к минимуму.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5753df2a-ab83-4a40-92d0-116b2514d8d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Ковариация, корреляция."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca559c1-8637-40aa-83a2-053d369ec77a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Ковариация** и **корреляция** — это два близких понятия, которые описывают, **как** связаны друг с другом две переменные (например, в контексте линейной регрессии — признаки между собой или признак и целевая переменная).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Ковариация\n",
    "\n",
    "- **Определение**: ковариация двух случайных величин $X$ и $Y$ — это среднее значение произведения отклонений $X$ и $Y$ от их средних:\n",
    "  $\n",
    "    \\mathrm{Cov}(X, Y) \\;=\\; \\mathbb{E}\\bigl[(X - \\mathbb{E}[X]) \\cdot (Y - \\mathbb{E}[Y])\\bigr].\n",
    "  $\n",
    "\n",
    "- **Интерпретация**:  \n",
    "  - Если $\\mathrm{Cov}(X, Y) > 0$, то $X$ и $Y$ имеют тенденцию меняться в **одну** сторону (когда $X$ растёт, $Y$ тоже растёт, и наоборот).  \n",
    "  - Если $\\mathrm{Cov}(X, Y) < 0$, то они связаны **обратной** зависимостью (рост $X$ сопровождается уменьшением $Y$).  \n",
    "  - Если $\\mathrm{Cov}(X, Y) \\approx 0$, то сильной линейной связи нет.  \n",
    "\n",
    "- **Измерение**: ковариация может принимать любые значения от $-\\infty$ до $+\\infty$. При этом её масштаб зависит от единиц измерения $X$ и $Y$. Например, если $X$ измеряется в километрах, а $Y$ — в рублях, то ковариация будет иметь измерение «км·рубль». Это затрудняет «прямое» сравнение ковариаций по разным наборам данных.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Корреляция\n",
    "\n",
    "- **Определение**: **корреляция Пирсона** (самая распространённая) — это нормированная ковариация:\n",
    "  $\n",
    "    \\mathrm{Corr}(X, Y) \\;=\\; \\frac{\\mathrm{Cov}(X, Y)}{\\sigma_X \\,\\sigma_Y},\n",
    "  $\n",
    "  где $\\sigma_X$ и $\\sigma_Y$ — стандартные отклонения $X$ и $Y$.\n",
    "\n",
    "- **Интерпретация**:  \n",
    "  - Принимает значения от $-1$ до $+1$.  \n",
    "  - $\\mathrm{Corr}(X, Y) = +1$ означает **идеальную прямую** связь: все точки лежат на одной прямой с положительным наклоном.  \n",
    "  - $\\mathrm{Corr}(X, Y) = -1$ — **идеальная обратная** связь: точки на прямой с отрицательным наклоном.  \n",
    "  - $\\mathrm{Corr}(X, Y) = 0$ — нет линейной зависимости (но могут быть нелинейные).  \n",
    "\n",
    "- **Почему это удобно**: так как мы делим на произведение стандартных отклонений, единицы измерения «сокращаются», и корреляцию можно интерпретировать без учёта шкал. Это позволяет напрямую сравнивать «силу» связи в разных задачах.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Применение в линейной регрессии\n",
    "\n",
    "- **Ковариация** и **корреляция** помогают понять:\n",
    "  - Насколько признак $x_j$ линейно связан с целевой переменной $y$. Сильная корреляция (по модулю близкая к 1) может означать, что признак хорошо объясняет часть вариации $y$.  \n",
    "  - Насколько признаки связаны между собой (т.н. мультиколлинеарность). Если два признака сильно коррелируют, в модели может возникнуть проблема нестабильности коэффициентов.  \n",
    "\n",
    "- **Коллинеарность (или мультиколлинеарность)**: если корреляция между двумя (или более) признаками очень высокая, то в матрице $\\mathbf{X}^T\\mathbf{X}$ могут возникать проблемы (она становится плохо обусловленной). Тогда метод наименьших квадратов даёт нестабильные решения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c6baa-97ed-4634-98ec-05b452d3e6fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Коэффициент детерминации ($R^2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490d1ddc-2d90-4c6c-8415-9d3558bddf37",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Коэффициент детерминации (R²)** — это показатель качества линейной регрессии (или другой регрессионной модели), который показывает, **какую долю** разброса (вариации) исходных данных удалось «объяснить» построенной моделью.\n",
    "\n",
    "---\n",
    "\n",
    "### Формальное определение\n",
    "\n",
    "Обозначим:\n",
    "- $y_i$ — реальные значения,\n",
    "- $\\hat{y}_i$ — предсказанные моделью значения,\n",
    "- $\\bar{y}$ — среднее реальных значений (среднее по всем $y_i$).\n",
    "\n",
    "Тогда:\n",
    "1. **Общая сумма квадратов** (total sum of squares, $SS_{\\text{tot}}$):\n",
    "   $\n",
    "   SS_{\\text{tot}} = \\sum_{i=1}^m (y_i - \\bar{y})^2.\n",
    "   $\n",
    "   Показывает, насколько сильно разбросаны исходные данные относительно их среднего.\n",
    "\n",
    "2. **Остаточная сумма квадратов** (residual sum of squares, $SS_{\\text{res}}$):\n",
    "   $\n",
    "   SS_{\\text{res}} = \\sum_{i=1}^m (y_i - \\hat{y}_i)^2.\n",
    "   $\n",
    "   Это «невязка» модели: насколько модель ошибается на каждом примере.\n",
    "\n",
    "3. **Коэффициент детерминации** (R²):\n",
    "   $\n",
    "   R^2 = 1 - \\frac{SS_{\\text{res}}}{SS_{\\text{tot}}}.\n",
    "   $\n",
    "\n",
    "---\n",
    "\n",
    "### Интерпретация\n",
    "\n",
    "- $R^2 = 1$ означает, что модель **идеально** предсказывает все значения (ошибка равна нулю).  \n",
    "- $R^2 = 0$ говорит, что модель предсказывает **не лучше**, чем просто среднее значение (то есть совсем не «учитывает» особенности данных).  \n",
    "- Если \\(R^2\\) **отрицательно**, значит модель даёт результат даже **хуже**, чем наивный прогноз средней (модель может быть совсем неподходящей для данных).\n",
    "\n",
    "Чем ближе $R^2$ к 1, тем лучше модель «объясняет» вариацию исходных данных. Однако стоит помнить, что **слишком высокое** $R^2$ может быть признаком **переобучения**, если модель чрезмерно подстраивается под обучающую выборку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b3d54-08aa-42fa-8fad-072ef6ace7b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Гомоскедастичность. Квартет Анскомба."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f578ba0-7420-4528-9aa7-dc96daa4c00e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Гомоскедастичность\n",
    "\n",
    "#### Определение\n",
    "- **Гомоскедастичность** (homoscedasticity) — это свойство данных (или модели), при котором **дисперсия остатков (ошибок) не зависит от значения независимых переменных**.  \n",
    "- Проще говоря, ошибки модели при разных значениях $x$ (или при разном уровне предсказания) имеют примерно одинаковую «амплитуду разброса».\n",
    "\n",
    "#### Пример в линейной регрессии\n",
    "- Допустим, мы строим линейную регрессию: $\\hat{y} = w_0 + w_1 x$.  \n",
    "- Если при маленьких $x$ отклонения (ошибки $\\hat{y} - y$) примерно те же, что и при больших $x$, то мы говорим о **гомоскедастичности**.  \n",
    "- Если же при возрастании $x$ ошибки становятся всё более «разбросанными» (дисперсия остатков растёт), то мы имеем **гетероскедастичность**.\n",
    "\n",
    "#### Почему это важно\n",
    "- В классическом МНК (методе наименьших квадратов) **предполагается** гомоскедастичность. Если она нарушена, то:\n",
    "  - Оценки коэффициентов $w_0, w_1, \\dots$ **останутся** состоятельными (то есть в среднем верными),  \n",
    "  - Но оценки дисперсии (а значит, доверительные интервалы и тесты значимости) могут быть искажены.  \n",
    "\n",
    "---\n",
    "\n",
    "### Квартет Анскомба\n",
    "\n",
    "#### Что это\n",
    "- **Квартет Анскомба** (Anscombe’s quartet) — это четыре разных набора данных из всего **11 точек** (примерно) в каждом, которые имеют **одинаковые**:\n",
    "  - Среднее $x$ и $y$,  \n",
    "  - Дисперсии $x$ и $y$,  \n",
    "  - Ковариацию (или корреляцию) между $x$ и $y$,  \n",
    "  - Одинаковую уравненную прямую (линейную регрессию).  \n",
    "- Но если их **построить на графиках**, то выглядят эти четыре набора **совершенно по-разному**.\n",
    "\n",
    "#### Главная идея\n",
    "- Одними **числовыми статистиками** (среднее, дисперсия, корреляция) нельзя исчерпывающе описать распределение данных.  \n",
    "- Квартет Анскомба показывает, насколько важно **визуализировать** данные, прежде чем слепо применять регрессию или делать выводы на основе только средних, корреляций и т.д.\n",
    "\n",
    "#### Примерно что в этих наборах\n",
    "1. Первый набор выглядит, как «адекватная» облачко точек, которое хорошо описывается прямой.  \n",
    "2. Второй набор выглядит более «криволинейно», хотя статистики те же.  \n",
    "3. Третий набор фактически это «совсем другая ситуация» — например, все точки лежат практически по прямой, кроме одной (явный выброс).  \n",
    "4. Четвёртый набор вообще практически все точки имеют одно и то же $x$, кроме одной, и опять же те же самые статистики."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3bc1f0-3e45-4020-8ec0-2b64b978d33c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Регуляризация LASSO, Ridge, Elastic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bcb76d-5053-4998-acfa-0ace7698b438",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "В линейной регрессии (и в других моделях) **регуляризация** нужна, чтобы модель не переобучалась и веса не «разлетались» на очень большие значения. Ниже разберём три популярных вида регуляризации:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Ridge (L2-регуляризация)\n",
    "\n",
    "#### Идея\n",
    "- Добавить к функции потерь (обычно MSE) **штраф** пропорционально сумме квадратов весов.  \n",
    "- Пусть наша обычная функция ошибки (MSE) в линейной регрессии:\n",
    "  $\n",
    "    \\text{MSE}(w) = \\frac{1}{m}\\sum_{i=1}^m (w_0 + w_1 x_1^{(i)} + \\ldots + w_n x_n^{(i)} - y^{(i)})^2.\n",
    "  $\n",
    "- С **Ridge-регуляризацией** к этой функции добавляется член:\n",
    "  $\n",
    "    \\alpha \\sum_{j=1}^n w_j^2,\n",
    "  $\n",
    "  где $\\alpha > 0$ — коэффициент регуляризации (иногда пишут $\\lambda$).\n",
    "\n",
    "- Таким образом, функция, которую мы минимизируем, становится:\n",
    "  $\n",
    "    \\text{MSE}(w) + \\alpha \\sum_{j=1}^n w_j^2.\n",
    "  $\n",
    "\n",
    "#### Эффект\n",
    "- Ridge «наказывает» большие по модулю веса, стремясь сделать их **как можно меньшими** (хотя не обязательно нулевыми).  \n",
    "- При $\\alpha > 0$ матрица $\\mathbf{X}^T \\mathbf{X} + \\alpha \\mathbf{I}$ становится лучше обусловленной, что помогает при мультиколлинеарности.  \n",
    "- Коэффициенты сокращаются, но обычно **не обнуляются** (Ridge редко даёт нулевые веса).\n",
    "\n",
    "#### Плюсы и минусы\n",
    "- **Плюсы**:  \n",
    "  - Сглаживает переобучение, особенно когда много коррелированных признаков.  \n",
    "  - Уменьшает дисперсию оценок.  \n",
    "- **Минусы**:  \n",
    "  - Не зануляет веса, значит не помогает «выбирать» ограниченное число признаков явно (все признаки остаются в игре).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Lasso (L1-регуляризация)\n",
    "\n",
    "#### Идея\n",
    "- Аналогично Ridge, но вместо суммы квадратов весов мы добавляем **сумму модулей** весов:\n",
    "  $\n",
    "    \\text{MSE}(w) + \\alpha \\sum_{j=1}^n |w_j|.\n",
    "  $\n",
    "\n",
    "#### Эффект\n",
    "- Благодаря свойству абсолютного значения Lasso может «продавливать» некоторые веса в **строгий ноль**.  \n",
    "- Это значит, что Lasso может одновременно быть средством и регуляризации, и отбора признаков (feature selection).  \n",
    "\n",
    "#### Плюсы и минусы\n",
    "- **Плюсы**:\n",
    "  - Явно «обнуляет» часть весов, что уменьшает число признаков (может упростить модель).  \n",
    "  - Часто лучше работает в ситуациях, когда среди множества признаков лишь некоторые действительно важны (разреженные решения).  \n",
    "- **Минусы**:\n",
    "  - Может быть нестабильным (разные части выборки могут занулять разные признаки).  \n",
    "  - Для высококоррелированных признаков Lasso зачастую «выбирает» только один из группы коррелированных, остальные обнуляет.  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Elastic Net\n",
    "\n",
    "#### Идея\n",
    "- **Elastic Net** сочетает в себе и L1, и L2-регуляризации:  \n",
    "  $\n",
    "    \\text{MSE}(w) + \\alpha \\Bigl( \\rho \\sum_{j=1}^n |w_j| + (1 - \\rho) \\sum_{j=1}^n w_j^2 \\Bigr).\n",
    "  $\n",
    "- Здесь $\\alpha$ — общий коэффициент регуляризации, а $\\rho$ (от 0 до 1) задаёт «пропорцию» между L1 и L2.\n",
    "\n",
    "#### Эффект\n",
    "- Берёт **лучшее** от обеих методов: L1 компоненту (зануление весов) и L2 компоненту (сглаживание и борьба с мультиколлинеарностью).  \n",
    "- При $\\rho = 1$ мы имеем чистый Lasso, при $\\rho = 0$ — чистый Ridge, а между этими значениями — компромисс.\n",
    "\n",
    "#### Когда применяют\n",
    "- Когда данные содержат много признаков, среди которых, возможно, несколько коррелированы, а некоторые незначимы. Elastic Net может сохранять группу коррелированных признаков вместе (не выталкивая все, кроме одного, в ноль), но при этом позволяет занулять действительно ненужные признаки."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8235703b-4309-4814-afd6-17385e2f51ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# 3.\tГенетический алгоритм."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45e69244-36e6-46d5-9a00-655f2850c988",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Многопараметрическая оптимизация. Доминантность и оптимальность по Парето."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b6b7ccc-6ca6-4bc9-b13d-d0ac24d8ebf8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "При **многопараметрической (многокритериальной) оптимизации** мы пытаемся улучшить **несколько** различных целей (критериев) одновременно. Например, можно хотеть максимизировать производительность и при этом минимизировать энергопотребление. Часто улучшение одного критерия приводит к ухудшению другого. \n",
    "\n",
    "В **генетических алгоритмах** (ГА) это решается путём поддержания «популяции» решений и использования идей **доминантности** и **оптимальности по Парето**.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Многокритериальная оптимизация\n",
    "\n",
    "Представим, что у нас есть две (или более) функции, которые мы хотим оптимизировать одновременно:\n",
    "\n",
    "$\n",
    "f_1(x), \\quad f_2(x), \\quad \\dots, \\quad f_k(x).\n",
    "$\n",
    "\n",
    "- Задача может быть, например, **минимизировать** все эти функции.  \n",
    "- Часто оказывается, что **нет** единственного решения, которое делает все критерии оптимальными сразу.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Доминантность и оптимальность по Парето\n",
    "\n",
    "#### 2.1 Доминирование (dominance)\n",
    "\n",
    "Пусть у нас есть два решения (особи) $A$ и $B$. Говорят, что **$A$ доминирует $B$**, если по **всем** критериям $A$ не хуже (то есть не имеет больших значений, если минимизируем) и по **хотя бы одному** — строго лучше.\n",
    "\n",
    "Если $A$ не доминирует $B$ и $B$ не доминирует $A$, говорят, что они **не сравнимы** (incomparable) по доминированию.\n",
    "\n",
    "#### 2.2 Оптимальность по Парето\n",
    "\n",
    "- **Парето-оптимальное** решение — это решение, которое **никто** не доминирует.  \n",
    "- Если решение не «забивает» никакое другое решение сразу по всем критериям, оно называется **эффективным по Парето**.  \n",
    "- **Парето-фронт** (Pareto front) — множество всех парето-оптимальных (не доминируемых) решений в пространстве критериев.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Генетические алгоритмы для многокритериальной оптимизации\n",
    "\n",
    "В классическом ГА мы имеем одну функцию приспособленности (fitness). В многокритериальном случае нужно **учитывать сразу несколько**.\n",
    "\n",
    "#### 3.1 Идея\n",
    "\n",
    "1. Генетический алгоритм хранит **популяцию** особей (решений).  \n",
    "2. Для каждой особи мы имеем набор значений критериев $ (f_1, f_2, \\dots, f_k)$.  \n",
    "3. Вместо классического «рейтинга», мы используем **понятие доминирования**:  \n",
    "   - Особь, которая **не доминируется** никакой другой особью в популяции, имеет **высокий приоритет** для сохранения (она «Парето-оптимальна» внутри данной популяции).  \n",
    "   - Если особь доминируется другой, она менее ценна.\n",
    "\n",
    "#### 3.2 Пример алгоритма: NSGA-II, SPEA2, и т.д.\n",
    "\n",
    "Существует несколько методов многокритериальной оптимизации на базе ГА, например:  \n",
    "- **NSGA-II (Non-dominated Sorting Genetic Algorithm II)**,  \n",
    "- **SPEA2 (Strength Pareto Evolutionary Algorithm 2)**.  \n",
    "\n",
    "Общая схема:\n",
    "1. **Отбор (selection)** с учётом доминирования: особи, не доминируемые в популяции, считаются более «плодовитыми».  \n",
    "2. **Сортировка** по нескольким «фронтам»: сначала выделяют фронт парето-оптимальных (не доминируемых) решений, затем рассматривают оставшихся (второй фронт), и т.д.  \n",
    "3. **Скрещивание и мутация** проходят, как в обычном ГА, но при выборе родителей и при формировании новой популяции учитывают ранг по фронту Парето (и, возможно, **разнообразие** — чтобы решения не слипались в одном месте).\n",
    "\n",
    "#### 3.3 Результат\n",
    "\n",
    "ГА постепенно эволюционирует к набору решений, которые формируют всё более «хороший» **Парето-фронт** в пространстве критериев. В конце работы мы получаем **целый набор** компромиссных решений, и можем вручную выбрать то, которое нам подходит (например, баланс между «расходом топлива» и «мощностью двигателя»)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1dc78181-6387-40e4-8c27-d2a1c9f16ab6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Функция качества (fitness)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a7717f6-76e2-445c-a8ff-2200eca32080",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Функция качества (fitness function)** в контексте **генетических алгоритмов (ГА)** — это функция, которая оценивает, «насколько хорошим» (приспособленным) является каждое потенциальное решение (особь) к задаче, которую мы пытаемся решить.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Роль функции качества в ГА\n",
    "\n",
    "1. **Отбор**:  \n",
    "   - Генетический алгоритм на каждом шаге (итерации) стремится «сберечь» или «чаще воспроизводить» особей с **лучшим** (большим) значением функции качества.  \n",
    "   - Особей с **низким** значением fitness чаще исключают или реже используют при формировании нового поколения.\n",
    "\n",
    "2. **Обратная связь**:  \n",
    "   - Функция качества — единственный «сигнал», который говорит алгоритму, насколько решения продвинулись к цели.  \n",
    "   - Если fitness большой (или маленький — зависит от постановки задачи), значит решение качественное; если низкий — решение слабое.\n",
    "\n",
    "3. **Эволюционное давление**:  \n",
    "   - Благодаря селекции по функции качества, популяция решений постепенно эволюционирует, улучшаясь по целевому критерию.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Как задаётся функция качества\n",
    "\n",
    "1. **Однокритериальные задачи**:  \n",
    "   - Обычно берем **целевую функцию**, которую мы хотим **максимизировать** (например, прибыль). Если задача формулируется на минимум (например, минимум затрат), то часто берут $\\text{fitness} = -\\text{функция}$ или преобразуют так, чтобы fitness рос при улучшении решения.\n",
    "\n",
    "2. **Многокритериальные задачи** (см. оптимальность по Парето):  \n",
    "   - Можно свести все критерии к одной функции (например, взять взвешенную сумму), но это не всегда удобно, т.к. теряется часть информации.  \n",
    "   - В современных ГА (NSGA-II, SPEA2 и т.п.) часто используют **неявное** определение «качества» через **доминантность**: не доминируемые решения считаются более «приспособленными», а внутри них дополнительно оценивают «разнообразие» (distance-based) или ранг по фронту Парето.\n",
    "\n",
    "3. **Специальные трюки**:  \n",
    "   - Иногда вводят штрафы (penalties) за нарушения ограничений, чтобы решение с нарушением резко теряло фитнес.  \n",
    "   - Иногда выделяют бонусы за желательные черты решения (например, компактность, гладкость и т.д.).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Требования к функции качества\n",
    "\n",
    "- **Однозначность**: должны чётко понимать, что большее (или меньшее) значение говорит о «лучшем» решении.  \n",
    "- **Скорость вычисления**: ГА многократно рассчитывает fitness для множества особей, поэтому важно, чтобы вычисление не было слишком дорогим.  \n",
    "- **Отражение цели**: Функция должна действительно учитывать все аспекты задачи (цели, ограничения), иначе ГА будет эволюционировать «не туда».  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bc36e70-8786-4019-be5c-1cf8956045a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Общая идея генетического алгоритма."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98e26b03-6615-4036-8fd4-57ec0af7f91d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Генетический алгоритм (ГА) — это эвристический метод оптимизации и поиска решений, который **подражает процессу естественной эволюции**. Его ключевая идея — поддерживать **популяцию** потенциальных решений и, через отбор и «эволюцию» (скрещивание и мутацию), постепенно улучшать качество этих решений.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Общая схема генетического алгоритма\n",
    "\n",
    "1. **Инициализация**  \n",
    "   - Генерируется **начальная популяция** возможных решений (обычно случайно или с учётом каких-то эвристик).  \n",
    "\n",
    "2. **Оценка (вычисление фитнеса)**  \n",
    "   - Для каждого решения в популяции рассчитывается **функция качества (fitness)**, показывающая, насколько хорошо это решение решает поставленную задачу.  \n",
    "\n",
    "3. **Отбор (selection)**  \n",
    "   - Выбираются решения с более высоким фитнесом (т. е. лучшие) для размножения.  \n",
    "   - Могут использоваться разные схемы отбора: турнирный, рулеточный (пропорционально фитнесу) и др.  \n",
    "\n",
    "4. **Операторы «эволюции»**  \n",
    "   1. **Скрещивание (crossover)**: берём две «родительские» особи и комбинируем их «гены» (части решения) в одну или две «потомка».  \n",
    "   2. **Мутация**: в новом потомке случаются **случайные изменения** (ошибки копирования генов) — небольшие рандомные изменения параметров решения.  \n",
    "\n",
    "5. **Формирование новой популяции**  \n",
    "   - Потомки (и, возможно, часть родителей) заполняют новую популяцию.  \n",
    "   - Старые, наименее успешные решения могут удаляться (или оставаться с малой вероятностью).  \n",
    "\n",
    "6. **Повтор**  \n",
    "   - Продолжаем с шага «Оценка» и далее, пока не достигнем критериев остановки (например, достигли заданного уровня качества или истекло время/число поколений).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Преимущества и недостатки\n",
    "\n",
    "#### Преимущества\n",
    "- **Гибкость**: не требует гладкости или выпуклости целевой функции, не обязательно иметь хорошую производную.  \n",
    "- **Глобальный поиск**: скрещивание и мутация позволяют «перепрыгивать» через локальные минимумы.  \n",
    "- **Универсальность**: можно применять к очень разным типам задач (числовым, дискретным, многокритериальным), достаточно лишь уметь кодировать решение и вычислять фитнес.  \n",
    "\n",
    "#### Недостатки\n",
    "- **Не гарантирует** нахождение глобального оптимума.  \n",
    "- **Высокая вычислительная сложность**: нужно многократно оценивать большое число особей, особенно если фитнес-счётчик дорог.  \n",
    "- **Гиперпараметры** (размер популяции, вероятность скрещивания, мутации и др.) надо аккуратно подбирать под задачу."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "530d4b7a-5a29-45fc-a77b-36f594ea86c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Представление особи."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7524f90c-821d-442c-873b-a7e6c0fd605f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "---\n",
    "\n",
    "### 1. Бинарная (двоичная) кодировка\n",
    "\n",
    "- **Что это**: решение представляется в виде **битовой строки** (например,$010110...$).  \n",
    "- **Как применяют**:  \n",
    "  - Если решение — набор числовых параметров, то каждый параметр можно закодировать отдельным набором бит.  \n",
    "  - Если задача комбинаторная, элементы решения иногда отражаются соответствующими битами.  \n",
    "- **Плюсы**: очень простая реализация операторов скрещивания (обмен подстроками битов) и мутации (flip бита).  \n",
    "- **Минусы**: иногда такая кодировка может быть «неестественной» и трудно интерпретируемой для задачи.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Числовая (вещественная) кодировка\n",
    "\n",
    "- **Что это**: решение представляется **массивом действительных чисел** (например, $[x_1, x_2, \\dots, x_n]$).  \n",
    "- **Как применяют**:  \n",
    "  - Чаще для непрерывных задач оптимизации или настроек гиперпараметров (где естественно иметь вещественные веса).  \n",
    "- **Плюсы**: мутацию можно сделать как добавление маленького шума к компонентам вектора, скрещивание — как смешивание координат.  \n",
    "- **Минусы**: нужно аккуратно определять масштабы шума, чтобы эволюция не «развалилась» или не застряла.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Перестановки\n",
    "\n",
    "- **Что это**: особь — это **перестановка** чисел (например, $[3, 1, 4, 2]$).  \n",
    "- **Где нужно**: задачи, где решение — это порядок обхода или распределения (популярный пример: задача коммивояжёра).  \n",
    "- **Операторы**:  \n",
    "  - Скрещивание: специальным образом объединяют порядок от двух «родителей» (частично упорядоченное кроссовер, цикл-кроссовер и др.).  \n",
    "  - Мутация: меняем местами пару элементов или сдвигаем участок.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Структурные кодировки (деревья, грамматики)\n",
    "\n",
    "- **Что это**: решение может быть деревом (как в **генетическом программировании**, где узлы дерева — функции/операторы, листья — константы/переменные) или иной более сложной структурой.  \n",
    "- **Зачем**: когда задача требует найти, например, **программу**, выражение или архитектуру нейросети.  \n",
    "- **Особенности**:  \n",
    "  - Скрещивание: подмена ветвей деревьев.  \n",
    "  - Мутация: перестройка поддеревьев."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0797af65-2f22-4c86-8c8b-f3edee78ad9d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Методы селекции: пропорционально качеству, stochastic universal sampling, с наследием, турнирная, элитизм."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6a25193-e207-4069-89f2-f6819de1a6c5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "---\n",
    "\n",
    "### 1. Пропорционально качеству (Roulette Wheel)\n",
    "\n",
    "#### Идея\n",
    "- Каждой особи приписывается «сектор на колесе рулетки», пропорциональный её фитнесу (чем выше фитнес, тем больше сектор).  \n",
    "- «Крутим рулетку» (случайная выборка), и особи с более высоким фитнесом имеют большую вероятность быть выбраны.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Stochastic Universal Sampling (SUS)\n",
    "\n",
    "#### Идея\n",
    "- Улучшенная версия «пропорциональной селекции», где мы выбираем сразу несколько особей «равномерно» по рулетке.  \n",
    "- Воображаем рулетку, в которой особи расположены пропорционально своим фитнесам. Затем выбираем **равномерно** несколько стрелок (точек) на рулетке (дискреты через одинаковый интервал), что даёт более «регулярную» выборку.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. С наследием (скользящая шкала)\n",
    "\n",
    "#### Идея (Scaling)\n",
    "- В классическом методе пропорциональной селекции, когда есть одна «супер-особь» с фитнесом, намного превышающим остальных, она может «захватить» почти всю популяцию.  \n",
    "- Чтобы этого избежать, применяют различные **преобразования фитнеса** (напр., линейное или логарифмическое «скейлирование»).  \n",
    "\n",
    "Пример — **линейное скейлирование** (Linear Scaling):\n",
    "$\n",
    "f'_i = a \\cdot f_i + b,\n",
    "$\n",
    "где $f_i$ — исходный фитнес особи $i$, а $f'_i$ — скорректированный фитнес. Параметры $a$ и $b$ подбираются так, чтобы контролировать влияние «сильных» особей и давать шанс «средним».\n",
    "\n",
    "**Смысл**: сгладить разницу между лучшими и средними, избежав ранней стагнации.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Турнирная селекция (Tournament Selection)\n",
    "\n",
    "#### Идея\n",
    "1. Случайно выбираем **несколько** (tournament size) особей из популяции.  \n",
    "2. Смотрим, у кого из них фитнес больше (или меньше, если задача на минимум).  \n",
    "3. Победитель «турнира» (или 1–2 лучших, в зависимости от настроек) попадает в новую популяцию.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Элитизм (Elitism)\n",
    "\n",
    "#### Идея\n",
    "- Гарантирует, что **лучшая особь** (или несколько лучших) **обязательно** перейдут в следующее поколение **без изменений**.  \n",
    "- Это делается для того, чтобы не потерять «уже найденное» хорошее решение из-за случайной мутации или отбора.\n",
    "\n",
    "#### Как реализовать\n",
    "- На каждом шаге сохраняем несколько лучших особей (1, 2, 5 и т.д.) сразу в новую популяцию. Остальные места в новой популяции заполняются стандартным способом (скрещивание, мутация).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fbb57dc-3ce4-4944-9eef-d49861488f43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Методы кроссовера: 1,2,k-точечный, равномерный, для перестановок."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd3bd698-6bdf-4dd3-ad69-193fcb7b556c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Кроссовер (скрещивание)** в генетическом алгоритме — это оператор, который берёт «родительские» решения и порождает «потомков», комбинируя части генетического материала (кодировки) родителей. Способ реализации кроссовера зависит от того, в каком формате (кодировке) представлены особи.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. 1-точечный кроссовер (one-point crossover)\n",
    "\n",
    "#### Идея\n",
    "1. Считаем, что каждый родитель представлен как **одномерная последовательность** (например, бинарная строка, массив чисел).  \n",
    "2. Случайно выбираем **одну точку** разреза (позицию) в этой строке.  \n",
    "3. Потомок 1: берём «левую часть» (от начала до точки) от Родителя A и «правую часть» (от точки до конца) от Родителя B.  \n",
    "4. Потомок 2 (если нужно): наоборот, «левую часть» от Родителя B и «правую часть» от Родителя A.\n",
    "\n",
    "#### Пример (бинарный)\n",
    "- Родитель A: `000|1111`  \n",
    "- Родитель B: `101|0100`  \n",
    "  - Разрез после 3-го символа:  \n",
    "  - Потомок 1: `0000100`  \n",
    "  - Потомок 2: `1011111`\n",
    "\n",
    "---\n",
    "\n",
    "### 2. 2-точечный кроссовер (two-point crossover)\n",
    "\n",
    "#### Идея\n",
    "1. Выбираем **две** точки разреза.  \n",
    "2. Потомок 1: берём **участок** между этими точками (включительно или как договоримся) от Родителя B, а всё остальное от Родителя A.  \n",
    "3. Потомок 2 — зеркально наоборот.\n",
    "\n",
    "#### Пример (бинарный)\n",
    "- Родитель A: `000|111|1000`  \n",
    "- Родитель B: `101|010|0101`  \n",
    "  - Срезы после 3-го и 6-го символов.  \n",
    "  - Потомок 1: `000(010)1000`  \n",
    "  - Потомок 2: `101(111)0101`\n",
    "\n",
    "#### Отличие от 1-точечного\n",
    "- Больше возможностей для «перемешивания» родительских частей, т.к. теперь обмениваемся **центральным сегментом** (или двумя сегментами, в зависимости от реализации).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. k-точечный кроссовер\n",
    "\n",
    "#### Идея\n",
    "- **Обобщение** 1- и 2-точечных методов.  \n",
    "- Задаём $k$ точек разреза (позиций) и чередуем фрагменты родителей в итоге.\n",
    "\n",
    "#### Пример\n",
    "Если $k = 3$, у нас будет что-то вроде:  \n",
    "- Потомок: `[A:0..p1] [B:p1..p2] [A:p2..p3] [B:p3..end]`.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Равномерный кроссовер (uniform crossover)\n",
    "\n",
    "#### Идея\n",
    "- Вместо точек разреза, на **каждой позиции** (гене) **случайно** определяем, из какого родителя мы берём ген.  \n",
    "- Для каждой позиции (бита, элемента массива) подбрасываем «монетку» с вероятностью 0.5 (или иной). Если «орёл» — берём из Родителя A, если «решка» — из Родителя B.\n",
    "\n",
    "#### Пример (бинарный)\n",
    "- Родитель A: `0 0 0 1 1 0 1 1`  \n",
    "- Родитель B: `1 0 1 0 1 1 0 0`  \n",
    "- Монетка: `A B B A A B A B` (случайная последовательность)  \n",
    "  - Потомок = `[0 0 1 1 1 1 1 0]`\n",
    "---\n",
    "\n",
    "### 5. Кроссовер для перестановок\n",
    "\n",
    "Когда особь (решение) представлена **перестановкой** (например, $[3,1,4,2]$ — порядок городов в задаче коммивояжёра), обычные точечные методы могут порождать «неправильные» потомки (дублирование элементов или пропуск некоторых элементов). Поэтому нужны специальные кроссоверы.\n",
    "\n",
    "#### 5.1 PMX (Partially Mapped Crossover)\n",
    "\n",
    "1. Выбираем **два** разреза (как при 2-точечном) → выделяем участок.  \n",
    "2. **Обмениваем** этот участок между родителями.  \n",
    "3. Создаём «отображение» (mapping), чтобы «переопределить» конфликтующие элементы.  \n",
    "   - Иначе говоря, если в одном потомке повторился элемент, мы заменяем его согласно сформированной карте сопоставлений.\n",
    "\n",
    "> PMX гарантирует, что в результате потомок остаётся **корректной перестановкой**, без дублирования.\n",
    "\n",
    "#### 5.2 OX (Order Crossover)\n",
    "\n",
    "1. Снова выбираем **два** разреза.  \n",
    "2. Копируем «средний сегмент» из Родителя A в Потомка 1 на ту же позицию.  \n",
    "3. Заполняем оставшиеся слоты элементами из Родителя B **в исходном порядке**, пропуская те, которые уже взяты из A.\n",
    "\n",
    "> OX сохраняет относительный порядок элементов Родителя B за пределами скопированного сегмента.\n",
    "\n",
    "#### 5.3 CX (Cycle Crossover)\n",
    "\n",
    "1. Поиск «циклов» в перестановках.  \n",
    "2. Элементы из одного цикла берём из Родителя A, следующий цикл — из Родителя B, и так далее.\n",
    "\n",
    "> CX сохраняет **позиции** тех элементов, которые входят в один цикл перестановки.\n",
    "\n",
    "#### Выбор метода\n",
    "- **PMX** популярен в задачах типа коммивояжёра.  \n",
    "- **OX** сохраняет порядок, что бывает важно, если сущности в перестановке имеют смысл «идти друг за другом».\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e557d60f-49f8-4089-af78-cec29e27147d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Мутация. Влияние на скорость обучения."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47910720-4f4d-487c-9005-762f39830487",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Мутация** — это оператор генетического алгоритма (ГА), который вносит **случайные изменения** в генотип (кодировку) особи. Её ключевая роль — поддерживать **разнообразие** (вариацию) в популяции, чтобы алгоритм не «залипал» в локальном оптимуме и имел возможность исследовать новые области пространства решений.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Идея мутации\n",
    "\n",
    "1. В классическом **бинарном** представлении мутация обычно значит «инвертировать» один или несколько случайных битов с некой **небольшой** вероятностью.  \n",
    "2. В **вещественном** (числовом) представлении мутация может означать добавление **случайного шума** (например, гауссовского) к компонентам вектора.  \n",
    "3. В **перестановочном** кодировании мутация может быть, например, «поменять местами две позиции», «случайно сдвинуть блок» и т.д.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Влияние на скорость обучения\n",
    "\n",
    "#### 2.1 Поддержка «поиска» (exploration)\n",
    "\n",
    "- **Без мутации** популяция может слишком быстро стабилизироваться (все особи становятся очень похожими), и ГА не сможет «вырваться» из локального экстремума.  \n",
    "- **Мутация** вносит «шум»: особь может перескочить в новое «пространство» решений. Это увеличивает шансы найти лучшие варианты, если текущее решение далеко от глобального оптимума.\n",
    "\n",
    "#### 2.2 Риск «разрушения» (exploitation vs exploration)\n",
    "\n",
    "- Если **вероятность мутации** слишком велика, то хорошие решения могут «ломаться» и их потомки не унаследуют качественный генетический материал. В этом случае ГА может «топтаться на месте», не успевая аккумулировать улучшения.  \n",
    "- Если **вероятность мутации** слишком мала, популяция может «слишком сойтись» (все особи становятся практически одинаковыми), и алгоритм перестаёт эффективно исследовать пространство.\n",
    "\n",
    "#### 2.3 Баланс\n",
    "\n",
    "- Оптимальный уровень мутации — **компромисс** между «сохранением» (exploitation) и «исследованием» (exploration).  \n",
    "- На ранних стадиях эволюции обычно нужно больше «шума» (исследовать), а на поздних — меньше (точнее дорабатывать найденные решения). Поэтому иногда применяют **адаптивную** мутацию:  \n",
    "  - Снижать вероятность мутации по мере роста поколения,  \n",
    "  - Или менять её в зависимости от разнообразия популяции."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "748c92ac-2e23-4663-9a87-3a1e4a9a3420",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Управление популяцией. Сегрегация, старение, распараллеливание."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab6bc16f-2627-443e-8833-d50e3a71e8bd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "---\n",
    "\n",
    "### 1. Сегрегация (разделение на подпопуляции)\n",
    "\n",
    "#### Идея\n",
    "- Вместо одной «большой» популяции используют несколько **подпопуляций** (или «островов», «ниш»).  \n",
    "- Каждая подпопуляция эволюционирует **почти независимо**, с периодическим (или редким) обменом особями между ними.\n",
    "\n",
    "#### Зачем это нужно\n",
    "1. **Избежать преждевременной сходимости**: если вся популяция «слиплась» в одну область пространства решений, ГА может застрять в локальном минимуме. Сегрегация даёт шанс одной из подпопуляций «избежать» плохой точки и найти более хороший путь.  \n",
    "2. **Исследовать разные гипотезы параллельно**: каждая подпопуляция может иметь свои параметры (разный оператор кроссовера, разную вероятность мутации и т.п.).  \n",
    "3. **Поддерживать разнообразие** за счёт редких миграций («миграция» лучших особей из одной подпопуляции в другую).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Старение (aging)\n",
    "\n",
    "#### Идея\n",
    "- Каждой особи приписывают некоторый **«возраст»**. С каждым поколением особь «стареет». Когда достигается максимальный возраст, особь выбывает из популяции независимо от её фитнеса.  \n",
    "- Либо (другой вариант) особи, пережившие достаточное число поколений без улучшения, удаляются, освобождая место для новых.\n",
    "\n",
    "#### Зачем это нужно\n",
    "1. **Избежать застоя**: высокоприспособленные (но уже «устаревшие») особи не будут бесконечно передавать гены, удерживая популяцию в районе одного локального оптимума.  \n",
    "2. **Обеспечить поступление «свежей крови»**: даже если решение хорошее, мы иногда хотим убрать его из популяции, чтобы дать шанс другим направлениям эволюции.  \n",
    "3. **Контролировать размер популяции**: механизм старения может быть частью стратегии «сколько особей мы храним». \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Распараллеливание (parallelization)\n",
    "\n",
    "#### Идея\n",
    "- Генетические алгоритмы изначально хорошо подходят для **параллельных** вычислений, потому что:\n",
    "  1. Вычисление фитнеса каждой особи — независимая задача (можно считать на отдельных процессорах).  \n",
    "  2. Популяцию можно разделить на подпопуляции, каждая эволюционирует «на своём узле» (см. Island Model).  \n",
    "  3. Операторы кроссовера и мутации тоже можно распараллелить, если популяция большая.\n",
    "\n",
    "#### Подходы\n",
    "1. **Уровень особи**: каждый фитнес считаем параллельно; актуально, если сама функция фитнеса дорогая.  \n",
    "2. **Уровень подпопуляции (island model)**: на каждом узле своя подпопуляция, иногда пересылаем «мигрантов» (лучшие особи) на другие узлы.  \n",
    "3. **Fine-grained parallel GA**: когда взаимодействуют только «близкие» особи (сетка, тор и другой topology). Применяется реже, но даёт гибкую параллелизацию.\n",
    "\n",
    "\n",
    "#### Модели\n",
    "- **Кооперативная модель**: Подзадачи решаются параллельно, а результаты объединяются.\n",
    "\n",
    "- **Островная модель**: Каждая машина отвечает за свой \"остров\". Миграция особей происходит через сеть.\n",
    "\n",
    "- **Модель распределённой оценки**: Оценка приспособленности отдельных особей выполняется параллельно.\n",
    "\n",
    "\n",
    "#### Плюсы\n",
    "- **Ускорение** эволюции за счёт параллельного вычисления фитнеса.  \n",
    "- **Лучшее исследование** пространства, если использовать независимые острова с разной конфигурацией ГА.  \n",
    "\n",
    "#### Минусы\n",
    "- Тратим ресурсы на передачу данных (особей) между узлами (если Island Model).  \n",
    "- Сложность реализации и администрирования кластеров."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8281c154-dc87-41b2-9e46-164d945c1fb9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# 4.\tОбобщённые линейные модели."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba33586b-a675-430d-bd7e-f3dd571ee9a6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Сигмоида и логит."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4ded4ce-553b-4169-8ba2-7bcf1d324e47",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Обобщённые линейные модели** (Generalized Linear Models, GLM) — это общее семейство моделей, куда входят линейная регрессия, логистическая регрессия, пуассоновская регрессия и др. Их общая идея:  \n",
    "1. Имеется **линейная предикция** $ \\eta = w_0 + w_1 x_1 + \\dots + w_n x_n $.  \n",
    "2. С помощью **функции связи** (link function) мы связываем эту линейную предикцию $\\eta$ со средним значением отклика $\\mu$.  \n",
    "\n",
    "В **логистической регрессии** (частный случай GLM) функция связи — это **логит** (logit), а обратная функция связи — это **сигмоида** (sigmoid).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Сигмоида (логистическая функция)\n",
    "\n",
    "**Сигмоидой** (logistic function) называют функцию вида:\n",
    "\n",
    "$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}.\n",
    "$\n",
    "\n",
    "- **Значения** $\\sigma(z)$ лежат в диапазоне $(0, 1)$.  \n",
    "- При $z \\to +\\infty$ $\\sigma(z) \\to 1$, при $z \\to -\\infty$ $\\sigma(z) \\to 0$.  \n",
    "- График имеет характерную «S-образную» форму.\n",
    "\n",
    "В задаче **логистической регрессии** мы делаем предположение, что вероятности «успеха» (класса «1») связаны с линейной предикцией $\\eta$ именно через сигмоиду:\n",
    "\n",
    "$\n",
    "P(y = 1 \\mid x) = \\sigma(\\eta) = \\sigma(w_0 + w_1 x_1 + \\dots + w_n x_n).\n",
    "$\n",
    "\n",
    "Таким образом, выход модели интерпретируется как вероятность, а сигмоида «сжимает» любое действительное число в диапазон $(0;1)$.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Логит (логистическая функция связи)\n",
    "\n",
    "**Логит** (logit) — это **обратная** функция к сигмоиде:\n",
    "\n",
    "$\n",
    "\\text{logit}(p) = \\ln\\!\\Bigl(\\frac{p}{1 - p}\\Bigr).\n",
    "$\n",
    "\n",
    "- Если $p = \\sigma(z)$, тогда $\\text{logit}(p) = z$.  \n",
    "- Логит переводит число из диапазона $(0,1)$ в $(-\\infty, +\\infty)$.  \n",
    "- В рамках **GLM** логит-функция — это «функция связи», которая связывает вероятность $p$ с линейной комбинацией признаков $\\eta$:\n",
    "  $\n",
    "    \\eta = \\ln \\Bigl(\\frac{p}{1-p}\\Bigr).\n",
    "  $\n",
    "\n",
    "#### Зачем это нужно?\n",
    "- Модель говорит, что **логарифм отношения шансов** (odds) — это линейная функция от $x$.  \n",
    "- В классической линейной регрессии мы бы сказали: $y = \\beta_0 + \\beta_1 x$. Но для вероятности (которая должна лежать от 0 до 1) удобнее работать не напрямую с $p$, а с $\\ln(p/(1-p))$, чтобы обойтись без нелинейных ограничений.  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Логическая связь в логистической регрессии\n",
    "\n",
    "В контексте обобщённых линейных моделей:\n",
    "1. **Среднее** $\\mu$ (в случае классификации — это вероятность $p$ события «1») связано с линейной предикцией $\\eta$ через функцию связи:  \n",
    "   $\n",
    "   \\eta = g(\\mu),\n",
    "   $\n",
    "   где $g$ — функция связи (логит).\n",
    "2. Обратная связь (или **инверсная** функция связи) даёт $\\mu = g^{-1}(\\eta)$, которая и есть **сигмоида**:\n",
    "   $\n",
    "   \\mu = \\sigma(\\eta).\n",
    "   $\n",
    "\n",
    "Для логистической регрессии:\n",
    "$\n",
    "\\mu = p = \\sigma(\\eta) = \\frac{1}{1 + e^{-\\eta}}, \n",
    "\\quad \n",
    "\\eta = \\ln \\Bigl(\\frac{p}{1-p}\\Bigr).\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Почему именно сигмоида / логит?\n",
    "\n",
    "- **Интерпретируемость**: $\\ln(\\frac{p}{1-p})$ — это логарифм шансов (odds). Линейная зависимость шансов от $x$ часто оказывается удобной и «естественной» моделью.  \n",
    "- **Гибкость**: при большом количестве признаков (или нелинейных преобразованиях) логистическая регрессия всё ещё даёт понятную вероятность."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4ddf219-41d9-4240-bc66-86fc0fb5bd3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Метод наибольшего правдоподобия."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6641e815-68f5-4d4a-b55b-5d26473f5c63",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Метод наибольшего правдоподобия (Maximum Likelihood Estimation, MLE)** — это фундаментальный подход в статистике и машинном обучении для оценки параметров модели. Основная идея метода заключается в том, чтобы выбрать такие параметры модели, при которых наблюдаемые данные наиболее вероятны. Другими словами, мы стремимся найти параметры, которые \"наилучшим образом объясняют\" имеющиеся данные.\n",
    "\n",
    "---\n",
    "### Общая идея\n",
    "\n",
    "Представьте, что у нас есть набор данных, состоящий из пар объектов и их соответствующих меток или результатов. Например, в задаче классификации у нас есть множество объектов с признаками и их принадлежностью к определенным классам. Модель, которую мы строим, имеет определенные параметры (например, веса в логистической регрессии), и она задает вероятность того, что объект принадлежит к тому или иному классу.\n",
    "\n",
    "**Правдоподобие** — это мера того, насколько вероятно наблюдать именно такие данные при заданных параметрах модели. Метод наибольшего правдоподобия заключается в поиске таких параметров, при которых правдоподобие всех наблюдаемых данных максимально.\n",
    "\n",
    "**Почему это важно?** Максимизируя правдоподобие, мы выбираем те параметры модели, которые делают наши наблюдения наиболее вероятными, тем самым улучшая способность модели точно предсказывать новые данные.\n",
    "\n",
    "---\n",
    "### Пример: Логистическая регрессия\n",
    "\n",
    "Рассмотрим пример с логистической регрессией, которая используется для задач бинарной классификации (например, определить, является ли электронное письмо спамом или нет).\n",
    "\n",
    "**Как работает модель:**\n",
    "- Для каждого объекта (например, письма) модель вычисляет вероятность того, что он принадлежит к определенному классу (например, спам).\n",
    "- Эти вероятности зависят от весов модели, которые мы хотим определить.\n",
    "\n",
    "**Задача MLE:**\n",
    "- Мы хотим подобрать такие веса модели, чтобы вероятность правильной классификации всех обучающих объектов была максимальной.\n",
    "- Это означает, что модель должна \"наиболее точно\" предсказывать классы для всех обучающих примеров.\n",
    "\n",
    "**Почему используется логарифм правдоподобия?**\n",
    "- Вместо того чтобы умножать вероятности для всех объектов (что может привести к очень маленьким числам и затруднить вычисления), мы берем логарифм правдоподобия. Это превращает произведение вероятностей в сумму, что упрощает процесс оптимизации.\n",
    "- Таким образом, задача сводится к максимизации суммы логарифмов вероятностей, что эквивалентно максимизации исходного правдоподобия.\n",
    "\n",
    "---\n",
    "### Практическое применение\n",
    "\n",
    "На практике метод наибольшего правдоподобия часто используется в сочетании с различными алгоритмами оптимизации, такими как градиентный спуск. Эти алгоритмы помогают эффективно находить параметры модели, которые максимизируют правдоподобие.\n",
    "\n",
    "Например, в логистической регрессии мы можем использовать алгоритм градиентного спуска для итеративного обновления весов модели таким образом, чтобы сумма логарифмов вероятностей правильных классификаций увеличивалась.\n",
    "\n",
    "**Преимущества MLE:**\n",
    "- **Интуитивная понятность**: Метод основан на простой идее максимизации вероятности наблюдаемых данных.\n",
    "- **Широкое применение**: Используется в разнообразных моделях и задачах.\n",
    "- **Теоретическая обоснованность**: MLE обладает хорошими статистическими свойствами, такими как состоятельность и асимптотическая нормальность.\n",
    "\n",
    "**Недостатки MLE:**\n",
    "- **Чувствительность к выбору модели**: Если модель плохо описывает данные, MLE может привести к некачественным оценкам параметров.\n",
    "- **Вычислительная сложность**: Для сложных моделей и больших наборов данных оптимизация может быть ресурсоёмкой.\n",
    "- **Неустойчивость к выбросам**: Аномальные данные могут сильно влиять на оценку параметров."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c9d411b-9225-4898-8179-fa1a18ba871c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Логистическая регрессия. Вариант для меток -1, 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7fb4ea39-7543-4cf8-96e2-55f544f53249",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### 1. Классический вариант: Метки классов 0 и 1\n",
    "\n",
    "#### Основная идея\n",
    "\n",
    "В задачах бинарной классификации часто используется представление классов с метками 0 и 1. Например, в задаче определения, является ли электронное письмо спамом (1) или нет (0).\n",
    "\n",
    "#### Как работает модель\n",
    "\n",
    "Модель предсказывает вероятность принадлежности объекта к одному из классов. Для каждого объекта модель оценивает вероятность того, что он принадлежит к классу 1 (например, спаму). Эта вероятность зависит от набора параметров модели, которые мы стремимся определить.\n",
    "\n",
    "#### Функция потерь\n",
    "\n",
    "Для обучения модели мы стремимся максимизировать вероятность правильной классификации всех обучающих объектов. Это означает, что мы хотим, чтобы модель присваивала высокие вероятности правильным классам и низкие вероятности неправильным. Для этого используется логарифмическая функция потерь, которая за неправильные предсказания. Чем ближе предсказанная вероятность к реальной метке класса, тем ниже потери.\n",
    "\n",
    "**Пример: Логистическая регрессия**\n",
    "\n",
    "В логистической регрессии модель оценивает вероятность того, что объект принадлежит к классу 1, используя сигмоидальную функцию. Если объект действительно принадлежит к классу 1, модель получает положительный вклад в функцию правдоподобия, если к классу 0 — отрицательный. Цель состоит в том, чтобы максимизировать общее правдоподобие всех данных, что эквивалентно минимизации суммы логистических потерь.\n",
    "\n",
    "---\n",
    "### 2. Вариант с метками -1 и +1\n",
    "\n",
    "#### Как работает модель\n",
    "\n",
    "В этом случае модель всё ещё оценивает вероятность принадлежности объекта к одному из классов, но интерпретирует метки как -1 и +1. Положительное значение означает принадлежность к одному классу, а отрицательное — к другому. Это позволяет модели использовать одну и ту же сигмоидальную функцию для обоих классов, адаптируя её в зависимости от знака метки.\n",
    "\n",
    "#### Функция потерь\n",
    "\n",
    "При использовании меток -1 и +1 функция потерь также направлена на максимизацию правдоподобия правильной классификации. Однако, для удобства вычислений, предсказания модели комбинируются с метками классов, что позволяет использовать единый подход для обоих классов. Это упрощает формулы и делает их более универсальными.\n",
    "\n",
    "**Преобразование функции потерь**\n",
    "\n",
    "Для удобства и стабильности вычислений функция потерь может быть преобразована в более удобную форму, например, через логистическую ошибку или кросс-энтропию. Это позволяет использовать эффективные алгоритмы оптимизации для обучения модели, минимизируя потери и улучшая точность классификации.\n",
    "\n",
    "\n",
    "#### 2.3 Интуиция\n",
    "\n",
    "- Если $y_i = +1$, то мы хотим, чтобы $w^T x_i$ было **большим** положительным числом (тогда $\\exp(-\\,(+1)\\cdot w^T x_i)$ будет маленьким, а лог мал).  \n",
    "- Если $y_i = -1$, то мы хотим, чтобы $w^T x_i$ было **большим** отрицательным числом (тогда $-1 \\times w^T x_i$ становится большим положительным, и опять же экспонента стремится к малому).  \n",
    "- Таким образом, минимизируя $\\ln(1 + \\exp(-\\,y_i \\, w^T x_i))$, мы «толкаем» скалярное произведение $w^T x_i$ в правильном направлении в зависимости от знака $y_i$.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Как перейти от $\\{-1, +1\\}$ к $\\{0, 1\\}$ или наоборот\n",
    "\n",
    "Если в задаче или в реализации фреймворка изначально предполагаются метки $\\{0,1\\}$, но у нас данные $\\{-1, +1\\}$ (или наоборот), мы можем **преобразовать** их:\n",
    "\n",
    "- $\\{-1, +1\\} \\to \\{0,1\\}$: \n",
    "  $\n",
    "    y_{\\{0,1\\}} = \\frac{y_{\\{-1,+1\\}} + 1}{2}.\n",
    "  $\n",
    "  (если $y = -1$, получится 0; если $y = +1$, получится 1).\n",
    "\n",
    "- $\\{0,1\\} \\to \\{-1, +1\\}$:\n",
    "  $\n",
    "    y_{\\{-1,+1\\}} = 2 \\cdot y_{\\{0,1\\}} - 1.\n",
    "  $\n",
    "\n",
    "Это чисто «техническая» замена для удобства алгоритма. В итоге, логистическая регрессия остаётся **тем же самым** методом, меняется лишь способ обозначения классов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d4a5185-fb2d-4487-9473-20a752eaf6d8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Функции связи. Регрессия Пуассона."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6ba92e8-0bb8-48c7-acb8-3fa415241fc0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Регрессия Пуассона (Poisson Regression)** — это специализированный метод анализа данных, используемый для моделирования количественных данных, представляющих собой количество событий, происходящих за определённый промежуток времени или пространство. Например, это может быть количество звонков в службу поддержки за день или количество посещений веб-сайта за час.\n",
    "\n",
    "### 2. Пуассоновская регрессия\n",
    "\n",
    "#### 2.1 Распределение\n",
    "\n",
    "В **регрессии Пуассона** предполагается, что количество событий, которое мы хотим предсказать, следует Пуассоновскому распределению. Это означает, что события происходят независимо друг от друга, и их среднее количество зафиксировано для заданных условий.\n",
    "\n",
    "#### 2.2 Функция связи\n",
    "\n",
    "Для обеспечения того, чтобы предсказанные значения количества событий были всегда положительными, используется логарифмическая функция связи. Это позволяет моделировать ожидаемое количество событий как экспоненциальную функцию от линейной комбинации признаков. Такая связь делает модель гибкой и способной учитывать мультипликативные эффекты признаков на количество событий.\n",
    "\n",
    "#### Интерпретация в модели\n",
    "\n",
    "В Пуассоновской регрессии ожидаемое количество событий увеличивается экспоненциально с увеличением значения линейной комбинации признаков. Это означает, что небольшие изменения в признаках могут приводить к значительным изменениям в предсказанном количестве событий.\n",
    "\n",
    "---\n",
    "### 3. Функция правдоподобия и оценка параметров\n",
    "\n",
    "**Функция правдоподобия** отражает вероятность наблюдения данных при заданных параметрах модели. В Пуассоновской регрессии мы стремимся найти такие параметры, которые делают наши наблюдаемые данные наиболее вероятными.\n",
    "\n",
    "#### Процесс оценки параметров:\n",
    "\n",
    "1. **Сбор данных**: Имеем набор наблюдений, каждое из которых включает количество событий и соответствующие признаки.\n",
    "\n",
    "2. **Построение модели**: Модель связывает среднее количество событий с признаками через логарифмическую функцию связи.\n",
    "\n",
    "3. **Максимизация правдоподобия**: Используя метод наибольшего правдоподобия, находим параметры модели, которые максимизируют вероятность наблюдения имеющихся данных. Это часто достигается с помощью методов оптимизации, таких как градиентный спуск.\n",
    "\n",
    "---\n",
    "### 4. Зачем «лог-связь»?\n",
    "\n",
    "**Логарифмическая функция связи** играет ключевую роль в Пуассоновской регрессии по нескольким причинам:\n",
    "\n",
    "1. **Гарантия положительных предсказаний**: Логарифм позволяет преобразовать линейную комбинацию признаков так, чтобы результат всегда был положительным. Это естественно для счётных данных, где количество событий не может быть отрицательным.\n",
    "\n",
    "2. **Мультипликативные эффекты признаков**: Использование логарифмической связи превращает изменения в признаках из аддитивных в мультипликативные. Это означает, что увеличение одного из признаков приводит к экспоненциальному увеличению ожидаемого количества событий, что часто соответствует реальным процессам.\n",
    "\n",
    "\n",
    "**Преимущества Регрессии Пуассона:**\n",
    "\n",
    "- **Подходит для счётных данных**: Идеально подходит для моделирования количества событий.\n",
    "- **Гибкость модели**: Позволяет учитывать различные влияния признаков на ожидаемое количество событий.\n",
    "- **Интерпретируемость**: Коэффициенты модели дают представление о том, как изменение признаков влияет на количество событий.\n",
    "\n",
    "**Недостатки Регрессии Пуассона:**\n",
    "\n",
    "- **Предположение о равенстве среднего и дисперсии**: В Пуассоновской регрессии предполагается, что среднее количество событий равно дисперсии, что не всегда соответствует реальным данным.\n",
    "- **Чувствительность к выбросам**: Аномальные значения могут сильно влиять на параметры модели.\n",
    "- **Не учитывает задержки или зависимости**: В реальных данных события могут быть зависимыми во времени или пространстве, что не учитывается стандартной Пуассоновской регрессией.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47003561-c107-4552-a6a1-a20067092771",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# 5.\tКластеризация."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f834944f-388c-48cf-b3fc-2fd8699b4f0b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Постановка задачи кластеризации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6b06c-b2be-4e6c-8a9f-2a914fe25d8a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Кластеризация** — это задача **разделения** (группировки) набора объектов на группы (кластеры) таким образом, чтобы **похожие** объекты оказывались в одном кластере, а **разные** — в разных. При этом никакой «правильной» разметки данных (как в обучении с учителем) у нас **нет**.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Что такое кластеризация?\n",
    "\n",
    "1. **Нет готовых меток** (классов). В отличие от задач классификации, где мы знаем, какой объект к какому классу относится, здесь у нас нет заранее определённых меток.  \n",
    "2. **Ищем структуру** в данных. Цель — найти некоторую структуру, закономерность в данных и группировать объекты с похожими признаками.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Формальная постановка задачи\n",
    "\n",
    "Пусть у нас есть:\n",
    "- Набор данных $\\{x^{(1)}, x^{(2)}, \\dots, x^{(m)}\\}$, где каждый $x^{(i)}$ — это вектор признаков (часто в $\\mathbb{R}^n$).  \n",
    "- Неизвестное количество или **ожидаемое** количество групп (кластеров), которое мы хотим получить (иногда это число задаётся, иногда нет).\n",
    "\n",
    "**Задача**:  \n",
    "- Разделить все объекты на подмножества (кластеры), чтобы объекты внутри одного кластера были **максимально похожи** (в смысле какой-то меры похожести или расстояния), а объекты из разных кластеров — максимально **отличались**.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Как это формализуют?\n",
    "\n",
    "Обычно вводят функцию расстояния $d(x^{(i)}, x^{(j)})$ или меру схожести $s(x^{(i)}, x^{(j)})$. Задача сводится к минимизации (или максимизации) некоторого **критерия кластеризации**. Классический пример — **k-means**:\n",
    "\n",
    "$\n",
    "\\min_{C_1,\\dots,C_k} \\sum_{j=1}^k \\sum_{x \\in C_j} \\| x - \\mu_j \\|^2,\n",
    "$\n",
    "где $C_j$ — это $j$-й кластер, а $\\mu_j$ — его «центр» (среднее по всем точкам кластера). Таким образом минимизируется разброс точек вокруг своих центров.\n",
    "\n",
    "Другие методы используют разные критерии (иерархические методы, плотностные методы типа DBSCAN и т.д.).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Итоги\n",
    "\n",
    "1. **Кластеризация** — метод обучения **без учителя**: мы не имеем готовых меток, а лишь структуру данных.  \n",
    "2. **Цель** — разбить объекты на кластеры так, чтобы объекты в одном кластере были «схожи» друг с другом, а объекты из разных кластеров — различались.  \n",
    "3. **Много подходов**: k-means, иерархические методы, DBSCAN, спектральная кластеризация и пр., в зависимости от типа данных и поставленной задачи.\n",
    "\n",
    "Таким образом, **задача кластеризации** — автоматически найти «естественные» группы (кластеры) в данных, не имея заранее информации о том, какие эти группы должны быть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cdfe76-e647-4398-97cf-8dd037678dbc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Метод k-средних (K-means). Выбор начального состояния."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59ea7f3-0c4e-4b87-a070-2b7ba9065002",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Метод k-средних (K-means)** — один из самых популярных алгоритмов кластеризации. Его цель — разбить данные на $k$ кластеров так, чтобы минимизировать суммарное квадратичное отклонение точек от центров (средних) кластеров. \n",
    "\n",
    "---\n",
    "\n",
    "### 1. Суть метода k-средних\n",
    "\n",
    "1. **Задаём** количество кластеров $k$.  \n",
    "2. **Инициализируем** центры (средние) кластеров (чаще всего случайным образом).  \n",
    "3. **Повторяем** до сходимости:\n",
    "   1. Распределяем каждую точку в кластер, чей центр ближе всего (по выбранной метрике, обычно — евклидово расстояние).  \n",
    "   2. Пересчитываем центр каждого кластера как среднее всех точек, попавших в этот кластер.  \n",
    "4. Останавливаемся, когда центры перестают меняться (или изменения становятся незначительными).\n",
    "\n",
    "Основная «тонкость» здесь — **шаг инициализации** центров (начального состояния).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Проблема выбора начального состояния\n",
    "\n",
    "- Если выбрать неудачные начальные центры случайным образом, алгоритм может быстро сойтись к **неоптимальному локальному минимуму**.  \n",
    "- В зависимости от размера и структуры данных, разные начальные состояния могут давать **различное** качество кластеризации.  \n",
    "\n",
    "#### 2.1 Рандомная инициализация (naive)\n",
    "\n",
    "1. Случайно **выбираем $k$ точек** из набора данных в качестве начальных центров (или случайно генерируем координаты в пределах объёма данных).  \n",
    "2. Запускаем стандартный цикл k-means.\n",
    "\n",
    "**Минус**: высока вероятность получить центры, которые не отражают реальной структуры данных (например, два центра могут оказаться «рядом», а какой-то регион останется без «представителя»).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Улучшенные способы инициализации\n",
    "\n",
    "#### 3.1 K-means++\n",
    "\n",
    "**Наиболее известный** и популярный способ инициализации — **k-means++**. Идея:  \n",
    "1. Случайно выбираем **один** центр из набора точек.  \n",
    "2. Далее **каждую** точку $x$ «взвешиваем» вероятностью, пропорциональной квадрату расстояния до ближайшего уже выбранного центра.  \n",
    "3. Случайным образом выбираем **следующий** центр из всех точек, где вероятность выбора точки $x$ тем выше, чем дальше эта точка от уже выбранных центров.  \n",
    "4. Повторяем, пока не выберем все $k$ центров.  \n",
    "\n",
    "**Преимущество**:  \n",
    "- Центры распределяются «распахано» по всему пространству, с наименьшей вероятностью оказываясь в одной области.  \n",
    "- Ускоряет сходимость и улучшает итоговое качество кластеризации на практике.\n",
    "\n",
    "#### 3.2 Распределённый k-means++\n",
    "\n",
    "Существует и **распределённая** версия k-means++ (иногда называют **k-means||**), используемая для больших данных. Но принцип тот же: «семя» центров стараются выбрать далеко друг от друга.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Другие техники инициализации\n",
    "\n",
    "- **Иерархический кластерный подход**: сначала применяют быстрый грубый иерархический метод (или метод density-based) для приблизительной группировки, а затем центры этих групп служат инициализацией для k-means.  \n",
    "- **Методы отбора «репрезентативных» точек**: например, взять точки с наибольшим «отклонением» от уже выбранных и т.д.  \n",
    "- **PCA-разбиение**: проецировать данные на главные компоненты и выбирать точки вдоль главных осей.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Практические советы\n",
    "\n",
    "1. **Используйте k-means++**: в большинстве реализаций библиотек (например, в scikit-learn) по умолчанию включена именно эта инициализация. Это даёт хороший баланс скорости и качества.  \n",
    "2. Если очень **большая** выборка, рассмотрите **k-means||** (распределённый алгоритм) или сделайте **сэмплинг** данных для инициализации.  \n",
    "3. **Несколько запусков**: иногда делают несколько перезапусков k-means с разными начальными состояниями (даже если это k-means++), выбирая потом решение с наименьшей суммарной ошибкой.  \n",
    "4. **Регулярно визуализируйте** результат (если размерность позволяет) и проверяйте логику кластеров. Алгоритм k-means чувствителен к выбросам, масштабированию признаков и т.п.\n",
    "\n",
    "---\n",
    "\n",
    "### Итоги\n",
    "\n",
    "- **Выбор начальных центров** в k-means — ключевой фактор, влияющий на качество и сходимость алгоритма.  \n",
    "- Простой **случайный выбор** часто приводит к плохим результатам.  \n",
    "- **k-means++** — стандарт де-факто для инициализации: он распределяет начальные центры с учётом расстояний, что даёт более стабильную и качественную кластеризацию.  \n",
    "- Можно также пробовать другие подходы (многократный перезапуск, иерархию, PCA и др.) в зависимости от задачи и объёма данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe01ad1-78e9-410d-97c4-9ec8fc4fcab4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Основная идея алгоритмов, основанных на плотности. Алгоритмы DBSCAN, OPTICS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac19377-4b11-4ca3-8df0-ced794e1bc6c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Алгоритмы кластеризации на основе плотности** (Density-based clustering) — это такие методы, в которых кластеры определяются как «области повышенной плотности» в пространстве признаков, разделённые между собой зонами низкой плотности. Самыми известными представителями являются **DBSCAN** и **OPTICS**.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Общая идея плотностной кластеризации\n",
    "\n",
    "1. Кластер понимается как **область**, в которой объекты (точки) «плотно упакованы».  \n",
    "2. Там, где плотность объектов низкая, считается, что происходит «разделение кластеров».  \n",
    "3. В отличие от k-means, не нужно задавать количество кластеров $k$ заранее. Алгоритм сам обнаруживает, сколько в данных «плотных» регионов.  \n",
    "4. Алгоритмы могут обнаруживать **кластер(ы) любой формы** (не только сферические) и выделять **выбросы** (точки, которые не принадлежат никакому кластеру).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. DBSCAN\n",
    "\n",
    "**DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** — один из самых популярных плотностных методов.\n",
    "\n",
    "#### 2.1 Идея алгоритма\n",
    "\n",
    "Параметры:\n",
    "- $\\epsilon$ (эпсилон): радиус соседства, внутри которого мы «считаем» точку близкой.  \n",
    "- $minPts$: минимальное число точек в радиусе $\\epsilon$, чтобы считать регион «достаточно плотным».\n",
    "\n",
    "Основные шаги:\n",
    "1. **Для каждой точки** смотрим её $\\epsilon$-окрестность (т.е. все точки, расстояние до которых $\\le \\epsilon$).  \n",
    "2. Если в этой окрестности **$\\ge minPts$** точек, то эта точка называется **ключевой** (core point).  \n",
    "3. Точки, которые лежат внутри $\\epsilon$-окрестности ключевой точки, принадлежат **тому же кластеру**, что и ключевая.  \n",
    "4. **Распространение кластера**: если есть несколько ключевых точек рядом, их кластеры сливаются.  \n",
    "5. Точки, которые не попали ни в одну $\\epsilon$-окрестность ключевой точки, объявляются **шумом** (выбросами), хотя они могут оказаться в $\\epsilon$-окрестности обычных (non-core) точек, но не образуют собственный кластер.\n",
    "\n",
    "#### 2.2 Преимущества и недостатки\n",
    "\n",
    "- **Плюсы**:\n",
    "  - Не нужно задавать число кластеров заранее.  \n",
    "  - Находит кластеры любой формы.  \n",
    "  - Выделяет шум (выбросы) отдельно.  \n",
    "\n",
    "- **Минусы**:\n",
    "  - Нужно подбирать $\\epsilon$ и $minPts$.  \n",
    "  - Если плотность сильно варьируется по разным областям пространства, «глобальный» $\\epsilon$ может быть неудачным (одни кластеры слишком плотно сгруппированы, другие — более рассеяны).  \n",
    "  - В высоких размерностях может становиться менее эффективным.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. OPTICS\n",
    "\n",
    "**OPTICS (Ordering Points To Identify the Clustering Structure)** — развитие идей DBSCAN, особенно для случаев, когда плотность разнородна в разных частях пространства.\n",
    "\n",
    "#### 3.1 Основная идея\n",
    "\n",
    "1. OPTICS не формирует кластеры «прямо», а формирует **упорядоченную последовательность** (reachability plot) всех точек, отражая, при какой «плотности» (или $\\epsilon$-радиусе) эти точки «соединяются» в кластеры.  \n",
    "2. Для каждой точки вычисляет **reachability distance** — мера того, насколько «легко» (какой минимальный $\\epsilon$ нужен) добраться от уже выбранной ключевой точки до текущей.  \n",
    "3. Получается упорядоченная последовательность точек по возрастанию этой «reachability distance».\n",
    "\n",
    "#### 3.2 Как формируются кластеры\n",
    "\n",
    "- Анализируя этот reachability plot, можно «отрезать» кластеры на разных уровнях плотности. То есть фактически OPTICS позволяет **автоматически находить разные кластеры** при разных значениях $\\epsilon$.  \n",
    "- OPTICS даёт более детальное описание структуры данных, в частности, когда плотность неоднородна (где-то нужно больше $\\epsilon$, чтобы объединить точки в кластер).\n",
    "\n",
    "#### 3.3 Преимущества и недостатки\n",
    "\n",
    "- **Плюсы**:\n",
    "  - Не нужно фиксировать одно $\\epsilon$. Алгоритм сам строит распределение reachability distances, из которого можно вычленить кластеры на разных масштабах плотности.  \n",
    "  - Лучше работает на данных с очень разной плотностью кластеров по сравнению с DBSCAN.  \n",
    "\n",
    "- **Минусы**:\n",
    "  - Реализация и понимание сложнее, чем у DBSCAN.  \n",
    "  - Результат требует дополнительного шага — анализа reachability plot, чтобы выделить конкретные кластеры.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Сравнение с другими методами кластеризации\n",
    "\n",
    "- **k-means**: требует заранее заданного $k$, предполагает «сферические» кластеры, не выделяет выбросы отдельно.  \n",
    "- **Иерархические**: строят дерево (дендрограмму), но не обязательно учитывают плотность как таковую.  \n",
    "- **Плотностные** (DBSCAN/OPTICS): не нужно задавать $k$, хороши для нелинейных форм кластеров, выделяют шум, но требуют выбора параметров плотности ($\\epsilon, minPts$) и могут быть сложны в высоких размерностях.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Краткий итог\n",
    "\n",
    "1. **Плотностная кластеризация** определяет кластеры как области высокой плотности, разделённые областями низкой плотности.  \n",
    "2. **DBSCAN**: простой и популярный подход, требующий двух параметров ($\\epsilon, minPts$). Даёт кластеры любой формы и выделяет «шум». Но может плохо работать, если плотность варьируется очень сильно по разным регионам пространства.  \n",
    "3. **OPTICS**: расширение DBSCAN, которое **динамически** учитывает разные масштабы плотности. Возвращает упорядоченную структуру (reachability plot), из которой можно выделять кластеры. Подходит для более сложных случаев, но требует более тонкой интерпретации.\n",
    "\n",
    "Таким образом, **DBSCAN** и **OPTICS** — важные инструменты для **кластеризации без необходимости заранее задавать количество кластеров**, особенно когда кластеры могут быть сложной формы и нужно также иметь возможность «отсеивать» выбросы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d00f6-003f-4f13-bf12-c99f2eaf2295",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# 6.\tМетод k ближайших соседей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719de082-7e73-4aec-8884-398da7a57129",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Базовая идея. Классификатор k-NN. Преимущества и недостатки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b132d3a-8426-4800-aceb-265e42da35cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Метод k ближайших соседей (k-Nearest Neighbors, k-NN)** — это один из самых простых и интуитивно понятных алгоритмов машинного обучения, используемый как для задач классификации, так и для регрессии.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Базовая идея\n",
    "\n",
    "**Метод k ближайших соседей** основывается на предположении, что **объекты, находящиеся близко друг к другу в пространстве признаков, имеют схожие характеристики** или принадлежат к одному классу. То есть, чтобы определить класс нового объекта, мы ищем **k** наиболее похожих (близких) объектов в обучающей выборке и на основе их классов делаем вывод о классе нового объекта.\n",
    "\n",
    "#### Ключевые моменты базовой идеи:\n",
    "\n",
    "- **Локальная зависимость**: Предполагается, что близкие по признакам объекты имеют схожие метки (классы).\n",
    "- **Не параметрический метод**: k-NN не делает предположений о распределении данных, что делает его гибким для различных типов задач.\n",
    "- **Простота реализации**: Метод легко реализовать и понять, не требует сложного обучения модели.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Классификатор k-NN\n",
    "\n",
    "#### Принцип работы классификатора k-NN:\n",
    "\n",
    "1. **Выбор параметра k**:\n",
    "   - Определяется число ближайших соседей, которое будет учитываться при классификации. Выбор k влияет на баланс между **переобучением** и **недообучением**.\n",
    "\n",
    "2. **Расчет расстояний**:\n",
    "   - Для нового объекта рассчитываются расстояния до всех объектов обучающей выборки. Наиболее часто используемые метрики расстояния:\n",
    "     - **Евклидово расстояние**:\n",
    "       $\n",
    "       d(x, y) = \\sqrt{\\sum_{i=1}^n (x_i - y_i)^2}\n",
    "       $\n",
    "     - **Манхэттенское расстояние**:\n",
    "       $\n",
    "       d(x, y) = \\sum_{i=1}^n |x_i - y_i|\n",
    "       $\n",
    "     - **Расстояние Минковского**, **Чебышёва** и др.\n",
    "\n",
    "3. **Поиск k ближайших соседей**:\n",
    "   - Выбираются **k** объектов обучающей выборки с наименьшими расстояниями до нового объекта.\n",
    "\n",
    "4. **Присвоение класса**:\n",
    "   - Для задачи **классификации** определяется класс, который чаще всего встречается среди **k** ближайших соседей (метод большинства голосов).\n",
    "   - Для задачи **регрессии** берется среднее значение целевой переменной среди **k** ближайших соседей.\n",
    "\n",
    "#### Пример работы классификатора k-NN:\n",
    "\n",
    "Предположим, у нас есть набор данных с двумя классами: **класс A** и **класс B**. Новый объект находится ближе к нескольким объектам класса A, чем к объектам класса B. Если k=3 и среди ближайших трех соседей два принадлежат классу A, а один — классу B, то новый объект будет отнесен к классу A.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Преимущества и недостатки\n",
    "\n",
    "#### Преимущества метода k-NN:\n",
    "\n",
    "1. **Простота и интуитивность**:\n",
    "   - Легко понять и реализовать.\n",
    "   - Не требует сложного этапа обучения модели.\n",
    "\n",
    "2. **Гибкость**:\n",
    "   - Может использоваться как для задач классификации, так и для регрессии.\n",
    "   - Поддерживает **много классов** без необходимости изменения алгоритма.\n",
    "\n",
    "3. **Не параметрический подход**:\n",
    "   - Не делает предположений о распределении данных, что позволяет применять его к широкому спектру задач.\n",
    "\n",
    "4. **Адаптивность**:\n",
    "   - Способен адаптироваться к сложным границам классов, поскольку основывается на локальных данных.\n",
    "\n",
    "#### Недостатки метода k-NN:\n",
    "\n",
    "1. **Высокая вычислительная сложность**:\n",
    "   - Для каждого нового объекта требуется вычислить расстояние до всех объектов обучающей выборки, что может быть ресурсоёмким при больших объёмах данных.\n",
    "\n",
    "2. **Проблема размерности**:\n",
    "   - В пространствах с высокой размерностью (много признаков) метод теряет эффективность из-за явления \"проклятия размерности\", когда расстояния между точками становятся менее информативными.\n",
    "\n",
    "3. **Зависимость от выбора параметра k**:\n",
    "   - Неправильный выбор k может привести к переобучению (слишком маленький k) или недообучению (слишком большой k).\n",
    "\n",
    "4. **Чувствительность к масштабированию признаков**:\n",
    "   - Разные масштабы признаков могут искажать расстояния. Поэтому часто требуется **нормализация** или **стандартизация** данных перед применением k-NN.\n",
    "\n",
    "5. **Необработанные выбросы**:\n",
    "   - Метод чувствителен к выбросам, поскольку они могут влиять на расстояния и, следовательно, на классификацию.\n",
    "\n",
    "6. **Требовательность к памяти**:\n",
    "   - Хранение всей обучающей выборки может быть проблематичным при больших объёмах данных.\n",
    "\n",
    "#### Способы преодоления недостатков:\n",
    "\n",
    "- **Использование эффективных структур данных** (например, деревья KD, Ball trees) для ускорения поиска ближайших соседей.\n",
    "- **Сокращение размерности** (например, с помощью PCA) для уменьшения эффекта \"проклятия размерности\".\n",
    "- **Выбор оптимального k** с помощью методов перекрёстной проверки.\n",
    "- **Предобработка данных**: нормализация, удаление выбросов и др.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4fdc46-4b59-42da-b691-6577bbf6865b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Кроссвалидация методом \"без одного\" (leave-one-out)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5595718d-eeec-4372-907d-e7ce78c34167",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Кросс-валидация методом \"без одного\" (Leave-One-Out Cross-Validation, LOOCV)** — это специфический вариант кросс-валидации, используемый для оценки производительности модели машинного обучения. В этом методе каждый объект из обучающей выборки поочередно используется в качестве **тестового** набора, а оставшиеся $m-1$ объектов — как **обучающая** выборка. Таким образом, проводится $m$ итераций обучения и тестирования.\n",
    "\n",
    "---\n",
    " \n",
    "### 1. Основная идея LOOCV\n",
    "\n",
    "**Кросс-валидация** — это метод оценки способности модели к обобщению на новых, невидимых данных. **Leave-One-Out Cross-Validation (LOOCV)** — это наиболее экстремальный случай k-fold кросс-валидации, где количество фолдов $k$ равно числу объектов в выборке.\n",
    "\n",
    "#### Шаги метода LOOCV:\n",
    "\n",
    "1. **Разделение данных**:\n",
    "   - Для обучающей выборки из $m$ объектов выбирается один объект в качестве **тестового** набора.\n",
    "   - Оставшиеся $m-1$ объектов формируют **обучающую** выборку.\n",
    "\n",
    "2. **Обучение модели**:\n",
    "   - Модель обучается на обучающей выборке из $m-1$ объектов.\n",
    "\n",
    "3. **Тестирование модели**:\n",
    "   - Обученная модель предсказывает класс или значение для единственного тестового объекта.\n",
    "   - Записывается ошибка предсказания.\n",
    "\n",
    "4. **Повторение**:\n",
    "   - Процесс повторяется для каждого из $m$ объектов, каждый раз выбирая новый объект в качестве тестового.\n",
    "\n",
    "5. **Итоговая оценка**:\n",
    "   - Рассчитывается средняя ошибка по всем итерациям, которая служит оценкой **общей производительности** модели.\n",
    "\n",
    "---\n",
    " \n",
    "### 2. Пример работы LOOCV\n",
    "\n",
    "Рассмотрим простой пример с обучающей выборкой из 3 объектов:\n",
    "\n",
    "- **Обучающая выборка**: $\\{A, B, C\\}$\n",
    "\n",
    "#### Итерации LOOCV:\n",
    "\n",
    "1. **Итерация 1**:\n",
    "   - **Тестовый объект**: A\n",
    "   - **Обучающая выборка**: $\\{B, C\\}$\n",
    "   - **Обучение**: Модель обучается на $\\{B, C\\}$\n",
    "   - **Тестирование**: Предсказывается класс для A\n",
    "   - **Запись ошибки**\n",
    "\n",
    "2. **Итерация 2**:\n",
    "   - **Тестовый объект**: B\n",
    "   - **Обучающая выборка**: $\\{A, C\\}$\n",
    "   - **Обучение**: Модель обучается на $\\{A, C\\}$\n",
    "   - **Тестирование**: Предсказывается класс для B\n",
    "   - **Запись ошибки**\n",
    "\n",
    "3. **Итерация 3**:\n",
    "   - **Тестовый объект**: C\n",
    "   - **Обучающая выборка**: $\\{A, B\\}$\n",
    "   - **Обучение**: Модель обучается на $\\{A, B\\}$\n",
    "   - **Тестирование**: Предсказывается класс для C\n",
    "   - **Запись ошибки**\n",
    "\n",
    "#### Итог:\n",
    "\n",
    "- **Средняя ошибка** = $\\frac{\\text{Ошибка}_1 + \\text{Ошибка}_2 + \\text{Ошибка}_3}{3}$\n",
    "\n",
    "---\n",
    " \n",
    "### 3. Преимущества LOOCV\n",
    "\n",
    "1. **Максимальное использование данных**:\n",
    "   - Каждый объект используется как для обучения, так и для тестирования, что особенно полезно при малых выборках.\n",
    "\n",
    "2. **Отсутствие перекрытия тестовых наборов**:\n",
    "   - Каждый тестовый набор содержит лишь один объект, исключая дублирование.\n",
    "\n",
    "3. **Бесконечная вариативность**:\n",
    "   - Модель оценивается на каждом возможном разделении данных, что даёт полную картину её производительности.\n",
    "\n",
    "4. **Отсутствие случайности**:\n",
    "   - В отличие от некоторых других методов кросс-валидации, результаты LOOCV детерминированы (при фиксированном порядке данных и отсутствии случайных операций внутри модели).\n",
    "\n",
    "---\n",
    " \n",
    "### 4. Недостатки LOOCV\n",
    "\n",
    "1. **Высокая вычислительная стоимость**:\n",
    "   - При больших выборках требуется обучить модель $m$ раз, что может быть ресурсоёмко и времязатратно.\n",
    "\n",
    "2. **Склонность к высокой вариативности оценки**:\n",
    "   - Хотя каждая итерация основана на практически полной выборке, оценка ошибки может быть подвержена сильным флуктуациям из-за влияния отдельных объектов.\n",
    "\n",
    "3. **Не всегда лучше, чем другие методы**:\n",
    "   - В некоторых случаях, например, при очень больших выборках, более эффективными могут оказаться другие формы кросс-валидации, такие как 5-fold или 10-fold, которые предлагают баланс между вычислительной эффективностью и точностью оценки.\n",
    "\n",
    "4. **Чувствительность к выбросам**:\n",
    "   - Один «непредставительный» объект может значительно влиять на итоговую оценку модели.\n",
    "\n",
    "---\n",
    " \n",
    "### 5. Сравнение с другими методами кросс-валидации\n",
    "\n",
    "| Метод               | Количество итераций | Использование данных | Вычислительная сложность | Оценка вариативности |\n",
    "|---------------------|----------------------|-----------------------|---------------------------|-----------------------|\n",
    "| **LOOCV**           | $m$                | Каждый объект — тестовый | Высокая                   | Высокая                |\n",
    "| **k-Fold (например, 10-Fold)** | $k$                  | Каждый объект используется в тестовом наборе ровно один раз | Средняя                  | Средняя                |\n",
    "| **Stratified k-Fold** | $k$                | Сохраняется пропорция классов в каждом фолде | Средняя                  | Средняя                |\n",
    "\n",
    "**Вывод**: LOOCV особенно полезен при малых выборках, где важно максимально использовать доступные данные. Однако для больших выборок или когда вычислительные ресурсы ограничены, более предпочтительны методы с меньшим количеством фолдов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4968233-6aeb-449d-8571-38672cec3442",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Показатель пограничности (Border ratio)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d46ddb-7eac-412e-bd18-8a2faa9577bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Показатель пограничности (Border Ratio)** — это метрика, используемая для оценки доли объектов в наборе данных, которые находятся вблизи границы разделения классов. В контексте метода **k ближайших соседей (k-NN)** этот показатель помогает понять, насколько сложна задача классификации и насколько чувствительна модель к расположению данных относительно границы решений.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Определение показателя пограничности\n",
    "\n",
    "**Пограничные объекты** — это те объекты, которые находятся близко к границе разделения классов, то есть их ближайшие соседи принадлежат разным классам. **Border Ratio** измеряет, какая часть всего набора данных является пограничной.\n",
    "\n",
    "#### Формальное определение\n",
    "\n",
    "$\n",
    "\\text{Border Ratio} = \\frac{\\text{Количество пограничных объектов}}{\\text{Общее количество объектов}}\n",
    "$\n",
    "\n",
    "**Где:**\n",
    "\n",
    "- **Пограничные объекты**: объекты, имеющие как минимум одного соседа из другого класса среди их k ближайших соседей.\n",
    "- **k**: количество ближайших соседей, используемое в алгоритме k-NN.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Как вычисляется Border Ratio\n",
    "\n",
    "#### Шаги вычисления:\n",
    "\n",
    "1. **Выбор параметра k**:\n",
    "   - Определите число ближайших соседей $k$ которое используется для классификации.\n",
    "\n",
    "2. **Определение класса каждого объекта**:\n",
    "   - Для каждого объекта в наборе данных определите его класс, основываясь на классах его $k$ ближайших соседей.\n",
    "\n",
    "3. **Идентификация пограничных объектов**:\n",
    "   - Объект считается пограничным, если среди его $k$ ближайших соседей присутствуют объекты разных классов.\n",
    "\n",
    "4. **Вычисление Border Ratio**:\n",
    "   - Подсчитайте количество таких пограничных объектов и разделите на общее число объектов в наборе данных.\n",
    "\n",
    "#### Пример:\n",
    "\n",
    "Предположим, у нас есть набор данных из 100 объектов, где 40 объектов являются пограничными (имеют соседей из другого класса).\n",
    "\n",
    "$\n",
    "\\text{Border Ratio} = \\frac{40}{100} = 0.4 \\quad (или \\quad 40\\%)\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Значение Border Ratio в k-NN\n",
    "\n",
    "#### Высокий Border Ratio:\n",
    "\n",
    "- **Сложность классификации**:\n",
    "  - Большое количество пограничных объектов указывает на сложную структуру данных с перекрывающимися классами.\n",
    "  \n",
    "- **Чувствительность к параметрам**:\n",
    "  - Модель становится более чувствительной к выбору $k$ и метрике расстояния. Неправильный выбор параметров может значительно снизить точность классификации.\n",
    "\n",
    "- **Влияние на устойчивость**:\n",
    "  - Высокий показатель может указывать на большую вероятность ошибок классификации, особенно при наличии шумовых данных или выбросов.\n",
    "\n",
    "#### Низкий Border Ratio:\n",
    "\n",
    "- **Ясное разделение классов**:\n",
    "  - Мало пограничных объектов свидетельствует о чётком разделении классов, что облегчает задачу классификации.\n",
    "  \n",
    "- **Меньшая чувствительность к параметрам**:\n",
    "  - Модель становится более устойчивой к выбору $k$ и метрики расстояния, так как большинство объектов находятся внутри чётко определённых кластеров.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Преимущества и недостатки использования Border Ratio\n",
    "\n",
    "#### Преимущества:\n",
    "\n",
    "1. **Оценка сложности задачи**:\n",
    "   - Позволяет количественно оценить, насколько сложно разделить классы в наборе данных.\n",
    "\n",
    "2. **Настройка параметров модели**:\n",
    "   - Помогает выбрать оптимальное значение $k$ и метрику расстояния, основываясь на структуре данных.\n",
    "\n",
    "3. **Диагностика качества данных**:\n",
    "   - Высокий Border Ratio может указывать на необходимость дополнительной предобработки данных, такой как удаление выбросов или увеличение числа признаков.\n",
    "\n",
    "#### Недостатки:\n",
    "\n",
    "1. **Зависимость от параметров k и метрики**:\n",
    "   - Значение Border Ratio может сильно варьироваться в зависимости от выбранного $k$ и метрики расстояния, что может затруднить интерпретацию.\n",
    "\n",
    "2. **Не учитывает распределение классов**:\n",
    "   - Border Ratio не отражает баланс классов в данных, что может быть важно для некоторых задач классификации.\n",
    "\n",
    "3. **Чувствительность к шуму**:\n",
    "   - Наличие шумовых данных или выбросов может искусственно увеличить Border Ratio, снижая общую точность модели.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Применение Border Ratio\n",
    "\n",
    "#### Оптимизация параметров k:\n",
    "\n",
    "- **Анализ влияния k**:\n",
    "  - Изменяя значение $k$ можно наблюдать, как меняется Border Ratio, и выбирать значение, при котором модель показывает наилучшее соотношение между точностью и обобщающей способностью.\n",
    "\n",
    "#### Выявление проблем в данных:\n",
    "\n",
    "- **Обнаружение перекрывающихся классов**:\n",
    "  - Высокий Border Ratio может свидетельствовать о том, что классы пересекаются в пространстве признаков, что требует более сложных моделей или добавления дополнительных признаков.\n",
    "\n",
    "#### Улучшение модели:\n",
    "\n",
    "- **Взвешенный k-NN**:\n",
    "  - Понимание Border Ratio может подтолкнуть к использованию методов, где ближние соседи имеют больший вес, уменьшая влияние пограничных объектов на классификацию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ebc01-7ae6-4acf-a1f1-7bcb072dd492",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Понятия выброса, прототипа, усвоенной точки. Алгоритм Харта."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2f5750-595c-4308-9555-1a9a06c5fe52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### 1. Понятие выброса (Outlier)\n",
    "\n",
    "#### Определение\n",
    "**Выброс** — это объект (точка данных), который значительно отличается от остальных объектов в наборе данных. Выбросы могут быть результатом ошибок измерения, редких событий или особенностей данных.\n",
    "\n",
    "#### Характеристики выбросов\n",
    "- **Аномальное положение**: Располагаются далеко от основной массы данных.\n",
    "- **Влияние на анализ**: Могут искажать результаты статистического анализа и модели машинного обучения.\n",
    "- **Причины возникновения**:\n",
    "  - Ошибки ввода или измерения.\n",
    "  - Естественные вариации данных.\n",
    "  - Редкие или необычные события.\n",
    "\n",
    "#### Методы обнаружения выбросов\n",
    "- **Визуализация**: Графики разброса, боксплоты.\n",
    "- **Статистические методы**: Z-оценка, метод межквартильного размаха (IQR).\n",
    "- **Машинное обучение**: Алгоритмы кластеризации, методы одномерной классификации (например, Isolation Forest).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Понятие прототипа (Prototype)\n",
    "\n",
    "#### Определение\n",
    "**Прототип** — это представительный объект или точка в кластере, которая наиболее точно характеризует этот кластер. Прототипы используются для упрощения модели и ускорения вычислений.\n",
    "\n",
    "#### Характеристики прототипов\n",
    "- **Центральное расположение**: Находятся вблизи центра кластера.\n",
    "- **Минимальное отклонение**: Обладают наименьшим средним расстоянием до остальных точек в кластере.\n",
    "- **Роль в кластеризации**: Служат эталонами для определения принадлежности других объектов к кластеру.\n",
    "\n",
    "#### Примеры использования\n",
    "- **k-средних (k-means)**: Использует центры кластеров как прототипы.\n",
    "- **k-медоидов (k-medoids)**: Использует реальные объекты данных в качестве прототипов.\n",
    "- **Методы на основе прототипов**: SOM (Self-Organizing Maps), нейронные сети.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Понятие усвоенной точки (Learned Point)\n",
    "\n",
    "#### Определение\n",
    "**Усвоенная точка** — это объект данных, который был \"усвоен\" алгоритмом кластеризации и включён в определённый кластер на основе своей близости к прототипу или другим точкам кластера.\n",
    "\n",
    "#### Характеристики усвоенных точек\n",
    "- **Принадлежность к кластеру**: Расположены близко к прототипу кластера.\n",
    "- **Роль в структуре кластера**: Поддерживают и формируют структуру кластера, обеспечивая его плотность и компактность.\n",
    "- **Не являются выбросами**: Усвоенные точки не находятся на границах кластера или далеко от прототипа.\n",
    "\n",
    "#### Значение в кластеризации\n",
    "- **Стабильность кластеров**: Усвоенные точки помогают поддерживать устойчивость кластеров при изменении данных.\n",
    "- **Оптимизация модели**: Обеспечивают эффективное представление кластера без необходимости хранения всех объектов данных.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Алгоритм Харта (Hart's Algorithm)\n",
    "\n",
    "**Алгоритм Харта** — это метод кластеризации, разработанный для эффективного обнаружения кластеров и выбросов в наборе данных. Он сочетает в себе концепции прототипов и выбросов для построения чёткой структуры кластеров.\n",
    "\n",
    "#### Основные шаги алгоритма Харта\n",
    "\n",
    "1. **Инициализация прототипов**:\n",
    "   - Выбираются начальные прототипы (центры кластеров) случайным образом или с использованием специфических критериев (например, k-means++).\n",
    "\n",
    "2. **Определение области влияния прототипов**:\n",
    "   - Для каждого прототипа определяется радиус или область, в которой будут усваиваться точки данных.\n",
    "\n",
    "3. **Назначение точек кластерам**:\n",
    "   - Каждая точка данных назначается к ближайшему прототипу, если она находится в пределах области влияния.\n",
    "   - Если точка не попадает ни в одну область влияния, она рассматривается как **выброс**.\n",
    "\n",
    "4. **Обновление прототипов**:\n",
    "   - Прототипы пересчитываются как средние (или медианные) значения точек в их кластерах.\n",
    "   - Этот шаг повторяется до сходимости (когда прототипы перестают значительно меняться).\n",
    "\n",
    "5. **Обработка выбросов**:\n",
    "   - Выбросы могут быть либо удалены из набора данных, либо назначены отдельным кластерам с низкой плотностью.\n",
    "\n",
    "#### Преимущества алгоритма Харта\n",
    "\n",
    "- **Эффективность**: Быстрая сходимость благодаря использованию прототипов.\n",
    "- **Обнаружение выбросов**: Способность идентифицировать и выделять аномальные объекты.\n",
    "- **Гибкость**: Подходит для различных типов данных и форм кластеров.\n",
    "\n",
    "#### Недостатки алгоритма Харта\n",
    "\n",
    "- **Чувствительность к инициализации**: Неправильный выбор начальных прототипов может привести к плохой кластеризации.\n",
    "- **Необходимость выбора параметров**: Требуется заранее определить количество кластеров и параметры областей влияния.\n",
    "- **Ограниченная масштабируемость**: Может быть менее эффективен для очень больших наборов данных по сравнению с другими алгоритмами кластеризации.\n",
    "\n",
    "\n",
    "### 5. Сравнение с другими алгоритмами кластеризации\n",
    "\n",
    "| Алгоритм          | Прототипы         | Обнаружение выбросов | Форма кластеров | Необходимость задания k | Сложность |\n",
    "|-------------------|-------------------|----------------------|------------------|------------------------|-----------|\n",
    "| **Алгоритм Харта** | Да                | Да                   | Любая            | Да                     | Средняя   |\n",
    "| **k-средних**     | Да                | Нет                  | Сферические      | Да                     | Низкая    |\n",
    "| **k-медоидов**    | Да                | Ограниченно          | Любая            | Да                     | Средняя   |\n",
    "| **DBSCAN**        | Нет                | Да                   | Любая            | Нет                    | Средняя   |\n",
    "| **Иерархическая** | Нет (в основном)| Зависит от метода    | Любая            | Нет                    | Высокая   |\n",
    "\n",
    "**Вывод**: Алгоритм Харта сочетает в себе преимущества методов, использующих прототипы и способных обнаруживать выбросы, обеспечивая гибкость в определении форм кластеров. Однако, как и любой другой алгоритм, он имеет свои ограничения и требует тщательной настройки параметров для достижения оптимальных результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210def4-f226-443b-ae72-fad0156b3ee0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Регрессия методом k-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91abdf43-4e28-45ed-82d0-3f86283f5a3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Регрессия методом k ближайших соседей (k-Nearest Neighbors Regression, k-NN Regression)** — это простой и интуитивно понятный алгоритм машинного обучения, используемый для прогнозирования **непрерывных** значений на основе значений ближайших соседей в обучающей выборке. В отличие от классификации, где цель — определить категориальную метку, регрессия k-NN предназначена для предсказания числовых значений.\n",
    "\n",
    "---\n",
    "### 1. Базовая идея регрессии k-NN\n",
    "\n",
    "**Регрессия k ближайших соседей** основывается на предположении, что **объекты, расположенные близко друг к другу в пространстве признаков, имеют похожие значения целевой переменной**. Таким образом, для предсказания значения целевой переменной нового объекта используется среднее (или взвешенное среднее) значений его **k ближайших соседей** в обучающей выборке.\n",
    "\n",
    "#### Ключевые моменты:\n",
    "- **Локальная зависимость**: Значение целевой переменной определяется ближайшими объектами.\n",
    "- **Не параметрический метод**: Не предполагает конкретной формы зависимости между признаками и целевой переменной.\n",
    "- **Простота реализации**: Легко реализуется и понимается, не требует сложного обучения модели.\n",
    "\n",
    "---\n",
    "### 2. Принцип работы регрессии k-NN\n",
    "\n",
    "#### Шаги алгоритма:\n",
    "\n",
    "1. **Выбор параметра k**:\n",
    "   - Определяется количество ближайших соседей $k$, которые будут учитываться при предсказании.\n",
    "\n",
    "2. **Расчет расстояний**:\n",
    "   - Для нового объекта рассчитываются расстояния до всех объектов обучающей выборки. Наиболее часто используемые метрики расстояния:\n",
    "     - **Евклидово расстояние**:\n",
    "       $\n",
    "       d(x, y) = \\sqrt{\\sum_{i=1}^n (x_i - y_i)^2}\n",
    "       $\n",
    "     - **Манхэттенское расстояние**:\n",
    "       $\n",
    "       d(x, y) = \\sum_{i=1}^n |x_i - y_i|\n",
    "       $\n",
    "     - **Расстояние Минковского**, **Чебышёва** и др.\n",
    "\n",
    "3. **Поиск k ближайших соседей**:\n",
    "   - Выбираются **k** объектов обучающей выборки с наименьшими расстояниями до нового объекта.\n",
    "\n",
    "4. **Предсказание значения**:\n",
    "   - **Среднее значение**:\n",
    "     $\n",
    "     \\hat{y} = \\frac{1}{k} \\sum_{i=1}^{k} y_i\n",
    "     $\n",
    "     где $y_i$ — значения целевой переменной ближайших соседей.\n",
    "   \n",
    "   - **Взвешенное среднее**:\n",
    "     $\n",
    "     \\hat{y} = \\frac{\\sum_{i=1}^{k} w_i y_i}{\\sum_{i=1}^{k} w_i}\n",
    "     $\n",
    "     где $w_i$ — веса, часто обратные расстоянию:\n",
    "     $\n",
    "     w_i = \\frac{1}{d(x, x_i) + \\epsilon}\n",
    "     $\n",
    "     $\\epsilon$ — малое число для предотвращения деления на ноль.\n",
    "\n",
    "#### Пример работы регрессии k-NN:\n",
    "\n",
    "Предположим, у нас есть набор данных с признаками $x$ и целевой переменной $y$:\n",
    "\n",
    "| Объект | $x$ | $y$ |\n",
    "|--------|-------|-------|\n",
    "| A      | 1     | 2     |\n",
    "| B      | 2     | 3     |\n",
    "| C      | 3     | 5     |\n",
    "| D      | 5     | 8     |\n",
    "| E      | 6     | 13    |\n",
    "\n",
    "Новый объект с $x = 4$. Пусть $k = 2$.\n",
    "\n",
    "1. **Расчет расстояний** до всех объектов:\n",
    "   - $d(4,1) = 3$\n",
    "   - $d(4,2) = 2$\n",
    "   - $d(4,3) = 1$\n",
    "   - $d(4,5) = 1$\n",
    "   - $d(4,6) = 2$\n",
    "\n",
    "2. **Выбор 2 ближайших соседей**: объекты C и D ($d = 1$).\n",
    "\n",
    "3. **Предсказание значения**:\n",
    "   - **Среднее значение**:\n",
    "     $\n",
    "     \\hat{y} = \\frac{5 + 8}{2} = 6.5\n",
    "     $\n",
    "   - **Взвешенное среднее** (если использовать веса $w_i = \\frac{1}{d + \\epsilon}$):\n",
    "     $\n",
    "     \\hat{y} \\approx \\frac{5 \\times 1 + 8 \\times 1}{1 + 1} = \\frac{13}{2} = 6.5\n",
    "     $\n",
    "\n",
    "---\n",
    "### 3. Преимущества и недостатки регрессии k-NN\n",
    "\n",
    "#### Преимущества:\n",
    "\n",
    "1. **Простота**:\n",
    "   - Легко реализуется и понимается.\n",
    "   - Не требует обучения модели, все вычисления выполняются при предсказании.\n",
    "\n",
    "2. **Гибкость**:\n",
    "   - Может использоваться для задач с любым количеством признаков.\n",
    "   - Не делает предположений о распределении данных.\n",
    "\n",
    "3. **Адаптивность**:\n",
    "   - Хорошо работает, когда границы между классами (в случае классификации) или зависимость между признаками и целевой переменной (в регрессии) сложные и нелинейные.\n",
    "\n",
    "4. **Инкрементальное обучение**:\n",
    "   - Новые данные можно легко добавлять без необходимости пересчитывать модель.\n",
    "\n",
    "#### Недостатки:\n",
    "\n",
    "1. **Высокая вычислительная сложность**:\n",
    "   - Для каждого предсказания необходимо вычислить расстояние до всех объектов обучающей выборки, что может быть ресурсоёмким при больших объёмах данных.\n",
    "\n",
    "2. **Проблема размерности (проклятие размерности)**:\n",
    "   - В пространствах с высокой размерностью расстояния между точками становятся менее информативными, что ухудшает качество предсказаний.\n",
    "\n",
    "3. **Чувствительность к масштабированию признаков**:\n",
    "   - Разные масштабы признаков могут искажать расстояния. Требуется **нормализация** или **стандартизация** данных.\n",
    "\n",
    "4. **Проблема выбора k**:\n",
    "   - Неправильный выбор параметра $k$ может привести к **переобучению** (слишком малое $k$) или **недообучению** (слишком большое $k$).\n",
    "\n",
    "5. **Хранение данных**:\n",
    "   - Необходимо хранить всю обучающую выборку, что может быть проблематично при больших данных.\n",
    "\n",
    "6. **Чувствительность к выбросам**:\n",
    "   - Выбросы могут сильно влиять на предсказание, особенно при использовании простого среднего.\n",
    "\n",
    "#### Способы преодоления недостатков:\n",
    "\n",
    "- **Использование эффективных структур данных** (например, деревья KD, Ball trees) для ускорения поиска ближайших соседей.\n",
    "- **Сокращение размерности** (например, с помощью методов главных компонент — PCA) для уменьшения влияния проклятия размерности.\n",
    "- **Выбор оптимального k** с помощью методов перекрёстной проверки (cross-validation).\n",
    "- **Предобработка данных**: нормализация, удаление выбросов и др.\n",
    "- **Использование взвешенного k-NN**, где ближайшим соседям присваиваются большие веса, уменьшая влияние удалённых точек и выбросов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6fe50-567f-4a54-81ab-c9629ab2078f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Взвешенные соседи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1269339-f3db-4e58-8156-d643bc35557b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "\n",
    "### 1. Определение взвешенных соседей\n",
    "\n",
    "**Взвешенные соседи** — это подход в алгоритме k-NN, при котором каждому соседу присваивается **вес**, отражающий его **важность** или **релевантность** при предсказании целевой переменной. Чем ближе сосед к новому объекту, тем **больше его вклад** в итоговое предсказание.\n",
    "\n",
    "#### Ключевые моменты:\n",
    "- **Вес** определяет степень влияния каждого соседа на предсказание.\n",
    "- **Масштабирование весов** позволяет более точно учитывать **локальную структуру данных**.\n",
    "- **Взвешивание** особенно полезно в ситуациях с **неоднородной плотностью** данных.\n",
    "\n",
    "---\n",
    "### 2. Методы взвешивания\n",
    "\n",
    "Существует несколько способов определения весов соседей. Наиболее популярные из них:\n",
    "\n",
    "#### 2.1 Обратная пропорция расстояния (Inverse Distance Weighting)\n",
    "\n",
    "Самый простой и распространенный метод:\n",
    "$\n",
    "w_i = \\frac{1}{d(x, x_i) + \\epsilon}\n",
    "$\n",
    "где:\n",
    "- $w_i$ — вес $i$-го соседа,\n",
    "- $d(x, x_i)$ — расстояние между новым объектом $x$ и соседом $x_i$,\n",
    "- $\\epsilon$ — небольшое положительное число для предотвращения деления на ноль.\n",
    "\n",
    "**Преимущества**:\n",
    "- Простота реализации.\n",
    "- Больше влияние ближних соседей.\n",
    "\n",
    "**Недостатки**:\n",
    "- Может быть чувствительно к выбросам (очень маленькие расстояния могут создавать очень большие веса).\n",
    "\n",
    "#### 2.2 Обратная квадратичная пропорция расстояния (Inverse Squared Distance)\n",
    "\n",
    "Усиление эффекта близости:\n",
    "$\n",
    "w_i = \\frac{1}{(d(x, x_i) + \\epsilon)^2}\n",
    "$\n",
    "\n",
    "**Преимущества**:\n",
    "- Еще более сильное акцентирование на ближних соседях.\n",
    "\n",
    "**Недостатки**:\n",
    "- Может усилить влияние выбросов.\n",
    "\n",
    "#### 2.3 Гауссовское взвешивание (Gaussian Weighting)\n",
    "\n",
    "Использование гауссовой функции для определения весов:\n",
    "$\n",
    "w_i = e^{-\\frac{d(x, x_i)^2}{2\\sigma^2}}\n",
    "$\n",
    "где $\\sigma$ — параметр, контролирующий ширину гауссового распределения.\n",
    "\n",
    "**Преимущества**:\n",
    "- Плавное снижение весов с увеличением расстояния.\n",
    "- Параметр $\\sigma$ позволяет контролировать степень взвешивания.\n",
    "\n",
    "**Недостатки**:\n",
    "- Необходимость выбора подходящего значения $\\sigma$.\n",
    "\n",
    "#### 2.4 Линейное взвешивание (Linear Weighting)\n",
    "\n",
    "Линейное уменьшение веса с увеличением расстояния:\n",
    "$\n",
    "w_i = \\max\\left(0, 1 - \\frac{d(x, x_i)}{d_{\\text{max}}}\\right)\n",
    "$\n",
    "где $d_{\\text{max}}$ — максимальное расстояние среди выбранных соседей.\n",
    "\n",
    "**Преимущества**:\n",
    "- Простота и интерпретируемость.\n",
    "- Вес равен нулю для точек, находящихся на границе выбора.\n",
    "\n",
    "**Недостатки**:\n",
    "- Резкое обнуление весов за пределами $d_{\\text{max}}$.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Преимущества и недостатки взвешенных соседей\n",
    "\n",
    "#### Преимущества:\n",
    "\n",
    "1. **Улучшенная точность**:\n",
    "   - Взвешивание позволяет учитывать **важность** соседей, что часто приводит к более точным предсказаниям по сравнению с равновесным k-NN.\n",
    "\n",
    "2. **Более гибкое управление влиянием соседей**:\n",
    "   - Возможность контролировать, насколько сильно ближние соседи влияют на предсказание через выбор функции взвешивания и параметров.\n",
    "\n",
    "3. **Снижение влияния выбросов**:\n",
    "   - Взвешенные методы могут уменьшить влияние дальних выбросов, которые не оказывают значительного веса.\n",
    "\n",
    "#### Недостатки:\n",
    "\n",
    "1. **Необходимость выбора функции и параметров взвешивания**:\n",
    "   - Требуется подобрать подходящую функцию взвешивания и её параметры (например, $\\sigma$ в гауссовском взвешивании), что может потребовать дополнительных вычислений и экспериментов.\n",
    "\n",
    "2. **Сложность реализации**:\n",
    "   - В сравнении с простым k-NN, взвешенные методы требуют дополнительных шагов для вычисления весов, что может увеличить вычислительную сложность.\n",
    "\n",
    "3. **Чувствительность к выбору метрики расстояния**:\n",
    "   - Как и в обычном k-NN, выбор метрики расстояния сильно влияет на результат, а неправильный выбор может ухудшить качество предсказаний.\n",
    "\n",
    "4. **Риск переусложнения**:\n",
    "   - В некоторых случаях, особенно при малом числе соседей или неудачном выборе весов, взвешивание может привести к ухудшению качества модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa4d2aa-2c08-4bbf-9922-b92a012aa918",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Эффективные методы поиска ближайших соседей (краткое описание)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da9ac8-dc40-40ad-a7f0-adfd345b9a70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### 1. KD-деревья (KD-Trees)\n",
    "\n",
    "#### **Описание**\n",
    "- **KD-дерево** (k-dimensional tree) — бинарное дерево, которое рекурсивно делит пространство признаков на гиперплоскости, перпендикулярные одному из признаков.\n",
    "  \n",
    "#### **Преимущества**\n",
    "- Эффективен для **низких** и **средних** размерностей (до ~20 признаков).\n",
    "- Позволяет ускорить поиск ближайших соседей по сравнению с линейным перебором.\n",
    "\n",
    "#### **Недостатки**\n",
    "- Эффективность резко снижается при **высокой размерности** из-за \"проклятия размерности\".\n",
    "- Требует балансировки дерева для оптимальной производительности.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Ball-деревья (Ball Trees)\n",
    "\n",
    "#### **Описание**\n",
    "- **Ball-дерево** разбивает пространство признаков на вложенные сферы («шары»), каждая из которых содержит подмножество точек.\n",
    "- Использует центр и радиус для описания каждого шара.\n",
    "\n",
    "#### **Преимущества**\n",
    "- Лучше справляется с **неравномерными** распределениями данных по сравнению с KD-деревьями.\n",
    "- Более устойчив к \"проклятию размерности\" в некоторых случаях.\n",
    "\n",
    "#### **Недостатки**\n",
    "- Как и KD-деревья, теряет эффективность при очень высокой размерности.\n",
    "- Сложнее в реализации и управлении.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Локально-чувствительное хеширование (Locality-Sensitive Hashing, LSH)\n",
    "\n",
    "#### **Описание**\n",
    "- **LSH** — метод **приближённого** поиска ближайших соседей, использующий хеш-функции, которые с высокой вероятностью хешируют похожие точки в одну корзину.\n",
    "- Часто применяется для **бинарных** или **вещественных** данных.\n",
    "\n",
    "#### **Преимущества**\n",
    "- Высокая скорость поиска в больших и высокоразмерных пространствах.\n",
    "- Позволяет эффективно обрабатывать **приближённые** соседей, что достаточно для многих практических задач.\n",
    "\n",
    "#### **Недостатки**\n",
    "- Не гарантирует нахождения **точных** ближайших соседей.\n",
    "- Требует настройки параметров хеширования для баланса между скоростью и точностью.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Cover-деревья (Cover Trees)\n",
    "\n",
    "#### **Описание**\n",
    "- **Cover-дерево** — структура данных, которая иерархически покрывает пространство точками с различными уровнями масштабов.\n",
    "- Позволяет быстро исключать большие подмножества точек при поиске.\n",
    "\n",
    "#### **Преимущества**\n",
    "- Работает эффективно при **различной плотности** данных.\n",
    "- Менее чувствительно к \"проклятию размерности\" по сравнению с KD- и Ball-деревьями.\n",
    "\n",
    "#### **Недостатки**\n",
    "- Сложность реализации.\n",
    "- Производительность зависит от структуры данных и расстояний между точками.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Алгоритмы приближённого поиска ближайших соседей (Approximate Nearest Neighbor, ANN)\n",
    "\n",
    "#### **Описание**\n",
    "- **ANN** методы стремятся найти ближайших соседей с приемлемой точностью, но значительно быстрее точных алгоритмов.\n",
    "- Включают такие подходы, как **Hierarchical Navigable Small World (HNSW)**, **Product Quantization (PQ)** и **Faiss** от Facebook.\n",
    "\n",
    "#### **Преимущества**\n",
    "- Высокая скорость поиска даже в **очень больших** и **высокодименсиональных** пространствах.\n",
    "- Поддержка масштабируемости и параллельных вычислений.\n",
    "\n",
    "#### **Недостатки**\n",
    "- Предоставляют **приближённые** результаты, что может быть неприемлемо для некоторых приложений.\n",
    "- Часто требуют дополнительной настройки и оптимизации под конкретные данные.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Индексы на основе графов (Graph-Based Indices)\n",
    "\n",
    "#### **Описание**\n",
    "- Строят графы, где узлы — это точки данных, а ребра соединяют близких соседей.\n",
    "- Используют методы обхода графа для быстрого поиска ближайших соседей.\n",
    "\n",
    "#### **Преимущества**\n",
    "- Высокая эффективность для **приближённого** поиска в больших наборах данных.\n",
    "- Хорошо работают с **сложными** структурами данных.\n",
    "\n",
    "#### **Недостатки**\n",
    "- Сложность построения и поддержки графа.\n",
    "- Может потребоваться значительное количество памяти.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Алгоритмы на основе факторизации пространства признаков\n",
    "\n",
    "#### **Описание**\n",
    "- Снижают размерность пространства признаков перед выполнением поиска ближайших соседей.\n",
    "- Используют методы, такие как **Principal Component Analysis (PCA)** или **t-Distributed Stochastic Neighbor Embedding (t-SNE)**.\n",
    "\n",
    "#### **Преимущества**\n",
    "- Уменьшают вычислительную сложность и улучшают эффективность поиска.\n",
    "- Могут улучшить качество поиска за счёт устранения шума и коррелированных признаков.\n",
    "\n",
    "#### **Недостатки**\n",
    "- Потенциальная потеря информации при снижении размерности.\n",
    "- Необходимость дополнительного шага предобработки данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d727d-61ca-46c8-abbb-52316fd6e03b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# 7.\tМетод опорных векторов (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d400b7-9daf-44a1-97fb-21651b17d42a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Постановка задачи линейного SVM для линейно разделимой выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9448fb80-b89b-4dfc-b56b-26b676141784",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "\n",
    "### 1. Постановка задачи\n",
    "\n",
    "**Цель линейного SVM** состоит в том, чтобы найти такую линию (или гиперплоскость в более высоких измерениях), которая максимально отделяет объекты разных классов. Представим, что у нас есть два типа точек на плоскости: одна группа точек принадлежит к одному классу, а другая — к другому. Линейный SVM стремится провести прямую линию так, чтобы она разделяла эти две группы с максимально возможным отступом между ближайшими точками каждой группы и линией разделения. Эти ближайшие точки, которые лежат на границе разделения, называются **опорными векторами**.\n",
    "\n",
    "**Линейно разделимая выборка** — это такой набор данных, где существует прямая линия (или гиперплоскость), которая может полностью отделить объекты одного класса от объектов другого класса без ошибок. В задачах с двумя классами обычно обозначают классы как положительный и отрицательный (например, +1 и -1).\n",
    "\n",
    "**Зазор (margin)** — это расстояние между линией разделения и ближайшими точками каждого класса. Цель SVM — найти такую линию, при которой этот зазор максимально велик. Больший зазор способствует лучшей обобщающей способности модели, то есть её способности правильно классифицировать новые, ранее не виденные объекты.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Решение задачи\n",
    "\n",
    "Для нахождения оптимальной линии разделения SVM использует методы из области оптимизации, включая условия оптимальности Каруша-Куна-Таккера (KKT) и двойственную форму задачи оптимизации. В результате оптимизации выясняется, что решение зависит только от опорных векторов — тех точек данных, которые лежат на границе зазора или немного за её пределами. Это делает SVM эффективным, так как для определения линии разделения не требуется учитывать все точки данных, а только опорные векторы.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Пример\n",
    "\n",
    "Рассмотрим простой пример с двумя классами точек на плоскости:\n",
    "\n",
    "- **Класс +1**: Точки с координатами (2, 3), (3, 4), (4, 5).\n",
    "- **Класс -1**: Точки с координатами (1, 1), (2, 1), (3, 2).\n",
    "\n",
    "**Шаги построения линейного SVM:**\n",
    "\n",
    "1. **Определение гиперплоскости**: Предположим, что линия разделения имеет определённые параметры, которые нужно найти.\n",
    "\n",
    "2. **Построение ограничений**: Для каждой точки одного класса устанавливаются условия, что они должны находиться по одну сторону линии разделения, а для другой группы — по другую сторону.\n",
    "\n",
    "3. **Минимизация значения**: Проводится оптимизация параметров линии таким образом, чтобы зазор между ближайшими точками двух классов был максимален.\n",
    "\n",
    "4. **Нахождение опорных векторов**: Опорными векторами будут те точки, которые находятся непосредственно на границе зазора или немного за её пределами. \n",
    "\n",
    "---\n",
    "\n",
    "### 6. Преимущества и недостатки линейного SVM для линейно разделимой выборки\n",
    "\n",
    "#### Преимущества:\n",
    "\n",
    "1. **Оптимальность**: Линейный SVM гарантирует, что найденная линия разделения обеспечивает максимально возможный зазор между классами, что улучшает способность модели к обобщению на новые данные.\n",
    "\n",
    "2. **Устойчивость к переобучению**: Максимизация зазора действует как форма регуляризации, уменьшая риск переобучения, особенно при малых объёмах данных.\n",
    "\n",
    "3. **Эффективность в высокоразмерных пространствах**: SVM хорошо работает, когда количество признаков (характеристик) велико, что часто встречается в реальных задачах, например, при обработке текстов или изображений.\n",
    "\n",
    "4. **Расширяемость через ядровые трюки**: Хотя мы рассматриваем линейный SVM, его можно легко расширить для работы с нелинейно разделимыми данными, используя специальные методы, называемые ядровыми трюками.\n",
    "\n",
    "#### Недостатки:\n",
    "\n",
    "1. **Линейность**: Линейный SVM подходит только для данных, которые можно полностью разделить прямой линией или гиперплоскостью. Если классы не линейно разделимы, необходимо использовать более сложные версии SVM с ядрами.\n",
    "\n",
    "2. **Чувствительность к масштабированию признаков**: Разные масштабы признаков могут искажать расстояния между точками, что влияет на качество разделения. Поэтому перед применением SVM часто требуется нормализация или стандартизация данных.\n",
    "\n",
    "3. **Вычислительная сложность**: Для очень больших наборов данных обучение линейного SVM может быть ресурсоёмким, хотя существуют оптимизированные алгоритмы и реализации, которые облегчают эту проблему.\n",
    "\n",
    "4. **Влияние выбросов**: Наличие выбросов — точек, сильно отличающихся от остальных — может существенно повлиять на положение линии разделения, снижая качество классификации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b29792-27fb-4ee0-91e0-c86f2dcf05f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Линейный SVM в случае линейно неразделимой выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfdf7be-3228-4203-bffd-4f1138a07238",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### 2. Введение мягкого зазора (Soft Margin)\n",
    "\n",
    "Чтобы адаптировать линейный SVM к линейно неразделимым данным, был предложен **подход мягкого зазора (Soft Margin)**. Этот подход позволяет некоторым объектам нарушать строгие границы классификации, вводя понятие **скользящих переменных (slack variables)**.\n",
    "\n",
    "#### 2.1 Скользящие переменные\n",
    "\n",
    "Для каждого объекта данных вводится скользящая переменная, которая измеряет степень, с которой объект нарушает границу классификации:\n",
    "\n",
    "- **Нулевые скользящие переменные**: Объект полностью соответствует условиям классификации и находится на правильной стороне разделяющей линии с достаточным запасом.\n",
    "\n",
    "- **Скользящие переменные внутри зазора**: Объект находится ближе к разделяющей линии, но всё ещё правильно классифицирован.\n",
    "\n",
    "- **Скользящие переменные вне зазора**: Объект неправильно классифицирован и лежит по неправильной стороне разделяющей линии.\n",
    "\n",
    "#### 2.2 Модифицированная задача оптимизации\n",
    "\n",
    "С введением мягкого зазора задача оптимизации линейного SVM изменяется следующим образом:\n",
    "\n",
    "- **Цель**: Найти разделяющую линию, которая не только максимально отделяет классы, но и минимизирует количество и степень нарушений границ классификации.\n",
    "\n",
    "- **Балансировка**: Вводится параметр, который контролирует баланс между максимизацией зазора и минимизацией ошибок классификации. Этот параметр позволяет модели быть более гибкой и устойчивой к шуму и выбросам в данных.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Геометрическая интерпретация мягкого зазора\n",
    "\n",
    "#### 3.1 Гиперплоскости с мягким зазором\n",
    "\n",
    "Вместо двух жестких границ разделения, которые полностью отделяют классы, вводятся гибкие границы, которые учитывают возможные нарушения:\n",
    "\n",
    "- **Гиперплоскости с учетом скользящих переменных**: Эти границы могут смещаться и изменять свой угол, чтобы позволить некоторым объектам нарушать строгие условия разделения, тем самым адаптируясь к реальной структуре данных.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Решение задачи оптимизации\n",
    "\n",
    "#### 4.1 Лагранжиан и условия оптимальности Каруша-Куна-Таккера (KKT)\n",
    "\n",
    "Для решения модифицированной задачи оптимизации с мягким зазором используются методы из области оптимизации, включая введение дополнительных условий и использование множителей Лагранжа. Эти методы позволяют эффективно найти оптимальные параметры разделяющей линии, учитывая возможность некоторых нарушений границ классификации.\n",
    "\n",
    "\n",
    "### 5. Пример работы линейного SVM с мягким зазором\n",
    "\n",
    "Рассмотрим простой пример с двумя классами точек, которые невозможно полностью разделить прямой линией без ошибок:\n",
    "\n",
    "#### Набор данных:\n",
    "\n",
    "- **Класс +1**: Точки, расположенные ближе к одной стороне пространства.\n",
    "- **Класс -1**: Точки, расположенные ближе к другой стороне пространства, но некоторые из них пересекаются с классом +1.\n",
    "\n",
    "#### Построение модели SVM:\n",
    "\n",
    "1. **Выбор параметра**: Определяется значение параметра, контролирующего компромисс между зазором и ошибками классификации.\n",
    "\n",
    "2. **Определение скользящих переменных**: Некоторые точки из класса -1 могут находиться ближе к линии разделения или даже пересекать её, что будет учтено через скользящие переменные.\n",
    "\n",
    "3. **Оптимизация**: Алгоритм SVM находит такую линию разделения, которая максимально отделяет классы, учитывая допустимые нарушения.\n",
    "\n",
    "4. **Результат**: Получается разделяющая линия, которая максимально отделяет основные группы классов, но допускает некоторые ошибки для повышения общей обобщающей способности модели.\n",
    "\n",
    "---\n",
    "\n",
    "**Заключение**\n",
    "\n",
    "**Линейный метод опорных векторов (SVM)** с мягким зазором — это мощный инструмент для задач классификации, особенно когда данные не поддаются полному разделению прямой линией. Введение мягкого зазора позволяет модели быть гибкой, сохраняя при этом общую структуру и устойчивость к переобучению. Однако для достижения наилучших результатов важно тщательно настраивать параметры модели, проводить предобработку данных и учитывать возможные выбросы. В случаях, когда линейный подход недостаточен, SVM можно расширить с помощью ядровых трюков, что позволяет моделировать более сложные и нелинейные разделения классов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe2f61-a60c-4231-80ac-a7654cbf263f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Задача оптимизации SVM. Двойственная задача."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd10e2f-0acb-4794-ab8c-8672b664e7be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### 1. Прямая задача SVM\n",
    "\n",
    "**Прямая задача SVM** заключается в том, чтобы найти такие параметры модели, которые обеспечивают максимальное разделение между двумя классами данных. Вот ключевые моменты:\n",
    "\n",
    "- **Максимизация зазора**: SVM стремится провести разделяющую линию (или гиперплоскость в многомерном пространстве) так, чтобы расстояние между этой линией и ближайшими точками каждого класса было максимально большим. Этот зазор способствует лучшей обобщающей способности модели, позволяя ей правильно классифицировать новые данные.\n",
    "\n",
    "- **Минимизация ошибок классификации**: В идеальном случае все точки одного класса находятся по одну сторону от разделяющей линии, а все точки другого класса — по другую. Однако в реальных данных такое идеальное разделение редко достижимо. Поэтому SVM допускает некоторые ошибки, вводя штрафы за неправильно классифицированные точки. Это делает модель более гибкой и устойчивой к шуму в данных.\n",
    "\n",
    "**Почему важно минимизировать определенное значение**: Минимизация сложности модели помогает предотвратить переобучение, то есть ситуацию, когда модель слишком точно подстраивается под обучающие данные и плохо работает на новых, ранее не виденных данных.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Двойственная задача SVM\n",
    "\n",
    "**Двойственная задача SVM** представляет собой альтернативный подход к решению основной задачи оптимизации. Вместо прямого поиска параметров разделяющей линии, двойственная задача фокусируется на определении того, как каждая точка данных влияет на решение.\n",
    "\n",
    "**Ключевые моменты двойственной задачи:**\n",
    "\n",
    "- **Набор коэффициентов (альфа)**: Для каждой точки данных вводится коэффициент, который показывает, насколько сильно эта точка влияет на определение разделяющей линии. Эти коэффициенты помогают определить, какие точки являются наиболее важными для модели.\n",
    "\n",
    "- **Опорные векторы**: Не все точки данных оказывают одинаковое влияние на разделение классов. Только небольшое подмножество точек, называемых опорными векторами, играет ключевую роль в формировании разделяющей линии. Эти точки находятся непосредственно на границе зазора или близко к ней. Остальные точки не влияют на конечное решение и могут быть проигнорированы.\n",
    "\n",
    "**Смысл перехода к двойственной задаче:**\n",
    "\n",
    "Вместо того чтобы напрямую работать с параметрами разделяющей линии, двойственная задача позволяет оптимизировать только набор коэффициентов, ассоциированных с каждой точкой данных. Это упрощает процесс обучения модели и делает его более эффективным, особенно при работе с большими наборами данных. Кроме того, двойственная форма задачи удобна для интеграции с ядровыми функциями, что открывает возможности для обработки нелинейных разделений.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428dbf2-2d34-4f8b-8c77-b4ec1d0cc9bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### 2.1 Причины перехода к двойственной задаче\n",
    "\n",
    "Переход от прямой задачи оптимизации к **двойственной задаче** предоставляет несколько преимуществ:\n",
    "- **Применение ядровых трюков**: Позволяет легко переходить к нелинейным разделениям, преобразуя данные в более высокоразмерное пространство.\n",
    "- **Экономия вычислительных ресурсов**: Решение двойственной задачи зависит от числа ограничений, которое обычно меньше, чем количество признаков, что делает вычисления более эффективными.\n",
    "- **Фокус на опорных векторах**: В двойственной задаче решение зависит только от определенного подмножества данных — опорных векторов, что снижает объем необходимых вычислений.\n",
    "\n",
    "\n",
    "### 5. Преимущества и недостатки двойственной формы SVM\n",
    "\n",
    "#### Преимущества:\n",
    "\n",
    "1. **Гибкость через ядровые функции**: Позволяет модели адаптироваться к различным структурам данных.\n",
    "2. **Экономия памяти и вычислений**: Решение зависит только от опорных векторов, что делает процесс обучения более эффективным.\n",
    "3. **Эффективность в высокоразмерных пространствах**: Подходит для задач с большим числом признаков.\n",
    "4. **Оптимальные свойства**: Гарантирует нахождение наилучшего разделения классов.\n",
    "\n",
    "#### Недостатки:\n",
    "\n",
    "1. **Вычислительная сложность для больших выборок**: При очень больших наборах данных построение двойственной задачи может требовать значительных вычислительных ресурсов.\n",
    "2. **Требовательность к памяти**: Для хранения и обработки информации о множестве точек может потребоваться много памяти.\n",
    "3. **Выбор ядра и параметров**: Необходимость тщательного выбора ядровой функции и настроек модели может усложнить процесс обучения.\n",
    "4. **Опорные векторы**: В случае большого числа опорных векторов модель может стать менее эффективной и подверженной переобучению.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba4a59-80fe-43d7-9104-43c51c754ca3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Kernel trick. Виды ядер."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed277fe-eeae-4a42-8033-806a8b680326",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Ядровой трюк (Kernel Trick). Виды ядер.**\n",
    "\n",
    "**Ядровой трюк (Kernel Trick)** — это мощная техника, используемая в **методе опорных векторов (SVM)** и других алгоритмах машинного обучения для преобразования данных в более высокоразмерное пространство признаков. Это позволяет моделям эффективно работать с **нелинейно разделимыми** данными, не требуя явного вычисления координат в новом пространстве. Вместо этого ядровой трюк использует **ядровые функции**, которые вычисляют скалярное произведение между парами точек в преобразованном пространстве напрямую.\n",
    "\n",
    "#### 3.2 Виды ядер\n",
    "\n",
    "Существует множество видов ядерных функций, каждая из которых подходит для определённых типов данных и задач. Рассмотрим наиболее популярные из них:\n",
    "\n",
    "1. **Линейное ядро**\n",
    "   - **Описание**: Соответствует разделению данных прямой линией без преобразования пространства признаков.\n",
    "   - **Когда использовать**: Если данные уже линейно разделимы или если размерность признаков высока и линейная модель может быть эффективной.\n",
    "   - **Преимущества**: Простота и низкая вычислительная стоимость.\n",
    "   - **Недостатки**: Не подходит для нелинейно разделимых данных.\n",
    "\n",
    "2. **Полиномиальное ядро**\n",
    "   - **Описание**: Преобразует данные в пространство, соответствующее полиномиальной функции заданной степени.\n",
    "   - **Когда использовать**: Для данных с полиномиальной структурой разделения классов.\n",
    "   - **Преимущества**: Способно моделировать сложные разделительные границы.\n",
    "   - **Недостатки**: Повышенная вычислительная сложность при больших степенях.\n",
    "\n",
    "3. **Радиально-базисное ядро (RBF)**\n",
    "   - **Описание**: Измеряет сходство между точками, быстро уменьшая вес с увеличением расстояния. Создаёт очень гибкие разделительные границы.\n",
    "   - **Когда использовать**: Широко используется для нелинейно разделимых данных.\n",
    "   - **Преимущества**: Способно создавать очень гибкие разделительные границы.\n",
    "   - **Недостатки**: Требует тщательной настройки параметра, контролирующего ширину функции.\n",
    "\n",
    "4. **Сигмоидальное ядро**\n",
    "   - **Описание**: Имитирует нейронные сети, применяя сигмоидальную функцию активации.\n",
    "   - **Когда использовать**: Реже используется, но может быть полезно в специфических задачах.\n",
    "   - **Преимущества**: Может моделировать различные нелинейные зависимости.\n",
    "   - **Недостатки**: Может быть нестабильным и сложно настраиваемым.\n",
    "\n",
    "5. **Ядро Минковского**\n",
    "   - **Описание**: Общая форма, включающая различные метрики расстояния в качестве основы для ядра.\n",
    "   - **Когда использовать**: Для задач, где специфическая метрика расстояния лучше подходит для структуры данных.\n",
    "   - **Преимущества**: Гибкость в выборе метрики.\n",
    "   - **Недостатки**: Может потребовать значительной настройки параметров.\n",
    "\n",
    "6. **Ядро Бесселя**\n",
    "   - **Описание**: Использует функцию Бесселя для измерения сходства.\n",
    "   - **Когда использовать**: Специфические задачи, где требуется подобная форма ядра.\n",
    "   - **Преимущества**: Может быть полезно для определённых типов данных.\n",
    "   - **Недостатки**: Не так широко используется и может быть сложным в настройке.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Преимущества и недостатки ядрового трюка\n",
    "\n",
    "#### Преимущества:\n",
    "\n",
    "1. **Гибкость**:\n",
    "   - Позволяет моделям адаптироваться к сложным структурам данных.\n",
    "   - Поддерживает широкий спектр ядерных функций для различных задач.\n",
    "\n",
    "2. **Универсальность**:\n",
    "   - Ядровой трюк можно применять не только в SVM, но и в других алгоритмах, таких как **Kernel PCA**, **Kernel Ridge Regression**, и др.\n",
    "\n",
    "3. **Эффективность**:\n",
    "   - Позволяет работать с высокоразмерными данными без явного преобразования, снижая вычислительную нагрузку.\n",
    "\n",
    "#### Недостатки:\n",
    "\n",
    "1. **Выбор ядра и параметров**:\n",
    "   - Требует тщательного выбора ядровой функции и её параметров, что может быть трудоемким и требует перекрестной валидации.\n",
    "\n",
    "2. **Вычислительная сложность**:\n",
    "   - Для больших наборов данных вычисление матрицы ядра может быть ресурсоёмким и требовать значительного объёма памяти.\n",
    "\n",
    "3. **Проклятие размерности**:\n",
    "   - Хотя ядровой трюк позволяет работать в высокоразмерных пространствах, эффективность может снижаться с увеличением размерности из-за \"проклятия размерности\".\n",
    "\n",
    "4. **Переобучение**:\n",
    "   - Сложные ядровые функции могут привести к переобучению модели, особенно при малом объёме данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e084db-1d81-46dd-9a2e-d2dd99ade520",
   "metadata": {},
   "source": [
    "# Деревья решений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1825e-e8df-4e1e-a96e-7d022842ef68",
   "metadata": {},
   "source": [
    "### Понятие энтропии, определение информации по Шеннону."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13656efe-f1ee-4285-b43d-d950fafefbeb",
   "metadata": {},
   "source": [
    "**Деревья решений** — это метод машинного обучения, который схематически разбивает данные на последовательность «правил», помогающих классифицировать объекты или предсказывать значения. \n",
    "\n",
    "---\n",
    "\n",
    "#### Энтропия\n",
    "\n",
    "**Энтропия** в контексте деревьев решений — это способ измерить, насколько перемешаны объекты разных классов в каком-то подмножестве данных. Представьте, что у вас есть корзина, в которой могут лежать яблоки и груши. Если корзина наполнена фруктами только одного вида, то вы уверены, что, доставая фрукт наугад, вы получите именно этот вид. Такая ситуация означает **низкую неопределённость** (то есть низкую энтропию). Напротив, если в корзине количество яблок и груш примерно одинаково, вам сложно предсказать, что вы вытащите, и неопределённость высокая (энтропия высока).\n",
    "\n",
    "В дереве решений мы ищем такие разбиения данных (ветвления), при которых неопределённость по классам в каждой из ветвей становится как можно меньше. Проще говоря, мы стараемся разделить наши объекты так, чтобы внутри каждой ветви дерева оставались объекты максимально одного класса, снижая энтропию.\n",
    "\n",
    "---\n",
    "\n",
    "#### Информация по Шеннону\n",
    "\n",
    "**Информация** в смысле Шеннона — это мера того, насколько сильно уменьшается наша неопределённость, когда мы узнаём результат. Предположим, вы не знаете, что вам достанется — яблоко или груша. Если вы получите подсказку, например, «фрукт жёлтого цвета», и это сильно повысит вашу уверенность в том, какой фрукт у вас будет (скажем, это, скорее всего, яблоко), то вы получили **много** информации. Если же подсказка ничего не проясняет (например, «фрукт растёт на дереве», а оба растут на дереве), значит, вы получили **мало** информации, потому что ваша неопределённость почти не уменьшилась.\n",
    "\n",
    "В контексте деревьев решений, когда мы делим данные на подгруппы, мы хотим выбрать такое разбиение (признак и его условие), которое даст нам **наибольшую выгоду** в смысле информации: то есть максимально уменьшит энтропию (неопределённость) относительно классов. Мы говорим, что это разбиение даёт наибольший **прирост информации**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Как это связано с деревьями решений\n",
    "\n",
    "1. **Корень дерева**: Сначала у нас есть все данные, и мы считаем, как сильно они «смешаны» по классам (энтропия).  \n",
    "2. **Первая ветка (признак)**: Мы выбираем признак, который лучше всего «разделяет» данные, уменьшая энтропию в получившихся группах. Другими словами, выбираем признак, дающий наибольший прирост информации.  \n",
    "3. **Рекурсивное продолжение**: Повторяем процесс для каждой ветви, пока данные в ветве не станут однородны (энтропия близка к нулю) или у нас не закончатся признаки для ветвления.\n",
    "\n",
    "Таким образом, энтропия и информация по Шеннону дают нам формальный способ измерить, насколько хорошее у нас получилось разделение данных по тому или иному признаку. В итоге дерево решений — это последовательный процесс выбора таких «лучших» признаков и разбиений, чтобы по пути от корня к листу мы максимизировали уверенность в принадлежности объектов к тому или иному классу.\n",
    "\n",
    "---\n",
    "\n",
    "Энтропия и прирост информации по Шеннону — это ключевые понятия при построении **деревьев решений**, особенно в алгоритмах типа **ID3**, **C4.5**, **CART (в версии с энтропией)**.\n",
    "\n",
    "Разберёмся по шагам.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Энтропия (Shannon Entropy)**\n",
    "\n",
    "Энтропия — мера неопределённости в данных. Для бинарной классификации:\n",
    "\n",
    "$$\n",
    "H(S) = -p_+ \\log_2(p_+) - p_- \\log_2(p_-)\n",
    "$$\n",
    "\n",
    "* $S$ — множество объектов (например, обучающие примеры в узле),\n",
    "* $p_+$ — доля положительных примеров (например, класс \"да\"),\n",
    "* $p_- = 1 - p_+$ — доля отрицательных.\n",
    "\n",
    "Если классов больше двух:\n",
    "\n",
    "$$\n",
    "H(S) = - \\sum_{i=1}^{k} p_i \\log_2(p_i)\n",
    "$$\n",
    "\n",
    "где $p_i$ — доля примеров класса $i$, $k$ — число классов.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Пример энтропии**\n",
    "\n",
    "Пусть в узле 10 объектов: 6 \"да\", 4 \"нет\".\n",
    "\n",
    "$$\n",
    "p_+ = \\frac{6}{10} = 0.6,\\quad p_- = 0.4\n",
    "$$\n",
    "\n",
    "$$\n",
    "H(S) = -0.6 \\log_2(0.6) - 0.4 \\log_2(0.4) \\approx 0.971\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Условная энтропия после разбиения**\n",
    "\n",
    "Допустим, у нас есть признак, который делит множество $S$ на два подмножества $S_1$ и $S_2$:\n",
    "\n",
    "* $S_1$: 4 \"да\", 0 \"нет\"\n",
    "* $S_2$: 2 \"да\", 4 \"нет\"\n",
    "\n",
    "Тогда:\n",
    "\n",
    "$$\n",
    "H(S_1) = -1 \\log_2(1) - 0 \\log_2(0) = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "H(S_2) = -\\frac{2}{6} \\log_2\\left(\\frac{2}{6}\\right) - \\frac{4}{6} \\log_2\\left(\\frac{4}{6}\\right) \\approx 0.918\n",
    "$$\n",
    "\n",
    "Взвешенная энтропия после разбиения:\n",
    "\n",
    "$$\n",
    "H_{after} = \\frac{4}{10} \\cdot 0 + \\frac{6}{10} \\cdot 0.918 = 0.551\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Прирост информации (Information Gain)**\n",
    "\n",
    "$$\n",
    "IG = H(S) - H_{after}\n",
    "$$\n",
    "\n",
    "$$\n",
    "IG = 0.971 - 0.551 = 0.42\n",
    "$$\n",
    "\n",
    "Признак с наибольшим приростом информации выбирается для разделения узла дерева.\n",
    "\n",
    "---\n",
    "\n",
    "## Кратко:\n",
    "\n",
    "* **Энтропия** — мера неопределённости в наборе.\n",
    "* **Information Gain** — насколько уменьшилась неопределённость после разбиения по признаку.\n",
    "* Используется при построении дерева для выбора лучшего признака.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "- **Энтропия** показывает, насколько объекты разных классов перемешаны (высокая энтропия — сильная неопределённость, низкая — высокая однородность).  \n",
    "- **Информация** по Шеннону говорит, насколько уменьшается наша неопределённость, когда мы узнаём значение признака.  \n",
    "- Деревья решений строятся, выбирая на каждом шаге признак с наибольшим приростом информации (или, эквивалентно, максимальным уменьшением энтропии), чтобы получившиеся ветви были как можно более «однородными» по классам.  \n",
    "\n",
    "Это позволяет деревьям решений принимать логические решения вида «Если признак A удовлетворяет условию X, иди влево, иначе — вправо», постепенно приближаясь к тому, чтобы в каждом «листочке» дерева оставались объекты одного класса или близко к тому."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89e75e-ae90-47e5-972c-1062ec6b0ed0",
   "metadata": {},
   "source": [
    "### Понятие дерева решений. Процесс обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c15979f-b578-4ba8-bed9-edbf9da6fb1e",
   "metadata": {},
   "source": [
    "**Дерево решений** — это метод машинного обучения, который пошагово «делит» данные с помощью простых вопросов (правил), пока не дойдёт до конечного «листа», где решение (класс или значение) становится очевидным. Эти последовательные вопросы похожи на проверку условий вида «если ... тогда ... иначе ...», позволяя постепенно сужать варианты и приходить к правильному выводу.\n",
    "\n",
    "---\n",
    "\n",
    "#### Понятие дерева решений\n",
    "\n",
    "- **Структура**: Дерево решений состоит из **узлов** (где задаётся вопрос или условие) и **ветвей** (путей), по которым данные «спускаются» дальше. Если данные удовлетворяют условию, они идут по одной ветви, а если нет — по другой.  \n",
    "- **Лист**: Узел, в котором дерево прекращает деление данных, называется **листом**. В листе мы даём ответ — например, к какому классу относятся объекты или какое числовое значение нужно предсказать.  \n",
    "\n",
    "> Пример: Если мы классифицируем цветок по признакам длины лепестка и ширины чашелистика, в первом узле можно спросить «длина лепестка > 2 см?». Если да — идём по одной ветви, если нет — по другой.\n",
    "\n",
    "---\n",
    "\n",
    "#### Процесс обучения\n",
    "\n",
    "1. **Подготовка данных**:  \n",
    "   - Собираем набор объектов (примеров) с известными признаками и ответами (метками).  \n",
    "   - Каждый объект имеет несколько признаков, например, «длина лепестка», «ширина стебля» и т. д.\n",
    "\n",
    "2. **Выбор признака для корня (первый вопрос)**:  \n",
    "   - Модель анализирует, какой признак наилучшим образом «делит» данные на группы, в которых объекты будут максимально похожи в отношении ответа.  \n",
    "   - Для этого используются меры «качества» разделения (например, уменьшение энтропии или прирост информации).  \n",
    "\n",
    "3. **Рекурсивное построение**:  \n",
    "   - После того как дерево выбирает признак и способ разделения, данные разбиваются на соответствующие ветви.  \n",
    "   - Для каждой ветви повторяется выбор «лучшего» признака среди оставшихся и задаётся новый «вопрос», пока данные в ветви не станут достаточно однородны (например, все объекты одной категории).  \n",
    "\n",
    "4. **Остановка**:  \n",
    "   - Дерево прекращает деление, когда достигнут один из критериев:  \n",
    "     - Все объекты в ветви относятся к одному классу (или значение почти одинаковое).  \n",
    "     - Нет оставшихся признаков для дальнейшего деления.  \n",
    "     - Достигнута заданная глубина или другое ограничение, чтобы предотвратить чрезмерное усложнение (переобучение).\n",
    "\n",
    "5. **Формирование листьев**:  \n",
    "   - В узлах, где деление прекращается, формируются **листья**, в которых хранится «ответ» (класс или среднее значение).  \n",
    "\n",
    "> Пример: Для наших цветков на каждом шаге выбираем признак (вопрос), который сильнее всего сокращает «разнообразие» ответов в ветвях. Это продолжается, пока листья не станут достаточно «однородными» по ответам.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "- **Дерево решений** — это иерархическая структура вопросов (условий), постепенно разделяющих объекты на группы с похожими ответами.  \n",
    "- **Процесс обучения** аналогичен серии «разветвляющихся» вопросов, где каждый вопрос выбирается так, чтобы максимально упорядочить данные относительно конечной цели (классификации или регрессии).  \n",
    "\n",
    "Это делает дерево решений понятным инструментом: оно не только даёт результат, но и объясняет, как именно к нему пришло, в виде простой и наглядной «логики» (если-то-иначе) на нескольких уровнях глубины."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e3224f-26d1-40c2-a8a9-2c6585900407",
   "metadata": {},
   "source": [
    "### Gini impurity, information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac76deb0-c424-4a9b-a658-8cd9910a2f7a",
   "metadata": {},
   "source": [
    "В процессе построения дерева решений мы хотим разбивать набор данных таким образом, чтобы объекты каждого «листа» (конечного узла) были как можно более однородны по целевому признаку (классу). Для этого используются специальные «метрики качества» разбиения, среди которых особую роль играют **Gini impurity** и **information gain**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Gini impurity (примесь Джини)\n",
    "\n",
    "**Gini impurity** — это показатель, говорящий о том, насколько «смешанными» или «неоднородными» являются данные внутри узла по сравнению с их целевым классом. Чем выше значение Gini impurity, тем более перемешаны классы внутри выборки (т. е. мы менее уверены, что все объекты принадлежат одному классу). \n",
    "\n",
    "- **Низкое значение Gini** (близкое к нулю) означает, что почти все объекты принадлежат к одному классу, и «неопределённость» в этом узле минимальна.  \n",
    "- **Высокое значение Gini** (близкое к максимуму) показывает, что объекты распределены по классам примерно поровну, и мы не можем «угадать», к какому классу отнесён случайный объект.\n",
    "\n",
    "В дереве решений мы стремимся выбрать такой признак и способ «разбить» данные, чтобы в получающихся подмножествах Gini impurity был как можно ниже (т. е. каждый узел содержал объекты преимущественно одного класса).\n",
    "\n",
    "---\n",
    "\n",
    "#### Information gain (прирост информации)\n",
    "\n",
    "**Information gain** (прирост информации) показывает, насколько хорошо мы «упорядочили» данные по классам, задавая конкретное разбиение. \n",
    "\n",
    "- Сначала мы измеряем «неопределённость» (энтропию или Gini) исходного набора.  \n",
    "- Затем смотрим, как эта неопределённость уменьшилась после того, как мы разбили набор по признаку (например, «длина лепестка больше/меньше X»).  \n",
    "\n",
    "Если после разбиения объекты в каждой ветви становятся более однородными (т. е. неопределённость в каждом из подмножеств заметно упала), значит мы получили **высокий прирост информации**. Напротив, если разбиение почти не улучшило «упорядоченность» классов, то прирост информации окажется маленьким.\n",
    "\n",
    "В дереве решений на каждом шаге выбирают тот признак и способ разбиения, который даёт наибольшее снижение неопределённости (или наибольший прирост информации).\n",
    "\n",
    "---\n",
    "\n",
    "#### Как это используется в деревьях решений\n",
    "\n",
    "1. **Изначально** вся обучающая выборка представляет собой один узел (корень). Мы считаем неопределённость (Gini impurity или энтропию) всего набора.  \n",
    "2. **Возможные разбиения**: Для каждого признака алгоритм рассматривает различные пороговые значения или категории, чтобы «разделить» данные на две (или больше) части.  \n",
    "3. **Оценка**: Считается, во сколько раз уменьшилась неопределённость (или насколько выросла информация) по сравнению с тем, что было до разбиения.  \n",
    "4. **Выбор лучшего варианта**: Берётся признак, который даёт **наибольшее** уменьшение неопределённости (или наибольший прирост информации). В дереве решений этот признак становится «вопросом» в соответствующем узле.  \n",
    "5. **Повтор**: Для каждой ветви (подмножества данных) процесс повторяется, пока данные не станут достаточно «чистыми» (Gini близка к 0 или энтропия минимальна) или пока не будут выполнены другие критерии остановки.\n",
    "\n",
    "Таким образом, **Gini impurity** и **information gain** — это два тесно связанных способа оценить, «насколько хорошие» разбиения мы делаем в дереве решений, стремясь на каждом шаге максимально упростить задачу классификации, сократив смешанность классов.\n",
    "\n",
    "---\n",
    "**Gini impurity** (нечистота Джини) — это альтернатива энтропии, часто используется в алгоритме **CART** для построения деревьев решений.\n",
    "\n",
    "---\n",
    "\n",
    "### **Определение Gini impurity**\n",
    "\n",
    "Для множества объектов $S$, где каждый объект принадлежит одному из $k$ классов, Gini impurity определяется так:\n",
    "\n",
    "$$\n",
    "Gini(S) = 1 - \\sum_{i=1}^{k} p_i^2\n",
    "$$\n",
    "\n",
    "где:\n",
    "\n",
    "* $p_i$ — доля объектов класса $i$ в множестве $S$,\n",
    "* $k$ — число классов.\n",
    "\n",
    "---\n",
    "\n",
    "### **Пример**\n",
    "\n",
    "Пусть в узле 10 объектов:\n",
    "\n",
    "* 6 \"да\", 4 \"нет\"\n",
    "* $p_1 = \\frac{6}{10} = 0.6$, $p_2 = \\frac{4}{10} = 0.4$\n",
    "\n",
    "$$\n",
    "Gini = 1 - (0.6^2 + 0.4^2) = 1 - (0.36 + 0.16) = 1 - 0.52 = 0.48\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Условная Gini impurity (после разбиения)**\n",
    "\n",
    "Пусть признак делит множество на два подмножества:\n",
    "\n",
    "* $S_1$: 4 \"да\", 0 \"нет\" → $Gini(S_1) = 1 - 1^2 - 0^2 = 0$\n",
    "* $S_2$: 2 \"да\", 4 \"нет\" →\n",
    "\n",
    "  $$\n",
    "  p_1 = \\frac{2}{6},\\quad p_2 = \\frac{4}{6},\\quad Gini(S_2) = 1 - \\left(\\frac{2}{6}\\right)^2 - \\left(\\frac{4}{6}\\right)^2 = 1 - \\left(0.111 + 0.444\\right) = 0.445\n",
    "  $$\n",
    "\n",
    "Взвешенная Gini после разбиения:\n",
    "\n",
    "$$\n",
    "Gini_{after} = \\frac{4}{10} \\cdot 0 + \\frac{6}{10} \\cdot 0.445 = 0.267\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Gini Gain (уменьшение Gini impurity)**\n",
    "\n",
    "Аналогично Information Gain:\n",
    "\n",
    "$$\n",
    "\\text{Gini Gain} = Gini(S) - Gini_{after} = 0.48 - 0.267 = 0.213\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a88ac4b-0966-4f6d-a01f-5e1b019facbe",
   "metadata": {},
   "source": [
    "### Случайный лес (Random forest)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf9e95-a465-4539-bd13-517d22112ff0",
   "metadata": {},
   "source": [
    "**Случайный лес (Random Forest)** — это метод ансамблевого обучения, который объединяет в себе множество отдельных деревьев решений, чтобы получить более надёжное и точное предсказание по сравнению с каждым отдельным деревом. Его главная идея — создать «лес» из деревьев решений, где каждое дерево обучается на немного разных данных и/или разных признаках. В результате совмещаются сильные стороны нескольких моделей, а слабые стороны отдельных деревьев сглаживаются.\n",
    "\n",
    "---\n",
    "\n",
    "#### Основные принципы\n",
    "\n",
    "1. **Бэггинг (Bagging)**  \n",
    "   - При бэггинге каждое дерево обучается на **случайной подвыборке** (bootstrap) из исходного датасета. То есть данные выбираются с возвращением, в итоге некоторые объекты в одной подвыборке могут повторяться, а некоторые не попадут туда вовсе.  \n",
    "   - Это разнообразит получающиеся деревья, потому что каждое дерево «видит» немного разные данные.\n",
    "\n",
    "2. **Случайный выбор признаков**  \n",
    "   - Помимо случайной подвыборки объектов, в случайном лесе при каждом разбиении дерева выбирается **случайный набор признаков**, среди которых выбирается лучший.  \n",
    "   - Это ещё больше увеличивает разнообразие между деревьями, так как разные деревья могут использовать разные наборы признаков на каждом шаге.\n",
    "\n",
    "3. **Комбинирование результатов**  \n",
    "   - После обучения каждого дерева случайного леса, результаты (прогнозы) объединяются. Для задач классификации чаще всего берётся **большинство голосов** (majority vote). Для регрессии обычно берётся **среднее** предсказаний.  \n",
    "   - Такая агрегированная оценка, как правило, оказывается более стабильной и точной, чем у отдельных деревьев.\n",
    "\n",
    "---\n",
    "\n",
    "#### Почему это работает\n",
    "\n",
    "- **Деревья решений** склонны к переобучению, если их не ограничивать по глубине или другим параметрам. Но объединение многих переобученных деревьев, которые обучались на разных поднаборах данных и признаков, даёт в среднем хороший результат.  \n",
    "- **Разнообразие** между деревьями помогает «отменять» ошибки друг друга. Если одно дерево ошиблось на каком-то примере, другое дерево может дать правильный ответ. При голосовании неправильные предсказания могут «утонуть» в массе правильных.\n",
    "\n",
    "---\n",
    "\n",
    "#### Преимущества случайного леса\n",
    "\n",
    "1. **Высокая точность**: Обычно даёт одну из лучших комбинаций точности и стабильности.  \n",
    "2. **Устойчивость к шуму**: Разные деревья решения сглаживают влияние аномальных объектов.  \n",
    "3. **Параллельность**: Обучение деревьев может идти параллельно, так как каждое дерево строится независимо.  \n",
    "4. **Гибкость**: Хорошо подходит для задач как классификации, так и регрессии.\n",
    "\n",
    "---\n",
    "\n",
    "#### Недостатки\n",
    "\n",
    "1. **Потеря интерпретируемости**: Хотя каждое дерево само по себе интерпретируемо, объединение многих деревьев уже сложно объяснить человеку.  \n",
    "2. **Большее потребление ресурсов**: Нужно обучать и хранить большое количество деревьев, что может быть затратно по времени и памяти.  \n",
    "3. **Чувствительность к параметрам**: Нужно подобрать количество деревьев, глубину деревьев, количество признаков для выборок и т. д.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Случайный лес** — это группа (ансамбль) независимых деревьев решений, где каждое дерево обучается на случайно выбранном подмножестве данных и признаков. Итоговый прогноз получается путём объединения (голосования или усреднения) предсказаний всех деревьев. За счёт разнообразия деревьев метод даёт высокую точность, стабильность и устойчивость к переобучению, однако при этом теряется прозрачность (сложнее понять, «почему» алгоритм сделал то или иное предсказание, так как в игре много деревьев) и возрастают вычислительные затраты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fa25b5-7ff4-40b3-b096-1baabffd74b4",
   "metadata": {},
   "source": [
    "### Bagging, выборка признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192d563-015a-49ca-ae76-9aaa9074f905",
   "metadata": {},
   "source": [
    "**Bagging** (или «Bootstrap Aggregating») — это метод ансамблевого обучения, который улучшает стабильность и точность моделей, комбинируя результаты нескольких «базовых» моделей (например, деревьев решений). Каждый «базовый» алгоритм обучается на собственном поднаборе данных, отобранном из исходной выборки путём случайного выбора объектов **с возвращением** (bootstrap). \n",
    "\n",
    "**Выборка признаков** (feature subspace) — это дополнительный приём, при котором на каждом шаге обучения базового алгоритма (например, дерева решений) выбирается случайное подмножество признаков (столбцов данных). Другими словами, помимо случайного выбора самих объектов (строк данных), случайно выбираются и некоторые признаки (колонки). Таким образом, разные модели видят не только разные объекты, но и разные подмножества признаков.\n",
    "\n",
    "---\n",
    "\n",
    "#### Как это работает вместе\n",
    "\n",
    "1. **Bagging объектов**  \n",
    "   - Из исходного набора данных многократно выбирают bootstrap-выборку — подмножество объектов с возвращением.  \n",
    "   - Каждое дерево (или другая «базовая» модель) обучается на этой подвыборке. \n",
    "\n",
    "2. **Случайная выборка признаков**  \n",
    "   - При построении каждого дерева (или на каждой точке разбиения) подмножество признаков выбирается случайно.  \n",
    "   - Это дополнительно увеличивает разнообразие между деревьями, поскольку разные деревья видят разные подмножества признаков.\n",
    "\n",
    "3. **Объединение результатов**  \n",
    "   - Для задач классификации обычно берётся **голосование** (какой класс получил большинство голосов).  \n",
    "   - Для регрессии — усреднение предсказаний.  \n",
    "\n",
    "Объединение этих двух техник создаёт ещё больше разнообразия между моделями в ансамбле, что помогает повысить точность и устойчивость к переобучению. \n",
    "\n",
    "#### Преимущества\n",
    "\n",
    "- **Снижение переобучения**: Модели, обучающиеся на разных подвыборках и разных наборах признаков, «ошибаются по-разному», и ошибки в среднем компенсируются.  \n",
    "- **Лучшее обобщение**: В итоге ансамбль часто работает лучше и стабильнее, чем каждая отдельная модель.  \n",
    "\n",
    "#### Недостатки\n",
    "\n",
    "- **Большие вычислительные затраты**: Нужно обучать много моделей (деревьев), что может быть медленнее и требовать больше памяти.  \n",
    "- **Потеря интерпретируемости**: Каждый «базовый» алгоритм сам по себе может быть понятным, но суммарный ансамбль из множества моделей уже сложнее интерпретировать.  \n",
    "\n",
    "Таким образом, **bagging** (случайные подмножества объектов) и **случайная выборка признаков** (случайные подмножества признаков) вместе делают ансамбль более разнообразным и, как правило, более точным и надёжным."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97107219-06d7-477f-a03e-0d118e5fd408",
   "metadata": {},
   "source": [
    "### Дерево регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da3abdf-4616-4950-97f3-b0b01bbc6b8d",
   "metadata": {},
   "source": [
    "**Дерево регрессии** — это разновидность дерева решений, которая применяется в задачах **прогнозирования числового значения**, а не для классификации. Вместо того чтобы предсказывать класс объекта (кошка/собака, да/нет и т.п.), мы пытаемся предсказать число (например, цену дома или температуру).\n",
    "\n",
    "---\n",
    "\n",
    "#### Основная идея\n",
    "\n",
    "- **Последовательное разбиение**: Как и в классическом дереве решений, мы пошагово делим данные на подмножества с помощью условий по признакам (например, «Если площадь дома больше 50 м², то идём влево, иначе идём вправо»).  \n",
    "- **Однородность по предсказываемому значению**: В дереве регрессии мы стремимся, чтобы в каждой «ветви» (подмножестве данных) объекты были как можно ближе друг к другу по числовому выходу (например, чтобы цены домов в одной ветви были примерно одинаковы).\n",
    "\n",
    "---\n",
    "\n",
    "#### Как формируется дерево регрессии\n",
    "\n",
    "1. **Выбираем признак и порог**: Для корневого узла смотрим, какой признак (и его пороговое значение) лучше всего делит данные так, чтобы объекты в каждой ветви имели наиболее похожие (близкие) целевые значения.  \n",
    "   - Критерий, в соответствии с которым выбираем «лучший» признак, обычно связан с минимизацией среднеквадратичной ошибки (MSE) или другим мерилом разброса значений в ветвях.\n",
    "\n",
    "2. **Делим данные**: После выбора признака и порога, данные распадаются на две ветви (или более, если тип разбиения другой). Каждое подмножество теперь обрабатывается аналогичным образом (рекурсивно).\n",
    "\n",
    "3. **Критерий остановки**: Процесс продолжается, пока либо не достигнем максимально допустимой глубины дерева, либо в текущем узле очень мало объектов, либо значения объектов достаточно однородны (ошибка в ветви низкая). В таком случае формируется **лист** дерева.\n",
    "\n",
    "4. **Предсказание**: В конечном листе хранится **числовое значение**, которое обычно является средним от целевых значений обучающих объектов, попавших в этот лист. Когда нужно сделать прогноз для нового объекта, мы просто «спускаемся» по дереву, следуя условиям, пока не окажемся в листе, и берём значение, хранящееся в этом листе.\n",
    "\n",
    "---\n",
    "\n",
    "#### Пример использования\n",
    "\n",
    "Допустим, мы хотим предсказать цену дома:\n",
    "\n",
    "1. **Признаки**: Площадь, количество комнат, возраст дома, район и т.д.  \n",
    "2. **Целевое значение**: Цена (число).\n",
    "\n",
    "**Дерево регрессии**:\n",
    "- Сначала может спросить: «Возраст дома меньше 10 лет?».  \n",
    "   - Если да — идём в левую ветвь.  \n",
    "   - Если нет — идём в правую.  \n",
    "- Затем в одной ветви может спросить: «Площадь больше 80 м²?».  \n",
    "   - И так далее.  \n",
    "\n",
    "В каждом листе мы храним среднюю цену домов, которые туда попали при обучении. Для нового дома мы движемся по узлам, отвечая на вопросы, и в конечном листе получаем среднюю цену уже обученных домов.\n",
    "\n",
    "---\n",
    "\n",
    "#### Плюсы и минусы\n",
    "\n",
    "**Плюсы**:\n",
    "1. **Простая интерпретация**: Понятно, по каким признакам и порогам дерево разделяет данные.\n",
    "2. **Быстрое предсказание**: Для одного объекта нужно пройтись по небольшому числу условий (глубине дерева).\n",
    "\n",
    "**Минусы**:\n",
    "1. **Склонность к переобучению**: Если разрешить дереву расти без ограничений, оно может слишком точно «выучить» конкретные объекты в листьях и потерять способность к обобщению.\n",
    "2. **Менее гладкое предсказание**: Поскольку значение в листе — это среднее, у дерева регрессии могут быть «скачки» на границах разбиения признаков.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Дерево регрессии** — это та же идея «дерева решений», но адаптированная для **числового** прогнозирования. Оно пошагово разбивает данные по признакам и порогам, стараясь, чтобы в каждой ветви значения целевой переменной были как можно более однородными. В конечном листе мы берём среднее значение, и это даёт нам предсказание для новых объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06eb43b-4435-4a9d-9fdd-15afa69ba580",
   "metadata": {},
   "source": [
    "### Сокращение дерева (pruning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee220e-ad53-4aab-8036-d3bfddeb2ab8",
   "metadata": {},
   "source": [
    "**Сокращение дерева (pruning)** — это процесс упрощения дерева решений после его первоначального построения, чтобы избежать переобучения и улучшить обобщающую способность модели. Изначально дерево может «выучивать» множество тонких (и иногда случайных) закономерностей из обучающей выборки, что приводит к чрезмерной глубине и количеству ветвлений. Pruning позволяет «обрезать» незначимые узлы и ветви, сохраняя только наиболее важные разбиения.\n",
    "\n",
    "---\n",
    "\n",
    "#### Почему дерево может переобучаться\n",
    "\n",
    "- **Глубокое дерево**: Во время обучения дерево может расти практически без ограничений, пока не достигнет очень маленьких подмножеств данных в листах. В результате оно начинает отражать и случайные «шумы» в обучающей выборке, а не истинные закономерности.\n",
    "- **Сложность**: Чем более детально дерево пытается описать данные, тем больше возникает риск, что оно «запомнит» отдельные случайные особенности обучающего набора, не пригодные для будущих (тестовых) данных.\n",
    "\n",
    "---\n",
    "\n",
    "#### Суть сокращения дерева\n",
    "\n",
    "1. **Определить несущественные части**: Сокращение дерева заключается в выявлении ветвей и узлов, которые дают минимальный вклад в улучшение качества предсказания.  \n",
    "2. **Упрощение структуры**: Удаляя или «обрезая» такие ветви, мы уменьшаем глубину дерева и число листьев, делая модель более «общей» и менее склонной к переобучению.  \n",
    "3. **Повышение обобщающей способности**: Простое дерево обычно лучше обобщает знания на новых данных. Это может привести к слегка большей ошибке на обучающей выборке, но зато ошибка на новых данных (обучении с «нуля») обычно снижается.\n",
    "\n",
    "---\n",
    "\n",
    "#### Виды pruning\n",
    "\n",
    "1. **Pre-pruning (предварительное сокращение)**:  \n",
    "   - На каждом шаге построения дерева проверяют, стоит ли продолжать деление или остановиться раньше.  \n",
    "   - Если улучшение качества слишком мало, дальнейшее углубление дерева прекращают.\n",
    "\n",
    "2. **Post-pruning (последующее сокращение)**:  \n",
    "   - Сначала дерево строится до конца (возможно, очень детально).  \n",
    "   - Затем проводится анализ, какая часть дерева может быть «обрезана» (узлы или ветви), чтобы не ухудшить существенно обобщающую способность.  \n",
    "   - Проще говоря, смотрят на субветви, чья «стоимость ошибки» для общей модели незначительна или даже «возмещается» улучшением в других местах.\n",
    "\n",
    "---\n",
    "\n",
    "#### Как определяется, что ветвь «лишняя»\n",
    "\n",
    "- **Анализ улучшения качества**: Смотрят, насколько конкретная ветвь снижала ошибку на обучающей выборке и (желательно) на валидационной. Если без этой ветви (с её заменой на лист) качество существенно не портится, ветвь «обрезают».  \n",
    "- **Специальные критерии**: Могут использоваться показатели вроде «число неправильных классификаций» (для классификации) или «среднеквадратичная ошибка» (для регрессии), штрафы за сложность и т. п.\n",
    "\n",
    "---\n",
    "\n",
    "#### Преимущества pruning\n",
    "\n",
    "1. **Улучшение обобщающей способности**: Уменьшая сложность дерева, мы снижаем риск переобучения.  \n",
    "2. **Повышение интерпретируемости**: Более короткое дерево проще понять, визуализировать и объяснять.  \n",
    "3. **Стабильность**: Менее глубокое дерево менее чувствительно к небольшим изменениям в данных.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Сокращение дерева** (pruning) — это ключевой этап улучшения дерева решений, позволяющий убрать «лишние» ветви, которые лишь запоминают случайные детали обучающего набора, но не помогают в предсказании новых данных. В итоге, дерево становится короче, проще, стабильнее и (обычно) точнее на реальных задачах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c29bd4-fd69-43d1-b095-069837ee12c6",
   "metadata": {},
   "source": [
    "# Бустинг (Boosting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a785618-14a7-4017-ac65-9c5ebb8d132a",
   "metadata": {},
   "source": [
    "### Понятие бустинга."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d51f4-61b6-4aa5-8255-74f42c4eddb7",
   "metadata": {},
   "source": [
    "**Бустинг (Boosting)** — это метод ансамблевого обучения, при котором мы **последовательно** создаём множество «слабых» моделей (чаще всего деревьев решений) таким образом, чтобы каждая новая модель старалась «исправить» ошибки предыдущих. В результате эти слабые модели, объединившись, формируют «усиленный» (boosted) алгоритм, который обычно превосходит каждую из них по отдельности.\n",
    "\n",
    "---\n",
    "\n",
    "#### Суть бустинга\n",
    "\n",
    "1. **Слабые модели**: Идея в том, чтобы взять модель, которая сама по себе даёт результат чуть лучше случайного угадывания, — такую модель называют «слабым классификатором» (weak learner).\n",
    "\n",
    "2. **Пошаговое улучшение**: Строится первая модель на данных. Затем анализируется, какие объекты были классифицированы (или предсказаны) неправильно. Во вторую модель добавляется «фокус» на эти ранее ошибочно предсказанные объекты, чтобы следующая модель лучше училась на сложных примерах.\n",
    "\n",
    "3. **Последовательное обучение**: Каждая новая модель обучается так, чтобы «исправлять» ошибки предыдущих. Итоговая предсказательная способность складывается из «голосов» (в классификации) или «суммы предсказаний» (в регрессии) всех моделей, но последние модели имеют больший «вес», поскольку они учитывают ошибки предыдущих.\n",
    "\n",
    "4. **Ансамбль**: По итогу все слабые классификаторы (деревья решений, например) объединяются. Итоговое решение принимается либо путём суммирования результатов, либо через механизм «веса» каждого классификатора. Таким образом, ошибки одного классификатора компенсируются другими, что даёт сильную итоговую модель.\n",
    "\n",
    "---\n",
    "\n",
    "#### Преимущества бустинга\n",
    "\n",
    "1. **Высокая точность**: Бустинг даёт одни из лучших результатов на большинстве задач, где данные представлены в табличном виде с признаками (карты, таблицы и т. д.).\n",
    "2. **Гибкость**: Можно применять разные «слабые» модели и разные способы «усиления», подстраиваясь под особенности данных.\n",
    "3. **Инкрементальное обучение**: Новые «слабые» модели можно добавлять пошагово, анализируя уже построенные классификаторы.\n",
    "\n",
    "---\n",
    "\n",
    "#### Недостатки\n",
    "\n",
    "1. **Чувствительность к шуму**: Если в данных много шумовых объектов, сильное «подстраивание» под ошибки может привести к переобучению.\n",
    "2. **Сложность настройки**: Есть несколько гиперпараметров (например, сколько «слабых» моделей, какая глубина деревьев и т. д.), которые нужно аккуратно подбирать.\n",
    "3. **Время обучения**: Последовательное обучение множества моделей может быть долгим, особенно на больших наборах данных.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Бустинг** — это метод, когда мы **последовательно** строим много простых моделей, каждая из которых старается исправлять ошибки предыдущих. Складывая результаты этих «слабых» моделей, мы получаем «сильный» (усиленный) алгоритм, который часто даёт превосходные результаты в задачах классификации и регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffb02d-26b6-4429-b39d-7c44a93c83c9",
   "metadata": {},
   "source": [
    "### Градиентный бустинг."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab82e7fc-a256-48da-8598-3435ba34dd0b",
   "metadata": {},
   "source": [
    "**Градиентный бустинг** — это особый вариант бустинга, в котором каждая новая «слабая» модель (обычно дерево решений) обучается на **остатках** или **ошибках**, оставшихся после всех предыдущих моделей, но делает это, «двигаясь» по **градиенту** функции потерь. Проще говоря, он пошагово строит ансамбль, где каждая новая модель старается исправить то, с чем не справились все предыдущие, используя представление ошибки как градиента (направления наибольшего улучшения).\n",
    "\n",
    "---\n",
    "\n",
    "#### Основная идея\n",
    "\n",
    "1. **Начало с простой модели**  \n",
    "   - Начинаем с очень «грубой» модели-предсказания (например, константного предсказания).  \n",
    "\n",
    "2. **Поэтапное улучшение**  \n",
    "   - На каждом шаге мы вычисляем, в каком направлении нужно «двигаться», чтобы улучшить предсказания.  \n",
    "   - В контексте градиентного бустинга это направление (градиент) говорит, как «исправлять» текущие ошибки или остатки, оставшиеся после предыдущих шагов.  \n",
    "\n",
    "3. **Новая слабая модель**  \n",
    "   - Находим следующую небольшую модель (чаще всего короткое дерево решений), которая лучше всего «убирает» текущие ошибки.  \n",
    "   - При этом модель обучается не на изначальные ответы, а на **остатки** (то есть на разницу между реальными ответами и тем, что уже предсказала композиция на данный момент).\n",
    "\n",
    "4. **Добавление к ансамблю**  \n",
    "   - Модель добавляется к ансамблю с некоторым «весом», показывающим, насколько сильное её влияние на общее предсказание.  \n",
    "   - Результирующее предсказание становится суммой (или другой комбинацией) всех предыдущих «слабых» моделей и новой.\n",
    "\n",
    "5. **Повтор**  \n",
    "   - Процесс повторяется, пока не достигнем заданного количества итераций или не увидим, что ошибки уже минимальны.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Почему «градиент»?\n",
    "\n",
    "- **Градиент** — это направление наибольшего возрастания некоторой функции. В задачах машинного обучения мы хотим **минимизировать** функцию потерь.  \n",
    "- Каждая новая модель «двигается» в направлении уменьшения потерь — именно это направление задаёт градиент. Тем самым пошагово корректируем «курс» предсказаний в сторону улучшения.\n",
    "\n",
    "---\n",
    "\n",
    "#### Преимущества и недостатки\n",
    "\n",
    "**Преимущества**:  \n",
    "1. **Высокая точность**: Градиентный бустинг даёт одни из лучших результатов в задачах с табличными данными.  \n",
    "2. **Гибкость**: Можно использовать разные типы потерь (например, для регрессии, классификации и т. д.), а также настраивать глубину деревьев, скорость обучения и др.\n",
    "\n",
    "**Недостатки**:  \n",
    "1. **Чувствительность к шуму**: Слишком агрессивное «движение по градиенту» может привести к переобучению, если данные шумные.  \n",
    "2. **Много гиперпараметров**: Нужно аккуратно выбирать скорость обучения (learning rate), количество итераций, глубину деревьев и т. д.  \n",
    "3. **Время обучения**: Нужно последовательно обучать много деревьев, что может быть довольно медленно на больших наборах данных.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Градиентный бустинг** — это бустинг, где каждая новая модель обучается на **градиенте** функции потерь (то есть на текущих ошибках), стремясь их исправить. Итоговая композиция (сумма всех «слабых» моделей) обычно получается очень сильной и часто показывает одну из лучших точностей среди ансамблевых методов, особенно при работе с табличными данными."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfecc8f0-886c-4434-9a21-2a829c3e6df1",
   "metadata": {},
   "source": [
    "### OneRule Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97829401-74ec-4558-8b4d-c5eac10deda0",
   "metadata": {},
   "source": [
    "**OneRule** (или «Правило один-атрибут») — это очень простой классификатор, который для каждого объекта выбирает класс, исходя лишь из **одного** признака. Он ищет признак, «лучше всего» делящий данные на классы, и затем для каждого возможного значения этого признака предсказывает наиболее вероятный класс. Так получается единственное правило вида: «Если признак = A, то класс X, иначе класс Y...»\n",
    "\n",
    "**OneRule Boosting** — это когда мы используем этот простой метод (OneRule) в качестве «базового» (слабого) классификатора в алгоритме бустинга. То есть:\n",
    "\n",
    "1. **Инициализация**: Сначала делаем одну «OneRule», которую обучаем на всей выборке.\n",
    "2. **Анализ ошибок**: Смотрим, какие объекты были предсказаны неверно.\n",
    "3. **Следующее правило**: Строим новую «OneRule», фокусируясь (приоритетом, весами) на тех объектах, где первая «OneRule» ошиблась.\n",
    "4. **Повтор**: Собираем много таких правил, каждое из которых старается исправить недочёты предыдущих.\n",
    "\n",
    "В итоге получаем ансамбль из последовательных правил «OneRule», каждое «правило» учитывает ошибки предыдущих. При финальном предсказании эти правила «голосуют» или суммируются в зависимости от их точности. Так слабые, но разные правила складываются в более сильный алгоритм:\n",
    "\n",
    "- **OneRule** даёт предсказания, глядя лишь на один признак.  \n",
    "- **Boosting** позволяет собрать много таких простых «однопризнаковых» правил, постепенно уменьшая ошибки и повышая точность.\n",
    "\n",
    "Таким образом, **OneRule Boosting** — это бустинговая композиция из очень простых правил, каждое из которых смотрит на один-единственный признак, и благодаря совместной работе они дают более мощный классификатор, чем отдельный OneRule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330fa993-ef7f-4399-b518-ad01884277b6",
   "metadata": {},
   "source": [
    "### Adaboost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea55d8eb-9843-4154-bd83-206773060108",
   "metadata": {},
   "source": [
    "**AdaBoost** (Adaptive Boosting) — это один из самых простых и известных алгоритмов бустинга. Его основная идея состоит в том, чтобы **последовательно** строить серию простых «слабых» моделей (обычно деревьев небольшой глубины, либо простых правил), где каждая новая модель уделяет большее внимание тем объектам, на которых предыдущие модели ошибались. \n",
    "\n",
    "---\n",
    "\n",
    "#### Основная идея AdaBoost\n",
    "\n",
    "1. **Начальное обучение**  \n",
    "   - Сначала все объекты обучающей выборки имеют равный «вес» — то есть алгоритм рассматривает их как одинаково важные.  \n",
    "   - Обучается первая «слабая» модель (например, короткое дерево решений), которая пытается классифицировать все объекты.\n",
    "\n",
    "2. **Анализ ошибок**  \n",
    "   - После предсказаний первой модели мы смотрим, на каких объектах она ошиблась.  \n",
    "   - Если объект был классифицирован неверно, его вес увеличивают (алгоритм «обращает на него больше внимания»). Если объект классифицирован правильно, его вес, напротив, может уменьшиться.\n",
    "\n",
    "3. **Обучение следующей модели**  \n",
    "   - Теперь в выборке объекты с более высокими весами (те, что были ошибочно предсказаны) для алгоритма более «значимы».  \n",
    "   - Вторая «слабая» модель обучается уже с учётом этих новых весов, стараясь исправить ошибки предыдущей.\n",
    "\n",
    "4. **Повтор**  \n",
    "   - Процесс повторяется заданное число итераций: каждая новая модель «учится» лучше справляться с теми случаями, которые ещё не покрыли предыдущие.  \n",
    "\n",
    "5. **Объединение результатов**  \n",
    "   - Наконец, все «слабые» модели складывают (или «голосуют» с некоторыми весами) свои предсказания. Если в задаче классификация, то AdaBoost весовым большинством выбирает класс, если регрессия — суммирует предсказания.\n",
    "\n",
    "---\n",
    "\n",
    "#### Ключевые моменты\n",
    "\n",
    "- **Адаптивность**: После каждой итерации алгоритм «адаптируется» к ошибкам, повышая вес неправильно классифицированных объектов. Так он концентрируется на сложных примерах.  \n",
    "- **«Слабые» модели**: AdaBoost требует, чтобы каждая модель была чуть лучше случайного угадывания, но не обязательно очень мощной.  \n",
    "- **Построение ансамбля**: Итоговый ответ получается путём комбинирования (голосования) всех «слабых» моделей, но с разными весами, которые зависят от точности каждой модели.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Преимущества AdaBoost\n",
    "\n",
    "1. **Высокая точность**: Для многих задач табличных данных AdaBoost даёт хороший результат.  \n",
    "2. **Простая реализация**: Принцип понятен и просто реализуется.  \n",
    "3. **Нет переобучения «сильных» моделей**: Можно использовать простые модели (правила, короткие деревья), а общий ансамбль будет достаточно «сильным».  \n",
    "\n",
    "---\n",
    "\n",
    "#### Недостатки AdaBoost\n",
    "\n",
    "1. **Чувствительность к выбросам**: Поскольку алгоритм может всё более увеличивать вес «трудных» объектов, выбросы могут сильно искажать обучение.  \n",
    "2. **Нужна аккуратная настройка**: В частности, число итераций, сложность «слабых» моделей и начальные веса.  \n",
    "3. **Последовательное обучение**: Не так просто распараллелить, так как каждая итерация зависит от результатов предыдущей.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**AdaBoost** — это классический пример бустинга, где каждая «слабая» модель обучается, уделяя больше внимания ошибкам всех предыдущих. В результате формируется «сильный» ансамбль, способный улучшать качество по сравнению с каждой отдельной моделью, и демонстрирующий одну из ключевых идей бустинга: **последовательное исправление ошибок**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03de024b-be8c-44f0-8ecd-4fc0e50672ec",
   "metadata": {},
   "source": [
    "### Бустинг деревьев."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed411be-c677-4217-97d8-379057ba44ec",
   "metadata": {},
   "source": [
    "**Бустинг деревьев** — это разновидность бустинга, где в качестве «слабых» моделей на каждом шаге используются **короткие деревья решений** (часто очень маленькие, например, глубины 1–5). Идея состоит в том, что мы строим множество последовательных деревьев, где каждое новое дерево старается исправить ошибки (остатки) всех предыдущих, а итоговое предсказание складывается из ответов каждого дерева с учётом их весов.\n",
    "\n",
    "---\n",
    "\n",
    "#### Как работает бустинг деревьев пошагово\n",
    "\n",
    "1. **Начало с простой модели**  \n",
    "   - Сначала берётся самая простая «нулевая» модель (иногда константа, среднее по целевой переменной и т. д.).  \n",
    "   - Эту модель можно считать первым приближением, которое далее будем улучшать.\n",
    "\n",
    "2. **Построение первого дерева**  \n",
    "   - Строим небольшое дерево решений (часто ограничивают глубину 1–5), сосредоточенное на исправлении текущих ошибок или на моделировании текущих «остатков».  \n",
    "   - Иными словами, дерево обучается «объяснять» те аспекты данных, которые наша текущая композиция ещё не объяснила.\n",
    "\n",
    "3. **Обновление композиции**  \n",
    "   - После построения дерева добавляем его в нашу сумму предсказаний (для регрессии — прибавляем ответы дерева, для классификации — прибавляем оценки/вероятности и т. д.).  \n",
    "   - Теперь итоговое предсказание уже учитывает и новое дерево.\n",
    "\n",
    "4. **Снова вычисляем ошибки (остатки)**  \n",
    "   - Смотрим, какие объекты теперь недостаточно хорошо предсказаны новой суммой (всеми деревьями вместе).  \n",
    "   - Формируем новую цель (или «остатки») для следующего дерева.\n",
    "\n",
    "5. **Следующее дерево**  \n",
    "   - Обучаем второе короткое дерево, фокусируясь на «недочётах» предыдущих шагов.  \n",
    "   - Добавляем его в ансамбль.\n",
    "\n",
    "6. **Повтор процесса**  \n",
    "   - Продолжаем так строить новые деревья, каждое из которых старается исправить всё, что не учли предыдущие.  \n",
    "   - Когда достигнем заданного числа деревьев или качество (ошибка) перестанет улучшаться, останавливаемся.\n",
    "\n",
    "7. **Итоговое предсказание**  \n",
    "   - Сумма (или иная комбинация) предсказаний всех деревьев даёт финальный результат.  \n",
    "   - В классификации обычно берут вероятностные выходы (сигмоиды/софтмаксы), которые потом переводят в классы. Для регрессии просто суммируют выходы каждого дерева.\n",
    "\n",
    "---\n",
    "\n",
    "#### Преимущества\n",
    "\n",
    "1. **Высокая точность**  \n",
    "   Бустинг деревьев на практике часто показывает одно из лучших качеств предсказания на задачах с табличными данными.\n",
    "\n",
    "2. **Гибкость**  \n",
    "   Можно применять разные функции потерь (для классификации, регрессии и т. д.). Количество деревьев, глубину каждого дерева, скорость обучения (learning rate) — всё это настраивается.\n",
    "\n",
    "3. **Устойчивость к разным типам признаков**  \n",
    "   Деревья могут работать как с числовыми, так и категориальными признаками (с определённой обработкой).\n",
    "\n",
    "---\n",
    "\n",
    "#### Недостатки\n",
    "\n",
    "1. **Чувствительность к шуму**  \n",
    "   Если не применять регуляризацию и ограничения на деревья, метод может переобучиться на выбросах или сложных паттернах.\n",
    "\n",
    "2. **Много гиперпараметров**  \n",
    "   Нужно подбирать глубину деревьев, число деревьев, скорость обучения (learning rate) и т. д., что усложняет применение.\n",
    "\n",
    "3. **Относительно долго обучается**  \n",
    "   Поскольку каждое дерево строится последовательно, бустинг деревьев часто работает медленнее, чем методы, которые могут строить деревья параллельно (например, случайный лес).\n",
    "\n",
    "---\n",
    "\n",
    "#### Типичные реализации\n",
    "\n",
    "- **Gradient Boosting Machine (GBM)**  \n",
    "  Классический градиентный бустинг, который обучает деревья на остатках с учётом градиента функции потерь.\n",
    "\n",
    "- **XGBoost**  \n",
    "  Популярная библиотека, оптимизированная по скорости и памяти, с дополнительными трюками вроде регуляризации, что повышает устойчивость.\n",
    "\n",
    "- **LightGBM**  \n",
    "  Ещё одна библиотека бустинга деревьев, фокусирующаяся на быстром обучении и низком расходе памяти, используя специальные техники построения дерева.\n",
    "\n",
    "- **CatBoost**  \n",
    "  Библиотека от Яндекс, которая хорошо работает с категориальными признаками и может автоматически их обрабатывать.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Бустинг деревьев** — это мощная техника: мы **последовательно строим много маленьких деревьев**, каждое из которых концентрируется на ещё не исправленных ошибках. Итоговая модель получается достаточно сильной, сочетающей преимущества деревьев решений и ансамблевых методов. Однако она требует аккуратной настройки и может потребовать больше вычислительных ресурсов по сравнению с другими методами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9638c26-5016-4aaa-bee6-1fc6df08911e",
   "metadata": {},
   "source": [
    "# Байесовский классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe2e791-6aff-4537-9f5c-4e792683fb26",
   "metadata": {},
   "source": [
    "### Условная вероятность. Теорема Байеса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf3d6b9-3268-49e6-b784-a071a48161a9",
   "metadata": {},
   "source": [
    "**Байесовский классификатор** — это метод, основанный на вероятностном подходе к классификации. Он использует **теорему Байеса** и понятие **условной вероятности**, чтобы определить, какова вероятность того, что объект принадлежит к определённому классу, учитывая его признаки.\n",
    "\n",
    "---\n",
    "\n",
    "#### Условная вероятность\n",
    "\n",
    "**Условная вероятность** — это вероятность события A, если мы уже знаем, что произошло событие B. Проще говоря, если у нас есть информация о B, как она влияет на нашу уверенность, что A тоже произойдёт?\n",
    "\n",
    "**Пример**:  \n",
    "- Допустим, событие A — «Сегодня пойдёт дождь», а событие B — «На небе много серых туч». Если мы уже видим тучи, то наша уверенность в том, что будет дождь, повышается.  \n",
    "- Без знания о тучах мы имели бы одну оценку вероятности дождя, но теперь, учитывая, что тучи есть, наша оценка меняется.\n",
    "\n",
    "---\n",
    "\n",
    "#### Теорема Байеса (интуитивное объяснение)\n",
    "\n",
    "**Теорема Байеса** говорит, как мы можем **пересмотреть** нашу изначальную «догадку» (представление о вероятности) события, если мы получили новую информацию.\n",
    "\n",
    "1. **Изначальная догадка** (априорная вероятность) — это наша уверенность в событии до того, как мы увидели текущие признаки.  \n",
    "2. **Наблюдаем новые признаки (дополнительная информация)**: Эти признаки могут сделать событие более или менее вероятным по сравнению с тем, что мы думали изначально.  \n",
    "3. **Обновляем (апостериорная вероятность)**: Мы учитываем, насколько эти признаки связаны с событием, и меняем нашу уверенность в его наступлении.\n",
    "\n",
    "**Пример**:  \n",
    "- Пусть изначально мы предполагаем, что шанс дождя равен 30%.  \n",
    "- Узнаём, что на небе появились тучи. Если тучи обычно сопровождают дождь, мы повышаем оценку вероятности дождя, скажем, до 70%.  \n",
    "- Формально, Байес говорит: «Вероятность события после наблюдения» = «Вероятность события до наблюдения, умноженная на то, насколько часто при этом событии бывают такие наблюдения», и делится на «вероятность таких наблюдений вообще».\n",
    "\n",
    "---\n",
    "\n",
    "#### Как это используется в Байесовском классификаторе\n",
    "\n",
    "1. **Классы**: У нас есть несколько возможных классов (пример: «спам» или «не спам»).  \n",
    "2. **Признаки**: Мы видим признаки объекта (например, слова в письме, его длина и т. п.).  \n",
    "3. **Цель**: Хотим найти, к какому классу объект вероятнее всего принадлежит, учитывая эти признаки.\n",
    "\n",
    "**Байесовский подход**:  \n",
    "- У нас есть **априорные вероятности** классов (например, как часто вообще приходит спам).  \n",
    "- Для нового объекта мы видим его признаки. По ним мы смотрим: «Какова вероятность, что объект относится к классу A, если у него есть такие признаки?»  \n",
    "- По теореме Байеса мы «переворачиваем» задачу: «Насколько часто такие признаки встречаются в классе A, по сравнению с другим классом B?»  \n",
    "- И наконец выбираем класс, для которого эта обновлённая вероятность оказывается самой большой.\n",
    "\n",
    "---\n",
    "\n",
    "#### На интуитивном уровне\n",
    "\n",
    "- Если мы знаем, что слово «скидка» обычно встречается в письмах, которые на 80% являются спамом, а слово «привет» обычно встречается в 10% писем, которые являются спамом, то появление слова «скидка» будет значительно указывать на спам, а появление «привет» — не так сильно.  \n",
    "- Байесовский классификатор «суммирует» эти наблюдения по всем признакам и даёт итоговый «балл» (вероятность), на основании которого делается вывод.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Байесовский классификатор** основан на теореме Байеса и понятии **условной вероятности**. Он вычисляет, насколько вероятно, что объект принадлежит к определённому классу, учитывая наблюдаемые признаки. Это делается путём обновления «априорной» вероятности класса с учётом «насколько часто такие признаки встречаются внутри класса» и «насколько часто они встречаются в целом». \n",
    "\n",
    "**Основные моменты**:  \n",
    "- Условная вероятность отвечает на вопрос, как новая информация (признаки) влияет на нашу уверенность в событии (классе).  \n",
    "- Теорема Байеса — формула, которая позволяет корректно пересчитывать вероятность события, исходя из новой информации.  \n",
    "- Байесовский классификатор использует этот принцип, чтобы находить класс с наибольшей «апостериорной» вероятностью после учёта признаков объекта."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45cf8e6-c64d-4527-a463-f8e2393a5d2c",
   "metadata": {},
   "source": [
    "### Наивный классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8696e9e-ed17-47ca-b8be-1f7d87824e12",
   "metadata": {},
   "source": [
    "**Наивный байесовский классификатор** (часто называемый просто «наивный классификатор») — это упрощённая версия байесовского классификатора. Его ключевая особенность заключается в «наивном» предположении о том, что **все признаки (факторы) объекта независимы друг от друга** при условии класса. Это упрощает вычисления, но при этом в реальности признаки обычно не бывают полностью независимыми.\n",
    "\n",
    "---\n",
    "\n",
    "#### Основная идея\n",
    "\n",
    "1. **Байесовский подход**:  \n",
    "   - Мы хотим оценить вероятность, что объект принадлежит к классу $C$, основываясь на его признаках $(x_1, x_2, \\dots, x_n)$.  \n",
    "\n",
    "2. **Наивное предположение**:  \n",
    "   - Предполагаем, что все признаки независимы друг от друга при условии класса. То есть, если мы знаем класс объекта, то значение одного признака якобы не влияет на вероятность другого.  \n",
    "\n",
    "3. **Простота вычислений**:  \n",
    "   - Благодаря этому предположению, вероятность «совместного появления» всех признаков в рамках одного класса можно разложить в виде произведения (если бы мы делали точный байесовский расчёт без этого допущения, пришлось бы учитывать все сложные связи между признаками).  \n",
    "   - В результате формулы и расчёты становятся гораздо проще и быстрее.\n",
    "\n",
    "---\n",
    "\n",
    "#### Пример из жизни\n",
    "\n",
    "- Представим, что мы классифицируем письма на «спам» и «не спам».  \n",
    "- В действительности, наличие одного слова может иметь определённую связь с наличием другого (например, «скидка» и «купить» часто встречаются вместе).  \n",
    "- **Наивный** байесовский классификатор всё равно предполагает, что каждое слово встречается независимо от других, при условии, что письмо — «спам» или «не спам».  \n",
    "\n",
    "Несмотря на очевидную «наивность» такого предположения, такой классификатор даёт часто **хорошие результаты** на практике: он быстро обучается и обрабатывает новые примеры.\n",
    "\n",
    "---\n",
    "\n",
    "#### Плюсы\n",
    "\n",
    "1. **Быстрая скорость обучения**: Благодаря упрощённым вычислениям, модель очень быстро обучается даже на больших объёмах данных.  \n",
    "2. **Низкие требования к памяти**: Не нужно хранить сложные структуры данных, достаточно статистики о признаках (например, частоты слов).  \n",
    "3. **Неплохое качество предсказания**: Наивный классификатор работает удивительно хорошо для ряда задач, особенно в фильтрации спама и в классификации текстов.\n",
    "\n",
    "#### Минусы\n",
    "\n",
    "1. **Нереалистичное предположение независимости**: Реальные признаки часто коррелированы (связаны). Это может приводить к неточным вероятностным оценкам.  \n",
    "2. **Менее гибок, чем более сложные модели**: Если данные сильно нарушают предположение о независимости, результат может проигрывать более продвинутым моделям.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Наивный классификатор** — это простой и быстрый метод, основанный на байесовском подходе, но с «наивным» допущением о независимости признаков. Он широко используется для **текстовой классификации** (спам-фильтры, тематический анализ) и в других сферах, благодаря своей скорости, лёгкости реализации и неожиданно неплохим результатам, несмотря на упрощённое предположение об отсутствии связей между признаками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc34f31-db95-4a7d-aecd-74467f8c6b21",
   "metadata": {},
   "source": [
    "### Оценка функции плотности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b923b8-f70d-4fed-a08f-71527343075d",
   "metadata": {},
   "source": [
    "**Оценка функции плотности** (Density Estimation) — это задача статистики и машинного обучения, в которой мы пытаемся приблизить (оценить) «форму» неизвестного распределения данных. Иными словами, мы хотим понять, как «распределены» объекты (точки) в нашем пространстве признаков, какие области пространства чаще встречаются, а какие — реже.\n",
    "\n",
    "---\n",
    "\n",
    "#### Для чего нужна оценка плотности?\n",
    "\n",
    "1. **Поиск структуры в данных**: Если мы знаем «где» и «как плотно» располагаются объекты, можем находить зоны с высокой или низкой концентрацией точек (например, области с аномалиями, или области, характеризующие разные кластеры).\n",
    "2. **Проверка вероятности**: Иногда необходимо оценить вероятность того, что новый объект «логичен» для данного набора данных (как часто встречаются подобные ему). Если значение плотности очень мало, объект может быть «выбросом» или сильно отличаться от основной массы данных.\n",
    "3. **Сжатие и генерация**: Если знаем функцию плотности, мы можем воспроизводить новые объекты, «похожие» на обучающие данные. Это лежит в основе генеративных моделей.\n",
    "\n",
    "---\n",
    "\n",
    "#### Как это делается?\n",
    "\n",
    "#### 1. Параметрические методы\n",
    "\n",
    "- **Предполагаем** форму распределения (например, гауссовское, экпоненциальное и т. д.).  \n",
    "- **Из параметров** (например, среднее, дисперсия для гауссовского) составляем модель.  \n",
    "- **Оцениваем** эти параметры по данным (методом наибольшего правдоподобия или др.).  \n",
    "\n",
    "Достоинство такого подхода — простота, но если реальное распределение сильно отличается от выбранной формы, модель может ошибаться.\n",
    "\n",
    "#### 2. Непараметрические методы\n",
    "\n",
    "- **Не делаем** предположений о конкретной форме распределения.  \n",
    "- **Строим** оценку напрямую из данных.  \n",
    "\n",
    "Наиболее популярные:\n",
    "- **Ядерная оценка плотности (Kernel Density Estimation)**: Для каждой точки ставим «окошко» (ядро) и суммируем вклады этих окошек, получая плавное распределение.  \n",
    "- **K-ближайших соседей** (KNN) для оценки плотности: Смотрим, на каком расстоянии находится K ближайших соседей, и оцениваем, как плотно они сгруппированы вокруг точки.\n",
    "\n",
    "---\n",
    "\n",
    "#### Пример (Интуитивно)\n",
    "\n",
    "Представьте, что у вас есть облако точек (например, координаты людей на плоскости «вес — рост»). Вы хотите понять, **как** эти люди «распределены»:\n",
    "- Может быть, есть область с особой плотностью (типичные значения роста и веса).  \n",
    "- Есть «длинный хвост», где очень высокие люди, но их мало.  \n",
    "\n",
    "**Оценка плотности** скажет: «В этой области пространства признаков точек очень много, значит вероятность встретить там нового человека выше. В другой области точек мало, значит новая точка там — редкость».\n",
    "\n",
    "---\n",
    "\n",
    "#### Зачем нужна оценка плотности в машинном обучении?\n",
    "\n",
    "1. **Поиск аномалий**: Если плотность данных вокруг новой точки очень низкая, мы можем считать эту точку выбросом.  \n",
    "2. **Генеративные модели**: Можем генерировать новые объекты, «похожие» на исходные.  \n",
    "3. **Предварительный анализ**: Понять, сколько есть пиков (мод) в распределении, какие данные редки и т. д.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Оценка функции плотности** — способ понять, как «распределены» данные в пространстве признаков, где «сконцентрированы» точки и где их почти нет. Это помогает в анализе данных (выбросы, аномалии, кластеризация) и в ряде приложений, связанных с вероятностными методами и генеративными моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb1a4b-597c-4786-a5d1-46397b26c150",
   "metadata": {},
   "source": [
    "### Мультиномиальный классификатор, сглаживание оценок. Классификация спама."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8eb5b-a2bb-47e7-873b-beaf826d15bf",
   "metadata": {},
   "source": [
    "**Мультиномиальный классификатор** — это разновидность наивного байесовского классификатора, обычно применяемая к задачам, где важна **частота** (количество) признаков, а не просто их наличие или отсутствие. Часто используется в анализе текстов (например, **классификация спама**), когда мы имеем дело со словами и подсчитываем, насколько часто каждое слово встречается в документе.\n",
    "\n",
    "---\n",
    "\n",
    "#### Зачем «мультиномиальный»?\n",
    "\n",
    "Когда мы хотим учесть **количество** вхождений различных признаков (слов) в документ, нам нужна модель, которая учитывает не просто факт «признак есть или нет», а сколько раз он повторился. Мультиномиальный классификатор предполагает, что признаки (слова) появляются из **мультиномиального распределения** (что-то вроде «распределения количества вхождений каждого слова»).\n",
    "\n",
    "**Пример**:  \n",
    "- Для классификации писем на «спам» и «не спам», мы можем считать, сколько раз встречаются слова «скидка», «купить», «привет» и т. д.  \n",
    "- «Мультиномиальный» значит, что каждое письмо — это «мешок слов» с определёнными частотами, и эти частоты учитываются при вычислении вероятности, что письмо — «спам».\n",
    "\n",
    "---\n",
    "\n",
    "#### Сглаживание оценок (Laplace / Additive smoothing)\n",
    "\n",
    "При обучении мультиномиальной модели (или любой наивной байесовской) мы оцениваем вероятность встретить слово в том или ином классе. Но что, если в обучающем наборе слово никогда не встречалось в каком-то классе? Простая модель дала бы «вероятность = 0», что может быть слишком жёстко и привести к тому, что письмо мгновенно попадает в другой класс при одном этом слове.\n",
    "\n",
    "**Сглаживание** (часто Laplace или аддитивное сглаживание) решает эту проблему:  \n",
    "1. **Избегает нуля**: Даже если мы не видели слово в классе, сглаживание даёт ему крохотную, но не нулевую вероятность.  \n",
    "2. **Более надёжная оценка**: Учитывая, что в реальном мире мы не можем быть на 100% уверены, что слово не появится в классе.\n",
    "\n",
    "**Интуитивно**: Это похоже на то, что мы «предварительно» добавляем по единичке (или другой маленькой константе) к количеству вхождений каждого слова, чтобы никакие вероятности не оказывались равными нулю.\n",
    "\n",
    "---\n",
    "\n",
    "#### Классификация спама (как пример)\n",
    "\n",
    "- **Данные**: Имеем набор писем, часть из них помечена как «спам», часть — как «не спам».  \n",
    "- **Признаки**: Обычно слова, которые встречаются в письме. Для мультиномиального подхода мы считаем, **сколько раз** каждое слово упоминается.  \n",
    "- **Обучение**:  \n",
    "  1. Измеряем, как часто слово «купить» появляется в спам-письмах против не спама, слово «привет» и т. д.  \n",
    "  2. Применяем сглаживание: даже если какое-то редкое слово мы не видели в «не спаме», оно получает маленькую (не нулевую) вероятность.  \n",
    "  3. Получаем «вероятностную» модель, которая может по набору слов (и их частотам) оценить шансы, что письмо — спам.  \n",
    "\n",
    "- **Предсказание**: Для нового письма смотрим, какие слова в нём есть и как часто. Мультиномиальный классификатор вычисляет (по «наивной» схеме независимости слов) вероятность «спам» и «не спам». Берётся класс с большей вероятностью.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Мультиномиальный классификатор** — это наивный байесовский метод, учитывающий **количество** вхождений признаков (например, слов) в документ. Часто используется в задаче **классификации писем** на «спам»/«не спам», так как хорошо работает с текстами и даёт достаточно точные результаты при правильном сглаживании. **Сглаживание** (Laplace/Additive) помогает избежать проблемы нулевых вероятностей и делает модель более устойчивой к редким (новым) словам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4407f-c8b5-4472-b24a-eea2a40524b4",
   "metadata": {},
   "source": [
    "### Гауссовый байесовский классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67bf8a3-31b5-479c-9073-2c60aaf5a0b0",
   "metadata": {},
   "source": [
    "**Гауссовый байесовский классификатор** — это разновидность наивного байесовского классификатора, в котором предполагается, что **распределение признаков внутри каждого класса** близко к **гауссовскому (нормальному) распределению**. Проще говоря, если мы возьмём все объекты, принадлежащие к одному классу, и посмотрим на распределение их признаков, модель «делает вид», что оно похоже на горбик нормального (гауссовского) вида в многомерном пространстве.\n",
    "\n",
    "---\n",
    "\n",
    "#### Основная идея\n",
    "\n",
    "1. **Байесовский подход**:  \n",
    "   - Мы хотим вычислить вероятность того, что объект принадлежит к классу $C$, с учётом его признаков $x$.  \n",
    "   - По теореме Байеса, нас интересует «апостериорная вероятность»: каково $P(C \\mid x$).\n",
    "\n",
    "2. **Наивное предположение**:  \n",
    "   - Предполагается, что признаки условно независимы при знании класса (наивность).  \n",
    "   - Но главная особенность «гауссового» варианта в том, что **каждый признак** в классе рассматривается как имеющий **нормальное распределение** со своими средним и дисперсией.\n",
    "\n",
    "3. **Параметры** (среднее и дисперсия)  \n",
    "   - Для каждого класса и каждого признака мы оцениваем (по обучающим данным) его среднее значение (му) и дисперсию (сигма квадрат).  \n",
    "   - Получается, что для класса $C$ и признака $i$ мы знаем, как выглядит его «колокол» (гауссово распределение).\n",
    "\n",
    "4. **Применение к новому объекту**  \n",
    "   - Когда поступает новый объект с признаками $x$, мы подставляем эти признаки в формулу вероятности гауссовского распределения для каждого класса.  \n",
    "   - Потом, по байесовскому правилу, выясняем, у какого класса вероятность (или апостериорная плотность) получается выше.\n",
    "\n",
    "---\n",
    "\n",
    "#### Пример\n",
    "\n",
    "Представьте, что у нас два класса (A и B) — например, «яблоки» и «груши». У яблок признак «цвет» и «вес» распределены (в среднем) одним образом, у груш — другим образом. Если предположить, что каждое из этих признаков для конкретного класса описывается **нормальным распределением**, мы просто посчитаем (для нового фрукта), какая «вероятность» увидеть такие признаки (цвет, вес) в классе A и какая — в классе B, а затем выберем класс с большей вероятностью.\n",
    "\n",
    "---\n",
    "\n",
    "#### Отличительные особенности\n",
    "\n",
    "1. **Гауссовое (нормальное) распределение**:  \n",
    "   - Модель особенно хорошо подходит, когда мы ожидаем (или знаем), что внутри класса признаки распределены «около» средних значений с «расползанием» по нормальному закону.\n",
    "\n",
    "2. **Меньше вычислений**, чем в мультивариантном случае:  \n",
    "   - В классическом «гауссовом байесе» часто предполагают, что признаки независимы (наивный подход), поэтому не нужно оценивать ковариационные матрицы, а достаточно оценить среднее и дисперсию каждого признака отдельно.\n",
    "\n",
    "3. **Быстро и просто**:  \n",
    "   - Так как нет сложной структуры связей между признаками, параметры (средние и дисперсии) легко и быстро оцениваются.\n",
    "\n",
    "---\n",
    "\n",
    "#### Плюсы\n",
    "\n",
    "1. **Быстрое обучение**: Нужно всего лишь посчитать среднее и дисперсию каждого признака по классам.  \n",
    "2. **Простота реализации**: Гауссовое распределение хорошо изучено, формулы просты.  \n",
    "3. **Неплохое качество**: Несмотря на «наивность», часто достаточно для ряда задач.\n",
    "\n",
    "#### Минусы\n",
    "\n",
    "1. **Предположение о нормальном распределении**: Если реальные признаки не похожи на «колокол», или есть сильные выбросы, модель может ошибаться.  \n",
    "2. **Нет учёта корреляции между признаками**: Если признаки зависимы, «наивная» модель не отражает это, и точность может страдать.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Гауссовый байесовский классификатор** — это метод, который сочетает в себе идею байесовского подхода с **предположением**, что признаки внутри каждого класса распределены нормально (гауссово). Он быстрый в обучении и может давать хорошие результаты в задачах, где действительно признаки распределены «около» нормального закона, а их взаимозависимость не слишком критична."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bca315-6a0c-4663-a5af-0ac056980597",
   "metadata": {},
   "source": [
    "# Классическое машинное зрение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f90d5a9-0e48-4f73-b989-af85df157107",
   "metadata": {},
   "source": [
    "### Фильтрация изображений. Sobel, Gauss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a22ae3-04c4-4775-b936-3307c92d7432",
   "metadata": {},
   "source": [
    "**Классическое машинное зрение** включает в себя ряд традиционных (до-нейросетевых) методов обработки изображений, которые основаны на математической обработке пикселей. Одной из важнейших частей этих методов является **фильтрация изображений**, то есть преобразование изображения для выделения или подавления определённых деталей. \n",
    "\n",
    "Ниже рассмотрим, что такое **фильтрация**, а также приведём примеры основных фильтров — **Собеля (Sobel)** и **Гаусса (Gaussian)**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Фильтрация изображений: общее понятие\n",
    "\n",
    "**Фильтрация** — это процесс, при котором мы берём входное изображение и пропускаем его через некий «шаблон» (часто именуемый **ядром** или **маской**), чтобы преобразовать пиксели к нужному виду. На практике это означает, что к каждому пикселю применяется небольшая операция с учётом его и соседних значений, и результат записывается в выходное изображение.\n",
    "\n",
    "- **Зачем фильтровать?**  \n",
    "  - Сгладить шум (убрать резкие случайные перепады яркости).  \n",
    "  - Выделить границы объектов (подчеркнуть изменения в яркости).  \n",
    "  - Подготовить изображение к дальнейшему анализу (например, распознаванию контуров и т. д.).\n",
    "\n",
    "---\n",
    "\n",
    "#### Фильтр Гаусса (Gaussian)\n",
    "\n",
    "**Фильтр Гаусса** используется для **сглаживания (размытия)** изображения и удаления высокочастотного шума. Он применяет гауссовскую (колоколообразную) функцию к окрестности каждого пикселя:\n",
    "\n",
    "- **Гауссовское «окно»**: в центре (под пикселем, который мы обрабатываем) вес самый высокий, а по краям снижается, наподобие колокола. Это значит, что вклад ближайших пикселей больше, чем у дальних.  \n",
    "\n",
    "- **Размытие без резких артефактов**: Гаусс даёт «мягкое» размытие, именно поэтому его часто используют для первичной фильтрации шума, убирая мелкие детали и делая изображение более «гладким».\n",
    "\n",
    "- **Пример: подавление шума**: если фото зернистое (много мелкого шума), фильтр Гаусса с определённым радиусом поможет сделать изображение более ровным, при этом не создавая резких переходов.\n",
    "\n",
    "---\n",
    "\n",
    "#### Фильтр Собеля (Sobel)\n",
    "\n",
    "**Фильтр Собеля** предназначен для **выделения границ** (контуров) в изображении. Он реагирует на изменения яркости в направлении по осям X и Y:\n",
    "\n",
    "1. **Горизонтальный оператор**: обнаруживает изменения яркости слева-направо (горизонтальные компоненты градиента).  \n",
    "2. **Вертикальный оператор**: находит изменения сверху-вниз (вертикальные компоненты градиента).  \n",
    "\n",
    "На практике часто мы комбинируем оба результата, получая «величину градиента» (насколько сильно меняется яркость) и «направление границы». \n",
    "\n",
    "#### Как работает Собель\n",
    "\n",
    "1. **Небольшая матрица (ядро)**, например, размером 3×3, скользит по изображению.  \n",
    "2. **Множество соседних пикселей** берётся с некоторыми весовыми коэффициентами, чтобы определить, есть ли существенный перепад яркости вдоль той или иной оси.  \n",
    "3. **Если перепад значительный**, результат (яркость в выходном изображении) получается высоким, указывая на наличие «контура» в этом месте.\n",
    "\n",
    "---\n",
    "\n",
    "#### Как это применяется?\n",
    "\n",
    "1. **Подготовка к распознаванию**  \n",
    "   - Сгладить изображение (фильтр Гаусса), чтобы убрать мелкий шум и не мешать определению контура.  \n",
    "   - Найти границы (фильтр Собеля), чтобы распознать форму объектов или проверить, где изображения существенно меняются.\n",
    "\n",
    "2. **Обработка шумных данных**  \n",
    "   - Если изображение снято при плохом освещении, методы сглаживания (Гаусс) помогают улучшить картинку перед анализом.\n",
    "\n",
    "3. **Классификация, детекция**  \n",
    "   - В классическом машинном зрении часто после фильтров Собеля пытаются определить формы объектов (например, машин, людей), опираясь на контуры.\n",
    "\n",
    "---\n",
    "\n",
    "#### Кратко о других фильтрах\n",
    "\n",
    "- **Laplace**: используется для выделения более резких переходов (вторая производная).  \n",
    "- **Median**: убирает шум, заменяя пиксель на медиану его окрестности. Полезно при «выбросах» яркости.  \n",
    "\n",
    "Тем не менее, **Собель** и **Гаусс** являются одними из самых классических и часто применяемых:\n",
    "\n",
    "- **Гаусс** для **размытия/сглаживания**.  \n",
    "- **Собель** для **нахождения контуров** (резких перепадов яркости).\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Фильтрация изображений** в классическом машинном зрении — это использование специальных «окон» (ядер), которые скользят по изображению и преобразуют пиксели.  \n",
    "- **Гауссовский фильтр** («размытие Гаусса») смягчает изображение и удаляет шум.  \n",
    "- **Фильтр Собеля** позволяет выделять границы и структуры, определяя места, где изображение резко меняет яркость.\n",
    "\n",
    "Оба фильтра вместе дают мощные инструменты для последующего анализа и понимания содержания в изображениях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b99db6-8ea1-49a1-9fe9-6853f703ed02",
   "metadata": {},
   "source": [
    "### Алгоритм детекции границ Canny."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62e4407-01eb-4f8b-b00d-eb6fabd9ac9a",
   "metadata": {},
   "source": [
    "**Алгоритм детекции границ Canny** — это один из самых распространённых и эффективных способов найти **контуры** (границы) объектов в изображении. Он аккуратно выявляет места, где яркость картинки резко меняется, и отделяет «настоящие» границы от случайных перепадов. Алгоритм был предложен Джоном Кэнни (John F. Canny).\n",
    "\n",
    "---\n",
    "\n",
    "#### Основные этапы\n",
    "\n",
    "1. **Сглаживание (фильтрация Гаусса)**  \n",
    "   - Перед тем как искать границы, изображение немного размывают с помощью Гауссового фильтра.  \n",
    "   - Это нужно, чтобы убрать мелкий шум и аномальные скачки яркости, которые могут создавать ложные границы.\n",
    "\n",
    "2. **Поиск градиентов**  \n",
    "   - После сглаживания ищут участки, где изображение резко меняет яркость (градиент высокий).  \n",
    "   - Чаще всего используют операторы Собеля или аналогичные, чтобы вычислить «горизонтальную» и «вертикальную» составляющие изменений.\n",
    "\n",
    "3. **Подавление немаксимумов (non-maximum suppression)**  \n",
    "   - В местах, где найден градиент, алгоритм определяет точное направление этого изменения.  \n",
    "   - Затем из всех соседних пикселей в этом направлении оставляют только тот пиксель, который имеет максимальную «силу градиента». Остальные, даже если они тоже «высокие», но не максимальные, обнуляют (то есть убирают).  \n",
    "   - Таким образом, мы получаем тонкие и точные линии контуров, а не «толстые мазки».\n",
    "\n",
    "4. **Двухпороговая обработка (hysteresis thresholding)**  \n",
    "   - После убирания немаксимумов остаются пиксели с разной величиной градиента. Нужно решить, какие из них «достаточно сильные», чтобы быть реальными границами.  \n",
    "   - Алгоритм использует два порога: «высокий» (upper) и «низкий» (lower).  \n",
    "   - Все пиксели, у которых градиент выше верхнего порога, сразу считаются истинными границами.  \n",
    "   - Те, у которых градиент ниже нижнего порога, отбрасываются как шум.  \n",
    "   - Пиксели между порогами считаются «неопределёнными» и принимаются как границы только если они связаны (смежны) с «уверенными» пикселями (которые прошли верхний порог). Это называют «гистерезисом» (hysteresis): мы говорим «если неопределённый пиксель рядом с уже подтверждённой границей, то тоже засчитываем его в границу».\n",
    "\n",
    "---\n",
    "\n",
    "#### Почему алгоритм Canny так хорош?\n",
    "\n",
    "1. **Убирает шум**: из-за начального сглаживания.  \n",
    "2. **Выделяет чёткие контуры**: благодаря вычислению градиента и non-maximum suppression, контуры становятся «тонкими» линиями.  \n",
    "3. **Гибкая система порогов**: двухпороговая система гистерезиса эффективно отсекает слабые шумовые границы, но при этом «дотягивает» частично обнаруженные контуры, если рядом уже подтверждён сильный сигнал.\n",
    "\n",
    "---\n",
    "\n",
    "#### Кратко\n",
    "\n",
    "- **Шаг 1**: Размыть (Gauss) изображение, чтобы сгладить шум.  \n",
    "- **Шаг 2**: Найти градиент (Собель и т. п.) и определить направления границ.  \n",
    "- **Шаг 3**: Оставить только пиксели, являющиеся локальными максимумами (non-maximum suppression), получаем тонкие линии.  \n",
    "- **Шаг 4**: Применить два порога, «высокий» и «низкий», и связать пиксели методом гистерезиса, чтобы отделить настоящие контуры от шумовых.\n",
    "\n",
    "**Canny** обеспечивает надёжное, точное и тонкое обнаружение границ, что делает его одним из наиболее популярных алгоритмов в классическом машинном зрении."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648580f0-5cf9-4dfb-8da6-09dd9ac249fe",
   "metadata": {},
   "source": [
    "### Алгоритм Хаффа поиска прямых (Hough lines)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80afe197-643f-4817-8cf7-61c9826af54e",
   "metadata": {},
   "source": [
    "**Алгоритм Хаффа для поиска прямых (Hough lines)** — это классический метод в компьютерном зрении, позволяющий находить **прямые** (линии) на изображении даже при наличии шумов или фрагментарных данных. \n",
    "\n",
    "---\n",
    "\n",
    "#### Основная идея\n",
    "\n",
    "1. **Наличие «точек-кандидатов»**: Предположим, мы уже выделили **точки**, которые предположительно лежат на контурах (например, с помощью детектора границ Canny).  \n",
    "\n",
    "2. **Переход в «параметрическое пространство»**:  \n",
    "   - Каждая прямая в обычных координатах (изображении) может быть описана некоторым набором параметров (например, расстояние до начала координат и угол наклона).  \n",
    "   - Алгоритм «Хафф» говорит: «Давайте заставим каждую точку ‘голосовать’ за все линии (параметры), которые через неё могут проходить».  \n",
    "\n",
    "3. **Голосование («accumulator»)**:  \n",
    "   - Мы создаём «массив-аккумулятор» (по осям — параметры прямой).  \n",
    "   - Для каждой точки изображения: она «гипотетически» подходит к множеству возможных линий (разные углы, расстояния). За каждую такую линию точка даёт «голос» в аккумуляторе.  \n",
    "\n",
    "4. **Поиск пиков в аккумуляторе**:  \n",
    "   - После того, как **все** точки проголосовали, в аккумуляторном пространстве появляются «пики» (множество голосов) в тех параметрах, где действительно проходит «много» точек. Это означает, что в этих параметрах есть реальная линия.  \n",
    "   - Линии, которые «проходят» только через пару точек, голосов наберут мало и «пика» не образуют.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Преимущества и недостатки\n",
    "\n",
    "**Преимущества**:  \n",
    "- Работает даже если линия **прерывиста**, присутствует шум, или часть контура отсутствует.  \n",
    "- Возмущения и пропуски не критичны, т. к. общее количество голосов всё равно может «вытащить» реальную линию.\n",
    "\n",
    "**Недостатки**:  \n",
    "- Могут быть довольно затратные вычисления (особенно если изображение большое и много точек).  \n",
    "- Нужно аккуратно настраивать пороги для «пиков» в аккумуляторе, чтобы не находить «линии-призраки» и не упускать реальные.\n",
    "\n",
    "---\n",
    "\n",
    "#### Пример использования\n",
    "\n",
    "1. **Детектор краёв** (например, Canny) создаёт набор пикселей, которые с высокой вероятностью лежат на границах.  \n",
    "2. **Хафф**: Каждый такой пиксель говорит: «Если линия проходит через меня под углом $\\theta$ и с расстоянием $\\rho$, я отдаю голос.»  \n",
    "3. **Накопление голосов**: Если много пикселей сходятся во мнении, что линия с параметрами $\\theta_0$ и $\\rho_0$ подходит под их положение, это значит, что такая линия действительно есть на изображении.  \n",
    "4. **Результат**: Получаем список найденных линий (каждая описывается своими параметрами).\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Алгоритм Хаффа поиска прямых** — это метод, который с помощью «голосования» в параметрическом пространстве выявляет линии, проходящие через множество контурных точек на изображении. Он устойчив к шуму и неполноте данных, что сделало его одним из самых известных алгоритмов в классическом машинном зрении для детекции прямых."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2cf4c7-ecd0-428f-9543-cac9336d8f33",
   "metadata": {},
   "source": [
    "### Алгоритм Хаффа поиска окружностей (Hough circles)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64dc5ad-2473-4ace-8b80-0db19ac8cc7b",
   "metadata": {},
   "source": [
    "**Алгоритм Хаффа для поиска окружностей (Hough circles)** — это обобщение идеи алгоритма Хаффа (Hough) для поиска **прямых** к задаче нахождения **окружностей** на изображении. Если алгоритм Хаффа для прямых ищет параметры $\\rho$ и $\\theta$ (расстояние до начала координат и угол наклона), то при поиске окружности мы ищем **центр** окружности $(x_c, y_c)$ и её **радиус** $r$.\n",
    "\n",
    "---\n",
    "\n",
    "#### Основная идея\n",
    "\n",
    "1. **Контурные точки**  \n",
    "   - Сначала мы имеем набор пикселей, которые с высокой вероятностью лежат на контуре (например, после детектора границ, как Canny).  \n",
    "   - Каждая такая точка — потенциально часть некоторой окружности.\n",
    "\n",
    "2. **Параметрическое пространство окружности**  \n",
    "   - Любая окружность можно описать координатами своего центра $(x_c, y_c)$ и радиусом $r$.  \n",
    "   - Значит, если пиксель $(x, y)$ лежит на окружности, то он «подсказывает», что $(x_c, y_c)$ должен находиться на расстоянии $r$ от $(x, y)$.\n",
    "\n",
    "3. **Голосование (accumulator) в трёхмерном пространстве**  \n",
    "   - Для каждой точки-границы $(x, y)$ алгоритм «перебирает» возможные значения радиуса $r$ и вычисляет, где мог бы быть центр $(x_c, y_c)$.  \n",
    "   - Это «гипотеза»: «Если радиус $r$, то центр должен быть на расстоянии $r$ от $(x, y)$».  \n",
    "   - Пиксель $(x, y)$ голосует за все такие потенциальные центры, увеличивая счётчик в аккумуляторном пространстве $(x_c, y_c, r)$.\n",
    "\n",
    "4. **Поиск «пиков»**  \n",
    "   - В конце, когда все контурные точки проголосовали, мы ищем в пространстве $(x_c, y_c, r)$ те ячейки, у которых «количество голосов» (accumulator) особенно велико.  \n",
    "   - Это значит, что существует много контурных точек, которые согласны с тем, что есть окружность с этим центром и этим радиусом.  \n",
    "   - Такие «пики» и есть потенциальные окружности на изображении.\n",
    "\n",
    "---\n",
    "\n",
    "#### Как это выглядит на практике\n",
    "\n",
    "1. **Нахождение границ** (например, Canny). Выделяем точки, где есть явные перепады яркости.  \n",
    "2. **Hough Circles** (окружности): \n",
    "   - На каждом таком пикселе $(x, y)$ перебирают некоторые наборы радиусов (часто в диапазоне от $r_{min}$ до $r_{max}$),  \n",
    "   - Вычисляют, где может быть центр $(x_c, y_c)$, чтобы окружность с радиусом $r$ проходила через $(x, y)$.  \n",
    "   - Голосование: $(x_c, y_c, r)$ получает 1 голос от этого пикселя.  \n",
    "3. **Итог**: там, где много пикселей-границ согласовываются на том же центре и радиусе, появляется «пик» в аккумуляторе. Эти пики и отображают найденные окружности.\n",
    "\n",
    "---\n",
    "\n",
    "#### Преимущества\n",
    "\n",
    "- **Устойчивость к шуму и прерывистым контурам**: Не все точки окружности должны быть на изображении — если есть достаточно много «голосов», окружность всё равно будет найдена.  \n",
    "- **Работает при пропущенных деталях**: Даже если часть окружности не видна, набор точек всё равно может «договориться» о центре и радиусе.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Недостатки\n",
    "\n",
    "1. **Вычеслительная сложность**: Перебор по центру $(x_c, y_c)$ и радиусу $r$ может быть весьма большим. Нужно иногда оптимизировать.  \n",
    "2. **Порог голосов**: Нужно аккуратно выбирать пороги (сколько голосов считать «пиком»), чтобы не находить ложные окружности и не пропускать реальные.  \n",
    "3. **Чувствительность к параметрам**: Если радиусы слишком ограничены или наоборот слишком широки, можно пропустить нужные окружности или получить кучу лишних.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Алгоритм Хаффа для окружностей** (Hough circles) — это метод поиска всех окружностей, проходящих через множество контурных точек. Он «голосует» в трёхмерном пространстве $(x_c, y_c, r)$, где каждый контурный пиксель предлагает центры и радиусы. Там, где скапливается много голосов, мы заключаем, что найдена реальная окружность. Такой подход эффективно детектирует окружности, даже если границы не идеальны и присутствует шум."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477f6102-d527-4709-a5ce-f14185d034ef",
   "metadata": {},
   "source": [
    "# Нейронные сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834a448d-d669-45f4-94e6-72312cfa7b88",
   "metadata": {},
   "source": [
    "### Полносвязный слой. (Dense, Fully connected)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926038e8-21a5-49c8-8e4b-62860501e2e9",
   "metadata": {},
   "source": [
    "**Полносвязный слой** (также называемый Dense или Fully Connected Layer) — это один из ключевых строительных блоков нейронной сети, в котором **каждый нейрон** слоя **соединён** с **каждым нейроном** следующего (или предыдущего) слоя. \n",
    "\n",
    "---\n",
    "\n",
    "#### Как это работает\n",
    "\n",
    "1. **Нейроны (или «узлы»)**: Представьте слой как набор независимых маленьких «блоков» (нейронов), каждый из которых ждёт на вход **числа** (активности) от предыдущего слоя.  \n",
    "2. **Полная связь**: В «полносвязном» слое **каждый** нейрон получает данные **от всех** нейронов предыдущего слоя. Это означает, что если предыдущий слой имеет $N$ выходных значений, а текущий слой содержит $M$ нейронов, то всего будет $N \\times M$ связей (плюс по одному смещению (bias) на каждую из $M$ нейронов).  \n",
    "3. **Взвешенные суммы**: Каждый вход умножается на соответствующий «вес» (параметр), а затем все эти произведения складываются. Далее прибавляется «смещение» (bias), и результат проходит через функцию активации (ReLU, sigmoid, tanh или другую), которая даёт итоговый выход конкретного нейрона.\n",
    "\n",
    "---\n",
    "\n",
    "#### Почему называется «полносвязный»?\n",
    "\n",
    "Потому что **все** возможные соединения между двумя соседними слоями в сети присутствуют. Нет ни одного нейрона, который не был бы связан с кем-то из следующего слоя. Это максимизирует возможность каждого нейрона «видеть» всю информацию от предыдущего слоя.\n",
    "\n",
    "---\n",
    "\n",
    "#### Роль в нейронной сети\n",
    "\n",
    "1. **Суммарное объединение** признаков: Полносвязный слой обрабатывает информацию, собранную ранее (например, если это сверточная сеть, то из свёрточных слоёв) и пытается «понять» взаимосвязи между всеми компонентами.  \n",
    "2. **Окончательное принятие решения**: Обычно в конце сети (например, перед выходом) ставят один или несколько Dense-слоёв, которые сводят всю информацию к окончательному решению (к примеру, к вероятностям классов).  \n",
    "3. **Мощная и универсальная архитектура**: В простых сетях (MLP — MultiLayer Perceptron) часто используется несколько таких полносвязных слоёв подряд.\n",
    "\n",
    "---\n",
    "\n",
    "#### Преимущества и недостатки\n",
    "\n",
    "#### Преимущества\n",
    "- **Универсальность**: Может приблизить (выучить) практически любую функцию при достаточном количестве нейронов.  \n",
    "- **Простота**: Идея легко понимается: каждый «узел» получает взвешенную сумму всех входов.  \n",
    "- **Гибкость**: При желании можно управлять количеством слоёв и нейронов в каждом слое.\n",
    "\n",
    "#### Недостатки\n",
    "- **Много параметров**: При большом числе входов и нейронов количество весов и смещений быстро растёт (ростет квадратично), что делает обучение более долгим и требовательным к памяти.  \n",
    "- **Не учитывает структуру входных данных**: Например, если данные — это изображение, Dense-слой «не знает» о пространственных связях, всё превращается в длинный вектор.\n",
    "\n",
    "---\n",
    "\n",
    "#### Пример использования\n",
    "\n",
    "1. **Простая MLP**: Допустим, есть вход из 10 численных признаков, и нужно классифицировать на 3 класса. Можно поставить один или два полносвязных слоя, а затем выходной слой из 3 нейронов (по числу классов).  \n",
    "2. **В конце сверточной сети**: После нескольких свёрточных и пуллинговых слоёв (которые вытягивают пространственные признаки из картинки), данные «выпрямляют» (flatten), получается вектор. Его подают на Dense-слой (или несколько), который комбинирует все эти признаки и выдаёт итоговую классификацию (например, «кошка», «собака», «машина»).\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Полносвязный слой (Dense Layer)** — это базовый, хорошо понимаемый тип слоя в нейронных сетях, где каждый нейрон соединён со всеми выходами предыдущего слоя. Он «объединяет» всю входную информацию, умножая входы на свои веса, складывая их и пропуская через функцию активации. Хотя Dense-слои очень универсальны, при работе с изображениями, звуком или текстами всё чаще используют специализированные слои (свёрточные, рекуррентные), а Dense-слои обычно служат «завершающими» слоями, сводящими всю обработку к нужному выходу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2f3ae-3746-4ccb-b09a-02e5c24c89d7",
   "metadata": {},
   "source": [
    "### Свёрточный слой. (Convolution)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd056d-026f-453c-a4d1-61648067ec50",
   "metadata": {},
   "source": [
    "**Свёрточный слой** (convolutional layer) — это ключевой элемент **свёрточных нейронных сетей** (Convolutional Neural Networks, CNN), которые особенно хорошо работают с изображениями (и другими данными, имеющими пространственную или временную структуру). Вместо того чтобы брать все входные признаки целиком (как в полносвязном слое), свёрточный слой **обрабатывает данные фрагментами** (локальными участками), «свёртывая» их с набором фильтров (ядёр).\n",
    "\n",
    "---\n",
    "\n",
    "#### Основная идея\n",
    "\n",
    "1. **Локальные «окна»**:  \n",
    "   - Представьте, что у вас есть изображение (или другой массив данных). Свёрточный слой скользит по нему небольшим «окном» (ядром, фильтром), которое обычно намного меньше, чем всё изображение.  \n",
    "   - Например, 3×3 пикселя или 5×5 пикселей в случае изображения.\n",
    "\n",
    "2. **Фильтр (ядро)**:  \n",
    "   - Фильтр (kernel) — это набор обучаемых весов, организованных в маленькую матрицу.  \n",
    "   - При «применении» фильтра к «окну» данных каждый элемент окна умножается на соответствующий вес, все результаты складываются, а затем может добавляться смещение (bias).  \n",
    "   - Результат идёт в выходное «пространство» — в пиксель (или значение) «карты признаков» (feature map) на выходе.\n",
    "\n",
    "3. **Скользящая операция** (свёртка):  \n",
    "   - Фильтр «проходится» (скользит) по входному массиву (изображению) шаг за шагом, совершая свёртку на каждом участке.  \n",
    "   - Каждый такой участок даёт одно число на выходе (вак как сумму произведений входов и весов).  \n",
    "\n",
    "4. **Выходные карты признаков**:  \n",
    "   - Обычно в слое есть несколько фильтров (скажем, 32 фильтра). Каждый фильтр выделяет **свой** тип признака (например, горизонтальные линии, вертикальные края, текстуры и т. д.).  \n",
    "   - Это порождает **несколько каналов** на выходе (по одному каналу на каждый фильтр).  \n",
    "   - Получается набор «карт признаков» (feature maps), показывающих, где (в каком месте) на входном изображении фильтр «среагировал».\n",
    "\n",
    "---\n",
    "\n",
    "#### Почему это работает для изображений\n",
    "\n",
    "- **Пространственная локальность**: В картинках часто важно, какие пиксели находятся рядом, а не какие пиксели в другом углу. Свёрточный слой обрабатывает именно **локальные** паттерны (например, маленькие кусочки).  \n",
    "- **Меньше параметров**: В отличие от полносвязного слоя, где каждый пиксель входа связан со всеми нейронами (что очень много весов), в свёрточном слое фильтр имеет небольшой размер (например, 3×3) и при этом «применяется» ко всему изображению. Это значит, что число обучаемых весов относительно мало, а возможности распознавать локальные структуры большие.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Пример\n",
    "\n",
    "1. **Допустим**, у нас есть изображение 28×28 пикселей (одноцветное).  \n",
    "2. **Фильтр** 3×3 с 8 фильтрами:  \n",
    "   - Значит, 8 «наборов» по 3×3 весов, итого 8×(3×3)=72 веса (плюс по одному смещению на фильтр).  \n",
    "3. **Применение**:  \n",
    "   - Для каждого положения (x,y) на картинке берём 3×3 окружение, умножаем на веса фильтра, складываем — получаем 1 число. Это число попадает в карту признаков данного фильтра.  \n",
    "   - Повторяем для всех позиций, двигаясь вправо и вниз по изображению (можно при этом настраивать шаг (stride), добавлять заполнение (padding)).  \n",
    "   - В итоге, каждая 3×3 операция создаёт соответствующее значение на выходе в «карте».  \n",
    "   - Мы делаем это для всех 8 фильтров, получая 8 выходных каналов.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Свёрточный слой** — это основной механизм в свёрточных нейронных сетях. Он «свёртывает» (перемножает и суммирует) локальные области данных (обычно изображения) с обучаемыми фильтрами, чтобы извлекать важные местные признаки (контуры, края, текстуры). Это делает CNN очень эффективными для обработки изображений и других данных, где локальная структура играет большую роль."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf45d00-64df-40ff-a194-82e199340f79",
   "metadata": {},
   "source": [
    "### Pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f69803-a6a5-45aa-a70c-bb1c93ba3389",
   "metadata": {},
   "source": [
    "**Pooling** — это операция в свёрточных нейронных сетях (CNN), позволяющая **уменьшать размер** (downsampling) пространственных признаков (feature maps). Она идёт после свёрточных слоёв и «сжимает» каждую карту признаков по высоте и ширине, оставляя лишь основные особенности и снижая вычислительную нагрузку.\n",
    "\n",
    "---\n",
    "\n",
    "#### Основная идея\n",
    "\n",
    "1. **Локальная область**  \n",
    "   - Подобно свёрточному слою, pooling «скользит» по изображению (или по карте признаков, полученной после свёртки) небольшим «окном» (например, 2×2 пикселя).  \n",
    "2. **Уменьшение размерности**  \n",
    "   - Для каждого такого окна получается **одно** число на выходе (либо максимальное, либо среднее), таким образом уменьшая размер выходной карты ровно в (размер окна) раз по каждому измерению (если используется нетерпящийся шаг по окну).  \n",
    "3. **Выделение главного**  \n",
    "   - Удаляются мелкие детали, шум, а сохраняется более «обобщённая» информация — например, «максимум» нам говорит, что в этом участке присутствует какой-то признак (пусть даже он локализован в одном пикселе).\n",
    "\n",
    "---\n",
    "\n",
    "#### Виды Pooling\n",
    "\n",
    "1. **Max Pooling**  \n",
    "   - Взять **максимальное** значение из окна (например, из 2×2 пикселей).  \n",
    "   - Хорошо определяет «сильнейшие» признаки в локальной области.  \n",
    "2. **Average Pooling**  \n",
    "   - Взять **среднее** значение по всем пикселям в окне.  \n",
    "   - Сглаживает особенности, более «усредняет» пространство.  \n",
    "3. **Global Pooling** (Global Max или Global Avg)  \n",
    "   - Окно равно размеру всей карты, берётся один максимум (или среднее) по всей карте признаков.  \n",
    "   - Этим способом можно «свернуть» всю карту признаков в одно число, что бывает нужно перед полносвязным слоем.\n",
    "\n",
    "---\n",
    "\n",
    "#### Зачем это нужно?\n",
    "\n",
    "- **Сокращение размерности**: После pooling объём данных уменьшается, что облегчает вычисление в следующих слоях и сокращает число параметров.  \n",
    "- **Робастность к смещениям**: Если важный признак сместился в пределах окна pooling, max pooling всё равно «увидит» его в том же выходном значении. Это улучшает инвариантность к сдвигу.  \n",
    "- **Предотвращение переобучения**: За счёт уменьшения размерности и некоторой потери избыточных деталей сеть меньше запоминает «шумы».\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Pooling** — это «операция сжатия» карты признаков в свёрточных сетях.  \n",
    "- **Max pooling** берёт максимальное значение в каждом локальном фрагменте,  \n",
    "- **Average pooling** — среднее,  \n",
    "- A иногда используют **Global pooling** для усреднения/максимума по всей карте.  \n",
    "\n",
    "Это помогает улучшать **смысловое обобщение** признаков, уменьшать вычислительные затраты и повышать устойчивость сети к маленьким сдвигам или шумам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1b13c-81c9-4297-9773-c21bbbeecc0e",
   "metadata": {},
   "source": [
    "### Функции активации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8dcd4d-991d-4174-a31b-189d85e6b7fd",
   "metadata": {},
   "source": [
    "**Функции активации** — это специальные функции, которые работают внутри нейронов в нейронных сетях, и помогают сети моделировать нелинейные зависимости. Когда мы говорим «нейрон» в глубокой сети, мы имеем в виду узел, который получает взвешенные суммы входов (с учётом весов и смещений), а потом пропускает результат через **функцию активации**, формируя окончательный выход нейрона.\n",
    "\n",
    "---\n",
    "\n",
    "#### Зачем нужны функции активации?\n",
    "\n",
    "1. **Нелинейность**: Без функций активации, нейронная сеть была бы просто набором линейных преобразований. Это означало бы, что любой дополнительный слой «не добавляет» новых типов зависимостей (потому что линейная функция от линейной функции всё равно остаётся линейной). Нелинейная функция активации «разрывает» эту линейность и позволяет сети учиться более сложным связям.\n",
    "\n",
    "2. **Контроль диапазона**: Некоторые функции активации ограничивают выход в определённом диапазоне (например, от 0 до 1), что бывает удобно в некоторых задачах (классификация и т. д.).\n",
    "\n",
    "3. **Глубокое обучение**: Именно благодаря наличию нелинейных активаций мы можем создавать глубокие сети (с многими слоями), обучающиеся сложным паттернам в данных.\n",
    "\n",
    "---\n",
    "\n",
    "#### Основные типы активаций\n",
    "\n",
    "#### 1. Сигмоида (Sigmoid)\n",
    "- **Выглядит**: Плавно нарастает от 0 до 1.  \n",
    "- **В чём польза**: Удобна, когда нужен результат вроде «вероятности» (числа от 0 до 1).  \n",
    "- **Минус**: При больших по модулю входах, выход «запирается» близко к 0 или 1, градиенты становятся очень маленькими (эффект «затухающего градиента»).\n",
    "\n",
    "#### 2. Тангенс гиперболический (Tanh)\n",
    "- **Похожа** на сигмоиду, но значения лежат в диапазоне от -1 до +1.  \n",
    "- **Минус**: Тоже может «насытиться» ( saturate ) и давать очень маленькие градиенты при больших по модулю входах.\n",
    "\n",
    "#### 3. ReLU (Rectified Linear Unit)\n",
    "- **Функция**: Если вход положительный — пропускаем как есть, если отрицательный — результат 0.  \n",
    "- **Выглядит**: Пороговая, «обрезает» отрицательные значения.  \n",
    "- **Плюсы**: Простая, не «насыщается» на больших положительных входах, градиенты там не затухают.  \n",
    "- **Минус**: Может «обнулять» весь сигнал, когда вход отрицательный, и нейрон перестаёт обучаться (эта ситуация называется «мертвые ReLU»).\n",
    "\n",
    "#### 4. Leaky ReLU, ELU и др.\n",
    "- **Это** вариации ReLU, где отрицательные входы не обрубаются до 0 совсем, а пропускают небольшое значение (например, 0.01 * x).  \n",
    "- **Цель**: Избежать эффекта «мертвых ReLU», сохраняя при этом простоту и эффективность.\n",
    "\n",
    "#### 5. Softmax\n",
    "- **Назначение**: Чаще всего используется в выходном слое для **многоклассовой классификации**.  \n",
    "- **Что делает**: Превращает набор входных чисел в «вероятности» для каждого класса (все числа становятся неотрицательными и сумма равна 1).\n",
    "\n",
    "---\n",
    "\n",
    "#### Как выбрать функцию активации?\n",
    "\n",
    "- **ReLU** (или её вариации) — стандартный выбор в современных нейронных сетях. Простая, быстрая, хорошо ведёт себя при обратном распространении ошибок.  \n",
    "- **Sigmoid** или **Tanh** — используются реже внутри сети (из-за проблемы затухающих градиентов), но всё же применимы, например, в выходном слое для бинарной классификации (сигмоида).  \n",
    "- **Softmax** — обычно в **выходном слое** при задаче многоклассовой классификации, чтобы получить вероятностное распределение по классам.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Функция активации** — это «шаг» внутри нейрона, который добавляет **нелинейность** к сумме взвешенных входов. Без неё сеть была бы просто одним большим линейным преобразованием. Большая часть успеха глубокого обучения связана с правильно подобранными функциями активации (особенно ReLU и её вариациями)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ca17b-7945-4e28-8272-be7e8a882706",
   "metadata": {},
   "source": [
    "### Метод обратного распространения ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f8abd-1c42-4e80-9d44-beb3f5587450",
   "metadata": {},
   "source": [
    "**Метод обратного распространения ошибки (Backpropagation)** — это ключевой алгоритм, позволяющий обучать (корректировать веса) в нейронных сетях. Основная задача — понять, как сильно каждая часть сети влияет на общую ошибку, чтобы «знать», какие веса нужно изменить и насколько.\n",
    "\n",
    "---\n",
    "\n",
    "#### Основная идея\n",
    "\n",
    "1. **Прямое прохождение (forward pass)**  \n",
    "   - Сначала мы подаём входные данные в сеть, слой за слоем, пока не получим финальный результат (предсказание).  \n",
    "   - На этом этапе мы можем вычислить, в чём именно и на сколько сеть ошиблась: сравнить выход с реальным ответом, чтобы найти **функцию потерь** (например, среднеквадратичная ошибка для регрессии или кроссэнтропия для классификации).\n",
    "\n",
    "2. **Обратное распространение (backpropagation)**  \n",
    "   - Затем алгоритм **двигается с конца сети** (от выходного слоя) **назад**, вычисляя, как каждый вес вносил вклад в ошибку.  \n",
    "   - Используя правила дифференцирования (по сути, «правило цепочки», chain rule), мы находим «производные» ошибки по отношению к весам: то есть, если мы слегка изменим этот вес, как изменится ошибка?  \n",
    "   - Эти производные говорят, в каком направлении (увеличить или уменьшить) и насколько менять каждый вес, чтобы уменьшить ошибку.\n",
    "\n",
    "3. **Обновление весов**  \n",
    "   - Получив градиенты (производные) по всем весам, мы корректируем каждый вес в сторону, уменьшающую ошибку. Часто это делается по схеме градиентного спуска (weights -= learning_rate * gradient).  \n",
    "   - Процесс повторяется много раз: в каждом цикле (эпохе) мы делаем прямое прохождение, считаем ошибку, распространяем её обратно и обновляем веса.\n",
    "\n",
    "---\n",
    "\n",
    "#### Почему это работает\n",
    "\n",
    "- **Правило цепочки**: Любая нейронная сеть представляет собой композицию функций (каждый слой — отдельная функция). «Правило цепочки» позволяет найти, как изменение одного веса повлияет на конечную ошибку, даже если между этим весом и выходом — несколько слоёв.  \n",
    "- **Набор частных производных**: При обучении мы ищем минимум функции потерь в пространстве весов. Градиент (набор производных) говорит нам, в каком направлении эта ошибка убывает быстрее всего.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Пример (Интуитивно)\n",
    "\n",
    "1. **У нас есть** 2 слоя, каждый с несколькими нейронами.  \n",
    "2. **Forward**: Мы подали данные (например, пиксели картинки), прошли через первый слой (получили промежуточные выходы), через второй (получили итоговое предсказание).  \n",
    "3. **Ошибка**: Сравнили предсказание с истинной меткой. Допустим, ошибка получилась 0.3.  \n",
    "4. **Backward**:  \n",
    "   - Сначала смотрим, как ошибка зависит от выхода второго слоя (т. е. как сильно каждый нейрон второго слоя «ошибся»).  \n",
    "   - Потом идём внутрь слоя: как каждый вес внутри второго слоя влияет на тот выход?  \n",
    "   - Затем переходим к первому слою и вычисляем, как каждый вес там влияет на ошибку, учитывая уже найденные зависимости во втором слое.  \n",
    "5. **Обновление**: У каждого веса получается своя «частная производная» (градиент), указывающая, как его немного сдвинуть, чтобы ошибка пошла вниз. Меняем веса согласно этим градиентам.\n",
    "\n",
    "---\n",
    "\n",
    "#### Итог\n",
    "\n",
    "**Метод обратного распространения ошибки** (backpropagation) — это алгоритм, который автоматизированно определяет, как нужно скорректировать **каждый вес** в нейронной сети, чтобы **уменьшить ошибку**. Он использует:\n",
    "\n",
    "- **Прямой проход** (посчитать предсказание и ошибку),  \n",
    "- **Обратный проход** (посчитать, в каком направлении и насколько менять веса).\n",
    "\n",
    "Без backpropagation глубокие нейронные сети было бы крайне сложно обучать, так как неизвестно, как каждая часть сети влияет на итоговую ошибку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc440949-d0da-427c-8ab9-eff91f19a484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
